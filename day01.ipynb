{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNa4tn9EEA67r0L9tCLq547",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clappingmin/deeplearning/blob/master/day01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9TDhQgsLgAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "629a254b-94fc-4ca0-a455-8be43ac947c7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "dataset_path = tf.keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path\n",
        "\n",
        "#######################################################\n",
        "\n",
        "import pandas as pd\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names, na_values = \"?\", comment='\\t',  sep=\" \", skipinitialspace=True)\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()\n",
        "\n",
        "#######################################################\n",
        "# 결측치 확인하기\n",
        "dataset.isna().sum()\n",
        "\n",
        "# 결측치 제거하기\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "##############################################\n",
        "\n",
        "# Origin열을 범주형 원-핫 엔코딩 변환\n",
        "origin = dataset.pop('Origin')  # Origin컬럼을 삭제하고 origin에 보관\n",
        "\n",
        "dataset['USA'] = (origin == 1) * 0.1\n",
        "dataset['Europe'] = (origin == 2) * 0.1\n",
        "dataset['Japan'] = (origin == 3) * 0.1\n",
        "\n",
        "\n",
        "##############################################\n",
        "# 80%로 분할하기\n",
        "train_dataset = dataset.sample(frac=0.8, random_state = 0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "train_dataset\n",
        "\n",
        "\n",
        "##############################################\n",
        "# standardscale\n",
        "\n",
        "trans_stats = train_dataset.describe()\n",
        "trans_stats.pop(\"MPG\")  # label에 속하는 항목은 제거\n",
        "trans_stats = trans_stats.transpose()\n",
        "\n",
        "#############################################\n",
        "# train_dataset와 test_dataset에서 MPG항목만 labels로 옮김\n",
        "\n",
        "train_labels = train_dataset.pop(\"MPG\")\n",
        "test_labels = test_dataset.pop(\"MPG\")\n",
        "\n",
        "# train_dataset, train_labels, test_dataset, test_labels\n",
        "############################################\n",
        "# standard scale\n",
        "def norm(x):\n",
        "  return (x-trans_stats['mean']) / trans_stats['std']\n",
        "\n",
        "train_dataset = norm(train_dataset)\n",
        "train_dataset\n",
        "\n",
        "test_dataset = norm(test_dataset)\n",
        "\n",
        "#############################################\n",
        "# 모델 생성\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Dense(64, activation=\"relu\", input_shape=[len(train_dataset.keys())]),\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "###########################################\n",
        "optimizer = tf.keras.optimizers.SGD(lr=0.01)\n",
        "#회귀 : loss:mse로 지표(metrics)는 mae\n",
        "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\", \"mse\"])\n",
        "\n",
        "###########################################\n",
        "#학습하기 1000\n",
        "# validation_split=0.2\n",
        "history = model.fit(train_dataset, train_labels, epochs=1000, validation_split=0.2)\n",
        "\n",
        "history.history.keys()\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 64)                640       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 6,913\n",
            "Trainable params: 6,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 455.2430 - mae: 19.4933 - mse: 455.2430 - val_loss: 183.0893 - val_mae: 11.3550 - val_mse: 183.0893\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 211.9672 - mae: 12.1424 - mse: 211.9672 - val_loss: 262.4534 - val_mae: 14.3894 - val_mse: 262.4534\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 110.9650 - mae: 8.2701 - mse: 110.9650 - val_loss: 15.2026 - val_mae: 3.1352 - val_mse: 15.2026\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 26.6984 - mae: 3.7796 - mse: 26.6984 - val_loss: 18.2353 - val_mae: 3.2639 - val_mse: 18.2353\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 38.4534 - mae: 4.5301 - mse: 38.4534 - val_loss: 19.2280 - val_mae: 3.1339 - val_mse: 19.2280\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 17.9712 - mae: 3.1074 - mse: 17.9712 - val_loss: 17.1886 - val_mae: 3.1485 - val_mse: 17.1886\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 24.6787 - mae: 3.6384 - mse: 24.6787 - val_loss: 13.5966 - val_mae: 2.6520 - val_mse: 13.5966\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 27.1023 - mae: 4.0091 - mse: 27.1023 - val_loss: 13.7037 - val_mae: 2.7937 - val_mse: 13.7037\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.7709 - mae: 2.2813 - mse: 9.7709 - val_loss: 14.8283 - val_mae: 2.9287 - val_mse: 14.8283\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.4054 - mae: 2.4942 - mse: 10.4054 - val_loss: 17.0412 - val_mae: 3.1419 - val_mse: 17.0412\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.0903 - mae: 2.5468 - mse: 12.0903 - val_loss: 16.3907 - val_mae: 3.3023 - val_mse: 16.3907\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 16.4580 - mae: 2.8776 - mse: 16.4580 - val_loss: 8.6797 - val_mae: 2.2526 - val_mse: 8.6797\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.3259 - mae: 1.9784 - mse: 8.3259 - val_loss: 12.8599 - val_mae: 2.8817 - val_mse: 12.8599\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 11.7870 - mae: 2.4488 - mse: 11.7870 - val_loss: 7.3843 - val_mae: 1.9628 - val_mse: 7.3843\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.2142 - mae: 1.9642 - mse: 7.2142 - val_loss: 18.5569 - val_mae: 3.5782 - val_mse: 18.5569\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.9961 - mae: 2.0781 - mse: 7.9961 - val_loss: 8.2227 - val_mae: 2.1789 - val_mse: 8.2227\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.1489 - mae: 2.1638 - mse: 8.1489 - val_loss: 7.1909 - val_mae: 2.0723 - val_mse: 7.1909\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.5505 - mae: 2.0466 - mse: 8.5505 - val_loss: 25.0458 - val_mae: 3.8520 - val_mse: 25.0458\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.1585 - mae: 2.4680 - mse: 12.1585 - val_loss: 7.3361 - val_mae: 1.9560 - val_mse: 7.3361\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.5300 - mae: 2.3919 - mse: 9.5300 - val_loss: 6.8503 - val_mae: 1.9495 - val_mse: 6.8503\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.2444 - mae: 2.3095 - mse: 10.2444 - val_loss: 8.6032 - val_mae: 2.4868 - val_mse: 8.6032\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.9273 - mae: 2.3646 - mse: 9.9273 - val_loss: 7.5343 - val_mae: 2.1004 - val_mse: 7.5343\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.8908 - mae: 2.3242 - mse: 9.8908 - val_loss: 27.1106 - val_mae: 4.2938 - val_mse: 27.1106\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 14.8688 - mae: 2.8523 - mse: 14.8688 - val_loss: 9.2984 - val_mae: 2.5195 - val_mse: 9.2984\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.2667 - mae: 1.7805 - mse: 6.2667 - val_loss: 7.9059 - val_mae: 2.0784 - val_mse: 7.9059\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.0224 - mae: 2.2259 - mse: 10.0224 - val_loss: 25.0657 - val_mae: 4.0289 - val_mse: 25.0657\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.2278 - mae: 3.0820 - mse: 17.2278 - val_loss: 9.7826 - val_mae: 2.4993 - val_mse: 9.7826\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.8413 - mae: 2.2784 - mse: 8.8413 - val_loss: 8.5817 - val_mae: 2.2932 - val_mse: 8.5817\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.3498 - mae: 1.9666 - mse: 7.3498 - val_loss: 14.5845 - val_mae: 3.1740 - val_mse: 14.5845\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.9219 - mae: 2.4451 - mse: 9.9219 - val_loss: 8.8609 - val_mae: 2.3841 - val_mse: 8.8609\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.7555 - mae: 2.4284 - mse: 10.7555 - val_loss: 7.0931 - val_mae: 1.8985 - val_mse: 7.0931\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.3197 - mae: 1.9881 - mse: 7.3197 - val_loss: 7.0102 - val_mae: 1.9696 - val_mse: 7.0102\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.8450 - mae: 1.7693 - mse: 5.8450 - val_loss: 7.4899 - val_mae: 2.0810 - val_mse: 7.4899\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.0172 - mae: 2.0513 - mse: 8.0172 - val_loss: 5.6805 - val_mae: 1.7670 - val_mse: 5.6805\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 11.0459 - mae: 2.5225 - mse: 11.0459 - val_loss: 11.3802 - val_mae: 2.7221 - val_mse: 11.3802\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.7169 - mae: 2.3861 - mse: 9.7169 - val_loss: 8.6286 - val_mae: 2.3317 - val_mse: 8.6286\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.8028 - mae: 2.1104 - mse: 7.8028 - val_loss: 7.4137 - val_mae: 2.1528 - val_mse: 7.4137\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.0942 - mae: 2.2124 - mse: 9.0942 - val_loss: 17.4504 - val_mae: 3.3677 - val_mse: 17.4504\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 12.6110 - mae: 2.6416 - mse: 12.6110 - val_loss: 6.1029 - val_mae: 1.9311 - val_mse: 6.1029\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.0370 - mae: 1.7821 - mse: 6.0370 - val_loss: 5.9687 - val_mae: 1.9058 - val_mse: 5.9687\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.3812 - mae: 1.6931 - mse: 5.3812 - val_loss: 10.9470 - val_mae: 2.6359 - val_mse: 10.9470\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.7412 - mae: 1.7195 - mse: 5.7412 - val_loss: 7.9645 - val_mae: 2.0754 - val_mse: 7.9645\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0052 - mae: 1.9183 - mse: 7.0052 - val_loss: 6.0359 - val_mae: 1.8519 - val_mse: 6.0359\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.9976 - mae: 1.7971 - mse: 5.9976 - val_loss: 16.8069 - val_mae: 3.2220 - val_mse: 16.8069\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 10.4806 - mae: 2.3154 - mse: 10.4806 - val_loss: 6.3797 - val_mae: 1.8442 - val_mse: 6.3797\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8871 - mae: 1.5978 - mse: 4.8871 - val_loss: 6.5074 - val_mae: 1.9224 - val_mse: 6.5074\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5264 - mae: 1.6753 - mse: 5.5264 - val_loss: 12.2078 - val_mae: 2.6590 - val_mse: 12.2078\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 10.5528 - mae: 2.3352 - mse: 10.5528 - val_loss: 6.4867 - val_mae: 1.8825 - val_mse: 6.4867\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 8.9706 - mae: 2.1438 - mse: 8.9706 - val_loss: 5.7156 - val_mae: 1.8604 - val_mse: 5.7156\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 9.4251 - mae: 2.2146 - mse: 9.4251 - val_loss: 8.7087 - val_mae: 2.3616 - val_mse: 8.7087\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.9487 - mae: 1.8966 - mse: 5.9487 - val_loss: 6.4488 - val_mae: 2.0287 - val_mse: 6.4488\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6725 - mae: 1.7117 - mse: 5.6725 - val_loss: 6.8562 - val_mae: 2.0454 - val_mse: 6.8562\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2129 - mae: 1.6740 - mse: 5.2129 - val_loss: 9.9031 - val_mae: 2.5260 - val_mse: 9.9031\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.7323 - mae: 2.2296 - mse: 8.7323 - val_loss: 9.3871 - val_mae: 2.5441 - val_mse: 9.3871\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6248 - mae: 1.8139 - mse: 5.6248 - val_loss: 6.3538 - val_mae: 2.0139 - val_mse: 6.3538\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 7.2435 - mae: 2.0478 - mse: 7.2435 - val_loss: 5.8092 - val_mae: 1.9227 - val_mse: 5.8092\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1945 - mae: 1.7399 - mse: 6.1945 - val_loss: 9.2126 - val_mae: 2.3230 - val_mse: 9.2126\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.1006 - mae: 1.8047 - mse: 6.1006 - val_loss: 6.9038 - val_mae: 1.9492 - val_mse: 6.9038\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0321 - mae: 1.8171 - mse: 7.0321 - val_loss: 35.9302 - val_mae: 4.5123 - val_mse: 35.9302\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 14.1593 - mae: 2.7246 - mse: 14.1593 - val_loss: 6.8312 - val_mae: 2.0588 - val_mse: 6.8312\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5223 - mae: 1.8648 - mse: 6.5223 - val_loss: 6.6082 - val_mae: 2.1108 - val_mse: 6.6082\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.1391 - mae: 1.7322 - mse: 6.1391 - val_loss: 7.1386 - val_mae: 2.1960 - val_mse: 7.1386\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.3655 - mae: 1.6845 - mse: 5.3655 - val_loss: 10.9438 - val_mae: 2.4313 - val_mse: 10.9438\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.4840 - mae: 1.8585 - mse: 6.4840 - val_loss: 5.9263 - val_mae: 1.8666 - val_mse: 5.9263\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6189 - mae: 1.7875 - mse: 5.6189 - val_loss: 6.5954 - val_mae: 2.0219 - val_mse: 6.5954\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8164 - mae: 1.5921 - mse: 4.8164 - val_loss: 8.2721 - val_mae: 2.3269 - val_mse: 8.2721\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9786 - mae: 1.6329 - mse: 4.9786 - val_loss: 6.0550 - val_mae: 1.8777 - val_mse: 6.0550\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.4781 - mae: 1.5271 - mse: 4.4781 - val_loss: 7.0177 - val_mae: 2.0530 - val_mse: 7.0177\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9305 - mae: 1.6112 - mse: 4.9305 - val_loss: 5.2677 - val_mae: 1.7284 - val_mse: 5.2677\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0402 - mae: 1.5993 - mse: 5.0402 - val_loss: 6.5583 - val_mae: 2.0270 - val_mse: 6.5583\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 6.3008 - mae: 1.8253 - mse: 6.3008 - val_loss: 9.2511 - val_mae: 2.3110 - val_mse: 9.2511\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1042 - mae: 1.6466 - mse: 5.1042 - val_loss: 5.9316 - val_mae: 1.8839 - val_mse: 5.9316\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.5626 - mae: 1.9837 - mse: 6.5626 - val_loss: 8.4783 - val_mae: 2.3232 - val_mse: 8.4783\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.9351 - mae: 2.0134 - mse: 6.9351 - val_loss: 7.3436 - val_mae: 2.3188 - val_mse: 7.3436\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.6724 - mae: 1.7781 - mse: 5.6724 - val_loss: 5.2215 - val_mae: 1.7073 - val_mse: 5.2215\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.2564 - mae: 1.4649 - mse: 4.2564 - val_loss: 8.9712 - val_mae: 2.3644 - val_mse: 8.9712\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8625 - mae: 1.6569 - mse: 4.8625 - val_loss: 6.1277 - val_mae: 1.9671 - val_mse: 6.1277\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 12.3199 - mae: 2.4270 - mse: 12.3199 - val_loss: 9.7243 - val_mae: 2.4815 - val_mse: 9.7243\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.6974 - mae: 1.7578 - mse: 5.6974 - val_loss: 10.1837 - val_mae: 2.5849 - val_mse: 10.1837\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7461 - mae: 1.7745 - mse: 5.7461 - val_loss: 9.8384 - val_mae: 2.5462 - val_mse: 9.8384\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.3420 - mae: 1.5719 - mse: 4.3420 - val_loss: 7.7660 - val_mae: 2.1166 - val_mse: 7.7660\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.1858 - mae: 1.6635 - mse: 5.1858 - val_loss: 11.9856 - val_mae: 2.8828 - val_mse: 11.9856\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2073 - mae: 1.8861 - mse: 6.2073 - val_loss: 8.1805 - val_mae: 2.1239 - val_mse: 8.1805\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0750 - mae: 1.7118 - mse: 5.0750 - val_loss: 6.0550 - val_mae: 1.9065 - val_mse: 6.0550\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.1627 - mae: 1.4874 - mse: 4.1627 - val_loss: 9.4834 - val_mae: 2.4580 - val_mse: 9.4834\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.8103 - mae: 1.6269 - mse: 4.8103 - val_loss: 6.2559 - val_mae: 1.8905 - val_mse: 6.2559\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.8311 - mae: 1.4131 - mse: 3.8311 - val_loss: 6.8678 - val_mae: 2.0732 - val_mse: 6.8678\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.6009 - mae: 1.3295 - mse: 3.6009 - val_loss: 6.4445 - val_mae: 2.0102 - val_mse: 6.4445\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.9621 - mae: 1.4385 - mse: 3.9621 - val_loss: 11.0887 - val_mae: 2.6986 - val_mse: 11.0887\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.1529 - mae: 1.5188 - mse: 4.1529 - val_loss: 5.8426 - val_mae: 1.8404 - val_mse: 5.8426\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5250 - mae: 1.5470 - mse: 4.5250 - val_loss: 5.8586 - val_mae: 1.8493 - val_mse: 5.8586\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5781 - mae: 1.5978 - mse: 4.5781 - val_loss: 7.0765 - val_mae: 2.0041 - val_mse: 7.0765\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.2444 - mae: 1.7385 - mse: 5.2444 - val_loss: 6.6096 - val_mae: 2.0082 - val_mse: 6.6096\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4119 - mae: 1.3157 - mse: 3.4119 - val_loss: 6.6222 - val_mae: 1.9704 - val_mse: 6.6222\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.9187 - mae: 1.4708 - mse: 3.9187 - val_loss: 7.9089 - val_mae: 2.1482 - val_mse: 7.9089\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.2834 - mae: 1.5473 - mse: 4.2834 - val_loss: 6.5311 - val_mae: 2.0325 - val_mse: 6.5311\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.0821 - mae: 1.4390 - mse: 4.0821 - val_loss: 6.1412 - val_mae: 1.9190 - val_mse: 6.1412\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6445 - mae: 1.4617 - mse: 4.6445 - val_loss: 15.9793 - val_mae: 3.3241 - val_mse: 15.9793\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.0820 - mae: 2.0340 - mse: 7.0820 - val_loss: 7.6347 - val_mae: 2.2553 - val_mse: 7.6347\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.1963 - mae: 1.6912 - mse: 5.1963 - val_loss: 6.1958 - val_mae: 1.9279 - val_mse: 6.1958\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.0857 - mae: 1.5935 - mse: 5.0857 - val_loss: 5.9099 - val_mae: 1.8831 - val_mse: 5.9099\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7172 - mae: 1.6417 - mse: 4.7172 - val_loss: 5.8038 - val_mae: 1.8434 - val_mse: 5.8038\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.1346 - mae: 1.2833 - mse: 3.1346 - val_loss: 8.2469 - val_mae: 2.3543 - val_mse: 8.2469\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5805 - mae: 1.6349 - mse: 4.5805 - val_loss: 7.4959 - val_mae: 2.2533 - val_mse: 7.4959\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2998 - mae: 1.9855 - mse: 6.2998 - val_loss: 6.6434 - val_mae: 2.0632 - val_mse: 6.6434\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.1646 - mae: 1.2696 - mse: 3.1646 - val_loss: 8.5938 - val_mae: 2.3329 - val_mse: 8.5938\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6779 - mae: 1.5503 - mse: 4.6779 - val_loss: 6.1928 - val_mae: 1.9636 - val_mse: 6.1928\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3483 - mae: 1.3115 - mse: 3.3483 - val_loss: 6.1705 - val_mae: 1.9481 - val_mse: 6.1705\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.8376 - mae: 1.3700 - mse: 3.8376 - val_loss: 8.0976 - val_mae: 2.2347 - val_mse: 8.0976\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7148 - mae: 1.7187 - mse: 4.7148 - val_loss: 8.8244 - val_mae: 2.1833 - val_mse: 8.8244\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.5023 - mae: 2.1679 - mse: 7.5023 - val_loss: 7.5990 - val_mae: 2.2332 - val_mse: 7.5990\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.2031 - mae: 1.5504 - mse: 4.2031 - val_loss: 8.4608 - val_mae: 2.2158 - val_mse: 8.4608\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.3425 - mae: 1.3595 - mse: 3.3425 - val_loss: 5.7845 - val_mae: 1.8923 - val_mse: 5.7845\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.3480 - mae: 1.3163 - mse: 3.3480 - val_loss: 5.7525 - val_mae: 1.8287 - val_mse: 5.7525\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.9777 - mae: 1.6512 - mse: 4.9777 - val_loss: 5.7226 - val_mae: 1.8296 - val_mse: 5.7226\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5105 - mae: 1.5020 - mse: 4.5105 - val_loss: 5.9628 - val_mae: 1.9246 - val_mse: 5.9628\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.7702 - mae: 1.4446 - mse: 3.7702 - val_loss: 5.8273 - val_mae: 1.8621 - val_mse: 5.8273\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.9093 - mae: 1.9867 - mse: 6.9093 - val_loss: 10.2920 - val_mae: 2.6534 - val_mse: 10.2920\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.6680 - mae: 1.9937 - mse: 6.6680 - val_loss: 6.2465 - val_mae: 1.9403 - val_mse: 6.2465\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.3368 - mae: 1.5228 - mse: 4.3368 - val_loss: 8.4506 - val_mae: 2.3501 - val_mse: 8.4506\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.8972 - mae: 1.4536 - mse: 3.8972 - val_loss: 6.0759 - val_mae: 1.8470 - val_mse: 6.0759\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1826 - mae: 1.5062 - mse: 4.1826 - val_loss: 5.6729 - val_mae: 1.8996 - val_mse: 5.6729\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2447 - mae: 1.3077 - mse: 3.2447 - val_loss: 8.6036 - val_mae: 2.3038 - val_mse: 8.6036\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3359 - mae: 1.6428 - mse: 4.3359 - val_loss: 6.4598 - val_mae: 2.0087 - val_mse: 6.4598\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.6483 - mae: 1.4215 - mse: 3.6483 - val_loss: 6.0814 - val_mae: 1.9535 - val_mse: 6.0814\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3579 - mae: 1.5460 - mse: 4.3579 - val_loss: 6.0109 - val_mae: 1.9033 - val_mse: 6.0109\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8606 - mae: 1.1746 - mse: 2.8606 - val_loss: 7.9138 - val_mae: 2.2825 - val_mse: 7.9138\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.9067 - mae: 1.4773 - mse: 3.9067 - val_loss: 6.7943 - val_mae: 2.0094 - val_mse: 6.7943\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5772 - mae: 1.1281 - mse: 2.5772 - val_loss: 5.9946 - val_mae: 1.9046 - val_mse: 5.9946\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5561 - mae: 1.3507 - mse: 3.5561 - val_loss: 5.6463 - val_mae: 1.8288 - val_mse: 5.6463\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5373 - mae: 1.3339 - mse: 3.5373 - val_loss: 6.8516 - val_mae: 1.9546 - val_mse: 6.8516\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9256 - mae: 1.2160 - mse: 2.9256 - val_loss: 6.2261 - val_mae: 1.9457 - val_mse: 6.2261\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.7092 - mae: 1.4381 - mse: 3.7092 - val_loss: 9.5930 - val_mae: 2.5169 - val_mse: 9.5930\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.0143 - mae: 1.5285 - mse: 4.0143 - val_loss: 8.1589 - val_mae: 2.2712 - val_mse: 8.1589\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4321 - mae: 1.3938 - mse: 3.4321 - val_loss: 5.5277 - val_mae: 1.7986 - val_mse: 5.5277\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9893 - mae: 1.2390 - mse: 2.9893 - val_loss: 6.9493 - val_mae: 2.0901 - val_mse: 6.9493\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.5091 - mae: 1.7998 - mse: 5.5091 - val_loss: 13.4478 - val_mae: 2.8710 - val_mse: 13.4478\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.7930 - mae: 1.6371 - mse: 4.7930 - val_loss: 6.8345 - val_mae: 1.9672 - val_mse: 6.8345\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8624 - mae: 1.2248 - mse: 2.8624 - val_loss: 5.7538 - val_mae: 1.8454 - val_mse: 5.7538\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.7139 - mae: 1.1894 - mse: 2.7139 - val_loss: 6.3488 - val_mae: 1.9423 - val_mse: 6.3488\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.3607 - mae: 1.6373 - mse: 4.3607 - val_loss: 6.7472 - val_mae: 2.1195 - val_mse: 6.7472\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.6576 - mae: 1.4274 - mse: 3.6576 - val_loss: 6.2590 - val_mae: 1.9545 - val_mse: 6.2590\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.5359 - mae: 1.3861 - mse: 3.5359 - val_loss: 6.1823 - val_mae: 1.8857 - val_mse: 6.1823\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.7293 - mae: 1.4010 - mse: 3.7293 - val_loss: 7.8208 - val_mae: 2.1773 - val_mse: 7.8208\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.7900 - mae: 1.1972 - mse: 2.7900 - val_loss: 7.0104 - val_mae: 2.0882 - val_mse: 7.0104\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.3669 - mae: 1.6037 - mse: 4.3669 - val_loss: 7.0250 - val_mae: 1.9319 - val_mse: 7.0250\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.7250 - mae: 1.3991 - mse: 3.7250 - val_loss: 11.1248 - val_mae: 2.5090 - val_mse: 11.1248\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.8634 - mae: 2.2672 - mse: 7.8634 - val_loss: 8.6173 - val_mae: 2.3240 - val_mse: 8.6173\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.7901 - mae: 1.3585 - mse: 3.7901 - val_loss: 5.9551 - val_mae: 1.8779 - val_mse: 5.9551\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.7559 - mae: 1.1903 - mse: 2.7559 - val_loss: 6.5853 - val_mae: 2.0191 - val_mse: 6.5853\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5956 - mae: 1.1987 - mse: 2.5956 - val_loss: 6.6684 - val_mae: 1.9648 - val_mse: 6.6684\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.2343 - mae: 1.3045 - mse: 3.2343 - val_loss: 10.0648 - val_mae: 2.5310 - val_mse: 10.0648\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.0142 - mae: 1.7254 - mse: 5.0142 - val_loss: 6.4126 - val_mae: 1.8950 - val_mse: 6.4126\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5306 - mae: 1.1136 - mse: 2.5306 - val_loss: 6.7602 - val_mae: 2.0218 - val_mse: 6.7602\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2272 - mae: 1.0477 - mse: 2.2272 - val_loss: 7.7050 - val_mae: 2.1618 - val_mse: 7.7050\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5130 - mae: 1.1301 - mse: 2.5130 - val_loss: 7.2682 - val_mae: 2.1450 - val_mse: 7.2682\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.7146 - mae: 1.4150 - mse: 3.7146 - val_loss: 7.4949 - val_mae: 2.0887 - val_mse: 7.4949\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.7143 - mae: 1.2170 - mse: 2.7143 - val_loss: 7.2705 - val_mae: 2.0869 - val_mse: 7.2705\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.2614 - mae: 1.3055 - mse: 3.2614 - val_loss: 6.7487 - val_mae: 2.0261 - val_mse: 6.7487\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6240 - mae: 1.1631 - mse: 2.6240 - val_loss: 11.7765 - val_mae: 2.7328 - val_mse: 11.7765\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.2702 - mae: 1.3606 - mse: 3.2702 - val_loss: 6.8980 - val_mae: 2.0286 - val_mse: 6.8980\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5742 - mae: 1.1587 - mse: 2.5742 - val_loss: 7.4837 - val_mae: 2.1171 - val_mse: 7.4837\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8524 - mae: 1.2847 - mse: 2.8524 - val_loss: 7.3408 - val_mae: 2.1052 - val_mse: 7.3408\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.6238 - mae: 1.1875 - mse: 2.6238 - val_loss: 7.2303 - val_mae: 2.0448 - val_mse: 7.2303\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1554 - mae: 1.0471 - mse: 2.1554 - val_loss: 6.4741 - val_mae: 1.9145 - val_mse: 6.4741\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5874 - mae: 1.0761 - mse: 2.5874 - val_loss: 6.3254 - val_mae: 1.8955 - val_mse: 6.3254\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2267 - mae: 1.5691 - mse: 4.2267 - val_loss: 8.5192 - val_mae: 2.4167 - val_mse: 8.5192\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.7643 - mae: 1.6719 - mse: 4.7643 - val_loss: 7.4311 - val_mae: 2.1620 - val_mse: 7.4311\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3325 - mae: 1.0847 - mse: 2.3325 - val_loss: 7.1846 - val_mae: 2.0579 - val_mse: 7.1846\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6379 - mae: 1.1868 - mse: 2.6379 - val_loss: 7.2601 - val_mae: 2.1878 - val_mse: 7.2601\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5484 - mae: 1.1971 - mse: 2.5484 - val_loss: 5.8841 - val_mae: 1.8497 - val_mse: 5.8841\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.2960 - mae: 1.3119 - mse: 3.2960 - val_loss: 6.7939 - val_mae: 2.0500 - val_mse: 6.7939\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2172 - mae: 1.3085 - mse: 3.2172 - val_loss: 5.8890 - val_mae: 1.8866 - val_mse: 5.8890\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.4866 - mae: 1.1528 - mse: 2.4866 - val_loss: 7.9709 - val_mae: 2.2455 - val_mse: 7.9709\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.9183 - mae: 1.4020 - mse: 3.9183 - val_loss: 8.9126 - val_mae: 2.4378 - val_mse: 8.9126\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.8263 - mae: 1.6160 - mse: 4.8263 - val_loss: 7.3103 - val_mae: 2.0999 - val_mse: 7.3103\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.6639 - mae: 1.1723 - mse: 2.6639 - val_loss: 6.6578 - val_mae: 1.9624 - val_mse: 6.6578\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.2496 - mae: 1.3441 - mse: 3.2496 - val_loss: 6.9802 - val_mae: 2.0973 - val_mse: 6.9802\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6282 - mae: 1.2236 - mse: 2.6282 - val_loss: 7.9940 - val_mae: 2.2592 - val_mse: 7.9940\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5929 - mae: 1.1288 - mse: 2.5929 - val_loss: 6.2890 - val_mae: 1.9192 - val_mse: 6.2890\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.4155 - mae: 1.1246 - mse: 2.4155 - val_loss: 8.2130 - val_mae: 2.3921 - val_mse: 8.2130\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6035 - mae: 1.1364 - mse: 2.6035 - val_loss: 6.2317 - val_mae: 1.9228 - val_mse: 6.2317\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9530 - mae: 0.9805 - mse: 1.9530 - val_loss: 8.8767 - val_mae: 2.3791 - val_mse: 8.8767\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5638 - mae: 1.1999 - mse: 2.5638 - val_loss: 7.0788 - val_mae: 2.0619 - val_mse: 7.0788\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9492 - mae: 1.2524 - mse: 2.9492 - val_loss: 7.0914 - val_mae: 2.1546 - val_mse: 7.0914\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.4463 - mae: 1.3747 - mse: 3.4463 - val_loss: 7.0103 - val_mae: 2.0583 - val_mse: 7.0103\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.4461 - mae: 1.1513 - mse: 2.4461 - val_loss: 6.9439 - val_mae: 2.0447 - val_mse: 6.9439\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.5508 - mae: 1.3610 - mse: 3.5508 - val_loss: 8.3915 - val_mae: 2.1964 - val_mse: 8.3915\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5468 - mae: 1.1415 - mse: 2.5468 - val_loss: 6.9126 - val_mae: 2.0964 - val_mse: 6.9126\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4439 - mae: 1.4119 - mse: 3.4439 - val_loss: 7.3895 - val_mae: 2.0625 - val_mse: 7.3895\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.4893 - mae: 1.0835 - mse: 2.4893 - val_loss: 9.1871 - val_mae: 2.3516 - val_mse: 9.1871\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1441 - mae: 1.0296 - mse: 2.1441 - val_loss: 6.5303 - val_mae: 1.9933 - val_mse: 6.5303\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8647 - mae: 0.9837 - mse: 1.8647 - val_loss: 7.5986 - val_mae: 2.1055 - val_mse: 7.5986\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3354 - mae: 1.1087 - mse: 2.3354 - val_loss: 7.0087 - val_mae: 2.0462 - val_mse: 7.0087\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.7284 - mae: 1.1337 - mse: 2.7284 - val_loss: 5.9251 - val_mae: 1.9423 - val_mse: 5.9251\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1170 - mae: 0.9955 - mse: 2.1170 - val_loss: 7.8318 - val_mae: 2.0502 - val_mse: 7.8318\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5091 - mae: 1.1058 - mse: 2.5091 - val_loss: 5.8361 - val_mae: 1.8772 - val_mse: 5.8361\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1452 - mae: 0.9868 - mse: 2.1452 - val_loss: 8.0519 - val_mae: 2.2426 - val_mse: 8.0519\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6537 - mae: 1.1699 - mse: 2.6537 - val_loss: 6.2975 - val_mae: 1.9605 - val_mse: 6.2975\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9477 - mae: 0.9954 - mse: 1.9477 - val_loss: 6.4077 - val_mae: 2.0280 - val_mse: 6.4077\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6891 - mae: 1.2214 - mse: 2.6891 - val_loss: 6.4369 - val_mae: 1.9394 - val_mse: 6.4369\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5058 - mae: 1.1938 - mse: 2.5058 - val_loss: 7.1241 - val_mae: 2.0936 - val_mse: 7.1241\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3081 - mae: 1.0721 - mse: 2.3081 - val_loss: 8.3595 - val_mae: 2.1717 - val_mse: 8.3595\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8776 - mae: 1.1707 - mse: 2.8776 - val_loss: 7.5762 - val_mae: 2.1756 - val_mse: 7.5762\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.2226 - mae: 1.3848 - mse: 3.2226 - val_loss: 6.3592 - val_mae: 1.9894 - val_mse: 6.3592\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0734 - mae: 1.0193 - mse: 2.0734 - val_loss: 6.9759 - val_mae: 2.0673 - val_mse: 6.9759\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8868 - mae: 0.9456 - mse: 1.8868 - val_loss: 6.0783 - val_mae: 1.9057 - val_mse: 6.0783\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3499 - mae: 1.0658 - mse: 2.3499 - val_loss: 7.9082 - val_mae: 2.2810 - val_mse: 7.9082\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.8988 - mae: 1.5246 - mse: 3.8988 - val_loss: 16.7784 - val_mae: 3.3401 - val_mse: 16.7784\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.7020 - mae: 1.3750 - mse: 3.7020 - val_loss: 6.7625 - val_mae: 2.0106 - val_mse: 6.7625\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5902 - mae: 1.3926 - mse: 3.5902 - val_loss: 6.5812 - val_mae: 1.9867 - val_mse: 6.5812\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 4.1853 - mae: 1.6399 - mse: 4.1853 - val_loss: 9.2473 - val_mae: 2.5208 - val_mse: 9.2473\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5252 - mae: 1.3733 - mse: 3.5252 - val_loss: 7.3812 - val_mae: 2.0644 - val_mse: 7.3812\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5976 - mae: 1.1853 - mse: 2.5976 - val_loss: 6.5840 - val_mae: 1.9719 - val_mse: 6.5840\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2323 - mae: 1.0414 - mse: 2.2323 - val_loss: 6.2141 - val_mae: 1.9106 - val_mse: 6.2141\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1074 - mae: 1.0122 - mse: 2.1074 - val_loss: 6.8075 - val_mae: 2.0548 - val_mse: 6.8075\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9844 - mae: 0.9470 - mse: 1.9844 - val_loss: 5.9244 - val_mae: 1.9162 - val_mse: 5.9244\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1651 - mae: 1.0445 - mse: 2.1651 - val_loss: 7.7510 - val_mae: 2.1567 - val_mse: 7.7510\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1255 - mae: 1.0943 - mse: 2.1255 - val_loss: 6.6936 - val_mae: 2.0343 - val_mse: 6.6936\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1418 - mae: 1.0430 - mse: 2.1418 - val_loss: 6.7545 - val_mae: 2.0648 - val_mse: 6.7545\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3040 - mae: 1.0305 - mse: 2.3040 - val_loss: 9.4733 - val_mae: 2.5374 - val_mse: 9.4733\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.6338 - mae: 1.1826 - mse: 2.6338 - val_loss: 7.3823 - val_mae: 2.1581 - val_mse: 7.3823\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.3572 - mae: 1.3968 - mse: 3.3572 - val_loss: 6.1633 - val_mae: 1.9945 - val_mse: 6.1633\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.5911 - mae: 1.7778 - mse: 5.5911 - val_loss: 7.0139 - val_mae: 1.9998 - val_mse: 7.0139\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3111 - mae: 1.0607 - mse: 2.3111 - val_loss: 7.1290 - val_mae: 2.0812 - val_mse: 7.1290\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0227 - mae: 0.9957 - mse: 2.0227 - val_loss: 7.6224 - val_mae: 2.1577 - val_mse: 7.6224\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2890 - mae: 1.1287 - mse: 2.2890 - val_loss: 7.3205 - val_mae: 2.0354 - val_mse: 7.3205\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7603 - mae: 0.9285 - mse: 1.7603 - val_loss: 6.8670 - val_mae: 2.0627 - val_mse: 6.8670\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7835 - mae: 0.9073 - mse: 1.7835 - val_loss: 7.2607 - val_mae: 2.1135 - val_mse: 7.2607\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8909 - mae: 1.0006 - mse: 1.8909 - val_loss: 9.0565 - val_mae: 2.4353 - val_mse: 9.0565\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6502 - mae: 1.1915 - mse: 2.6502 - val_loss: 8.1577 - val_mae: 2.2555 - val_mse: 8.1577\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7923 - mae: 0.9334 - mse: 1.7923 - val_loss: 6.7313 - val_mae: 2.1052 - val_mse: 6.7313\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8616 - mae: 0.9396 - mse: 1.8616 - val_loss: 6.3254 - val_mae: 1.9311 - val_mse: 6.3254\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2858 - mae: 1.1127 - mse: 2.2858 - val_loss: 7.0975 - val_mae: 2.0351 - val_mse: 7.0975\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7845 - mae: 0.9193 - mse: 1.7845 - val_loss: 7.9557 - val_mae: 2.3367 - val_mse: 7.9557\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5964 - mae: 1.1375 - mse: 2.5964 - val_loss: 6.4634 - val_mae: 1.9668 - val_mse: 6.4634\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5794 - mae: 1.5565 - mse: 4.5794 - val_loss: 8.2909 - val_mae: 2.2761 - val_mse: 8.2909\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5382 - mae: 1.3161 - mse: 3.5382 - val_loss: 6.7407 - val_mae: 2.0306 - val_mse: 6.7407\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5903 - mae: 1.1475 - mse: 2.5903 - val_loss: 12.3158 - val_mae: 2.8184 - val_mse: 12.3158\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.6058 - mae: 2.3112 - mse: 8.6058 - val_loss: 8.7457 - val_mae: 2.2722 - val_mse: 8.7457\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5744 - mae: 1.1518 - mse: 2.5744 - val_loss: 6.9047 - val_mae: 2.0788 - val_mse: 6.9047\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8813 - mae: 0.9307 - mse: 1.8813 - val_loss: 7.0077 - val_mae: 2.0762 - val_mse: 7.0077\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8925 - mae: 0.9547 - mse: 1.8925 - val_loss: 10.2405 - val_mae: 2.4449 - val_mse: 10.2405\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5898 - mae: 1.2032 - mse: 2.5898 - val_loss: 7.8829 - val_mae: 2.1160 - val_mse: 7.8829\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.7914 - mae: 1.2755 - mse: 2.7914 - val_loss: 6.4498 - val_mae: 1.9560 - val_mse: 6.4498\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.7195 - mae: 1.2817 - mse: 2.7195 - val_loss: 8.1482 - val_mae: 2.2133 - val_mse: 8.1482\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0844 - mae: 1.0582 - mse: 2.0844 - val_loss: 6.2896 - val_mae: 1.9571 - val_mse: 6.2896\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1759 - mae: 1.0366 - mse: 2.1759 - val_loss: 6.8739 - val_mae: 2.0824 - val_mse: 6.8739\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9374 - mae: 0.9604 - mse: 1.9374 - val_loss: 7.2282 - val_mae: 2.1228 - val_mse: 7.2282\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6926 - mae: 0.9327 - mse: 1.6926 - val_loss: 6.3106 - val_mae: 1.9416 - val_mse: 6.3106\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7974 - mae: 0.9027 - mse: 1.7974 - val_loss: 8.0292 - val_mae: 2.2373 - val_mse: 8.0292\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.9325 - mae: 1.2635 - mse: 2.9325 - val_loss: 6.8571 - val_mae: 2.0051 - val_mse: 6.8571\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8072 - mae: 0.9334 - mse: 1.8072 - val_loss: 7.5298 - val_mae: 2.1382 - val_mse: 7.5298\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6709 - mae: 0.8748 - mse: 1.6709 - val_loss: 6.7664 - val_mae: 2.0905 - val_mse: 6.7664\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1125 - mae: 1.0251 - mse: 2.1125 - val_loss: 6.6175 - val_mae: 1.9948 - val_mse: 6.6175\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6183 - mae: 0.8326 - mse: 1.6183 - val_loss: 7.0565 - val_mae: 2.0963 - val_mse: 7.0565\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9900 - mae: 0.9646 - mse: 1.9900 - val_loss: 7.2741 - val_mae: 2.1406 - val_mse: 7.2741\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7507 - mae: 0.9084 - mse: 1.7507 - val_loss: 6.6092 - val_mae: 2.0560 - val_mse: 6.6092\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1222 - mae: 1.0597 - mse: 2.1222 - val_loss: 6.8147 - val_mae: 2.0279 - val_mse: 6.8147\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5153 - mae: 0.8377 - mse: 1.5153 - val_loss: 7.3141 - val_mae: 2.1582 - val_mse: 7.3141\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4693 - mae: 0.8184 - mse: 1.4693 - val_loss: 6.9969 - val_mae: 2.1075 - val_mse: 6.9969\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5967 - mae: 0.9143 - mse: 1.5967 - val_loss: 5.7654 - val_mae: 1.9167 - val_mse: 5.7654\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8373 - mae: 0.9661 - mse: 1.8373 - val_loss: 7.0905 - val_mae: 2.0807 - val_mse: 7.0905\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0730 - mae: 0.9570 - mse: 2.0730 - val_loss: 6.2071 - val_mae: 2.0240 - val_mse: 6.2071\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6144 - mae: 1.1138 - mse: 2.6144 - val_loss: 8.2969 - val_mae: 2.2856 - val_mse: 8.2969\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1949 - mae: 1.0589 - mse: 2.1949 - val_loss: 7.5341 - val_mae: 2.1013 - val_mse: 7.5341\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8104 - mae: 0.9521 - mse: 1.8104 - val_loss: 7.3631 - val_mae: 2.1028 - val_mse: 7.3631\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5129 - mae: 0.8269 - mse: 1.5129 - val_loss: 7.2602 - val_mae: 2.2022 - val_mse: 7.2602\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9886 - mae: 0.9756 - mse: 1.9886 - val_loss: 6.3671 - val_mae: 1.9863 - val_mse: 6.3671\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2127 - mae: 1.0864 - mse: 2.2127 - val_loss: 7.5547 - val_mae: 2.0846 - val_mse: 7.5547\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6402 - mae: 0.8993 - mse: 1.6402 - val_loss: 7.7516 - val_mae: 2.2244 - val_mse: 7.7516\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1264 - mae: 0.9338 - mse: 2.1264 - val_loss: 9.2119 - val_mae: 2.5689 - val_mse: 9.2119\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0849 - mae: 1.0343 - mse: 2.0849 - val_loss: 6.7675 - val_mae: 2.0343 - val_mse: 6.7675\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6637 - mae: 0.8763 - mse: 1.6637 - val_loss: 7.1190 - val_mae: 2.1256 - val_mse: 7.1190\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5950 - mae: 0.9130 - mse: 1.5950 - val_loss: 6.6729 - val_mae: 2.0683 - val_mse: 6.6729\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4691 - mae: 0.8161 - mse: 1.4691 - val_loss: 7.8413 - val_mae: 2.1846 - val_mse: 7.8413\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0802 - mae: 1.0414 - mse: 2.0802 - val_loss: 7.2127 - val_mae: 2.1566 - val_mse: 7.2127\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9526 - mae: 0.9270 - mse: 1.9526 - val_loss: 7.6102 - val_mae: 2.2533 - val_mse: 7.6102\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0194 - mae: 0.9582 - mse: 2.0194 - val_loss: 7.6582 - val_mae: 2.1441 - val_mse: 7.6582\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.0884 - mae: 1.3530 - mse: 3.0884 - val_loss: 7.2563 - val_mae: 2.1034 - val_mse: 7.2563\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6583 - mae: 0.8922 - mse: 1.6583 - val_loss: 7.3151 - val_mae: 2.0732 - val_mse: 7.3151\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1664 - mae: 1.0012 - mse: 2.1664 - val_loss: 8.8528 - val_mae: 2.3474 - val_mse: 8.8528\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0385 - mae: 0.9825 - mse: 2.0385 - val_loss: 7.0239 - val_mae: 2.0679 - val_mse: 7.0239\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7629 - mae: 0.9408 - mse: 1.7629 - val_loss: 6.3967 - val_mae: 1.9402 - val_mse: 6.3967\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9689 - mae: 1.0056 - mse: 1.9689 - val_loss: 7.1244 - val_mae: 2.0434 - val_mse: 7.1244\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8876 - mae: 0.9553 - mse: 1.8876 - val_loss: 6.8025 - val_mae: 2.0413 - val_mse: 6.8025\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5245 - mae: 0.8225 - mse: 1.5245 - val_loss: 7.3626 - val_mae: 2.1489 - val_mse: 7.3626\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7009 - mae: 0.8734 - mse: 1.7009 - val_loss: 8.9014 - val_mae: 2.3131 - val_mse: 8.9014\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.0588 - mae: 1.3376 - mse: 3.0588 - val_loss: 6.7094 - val_mae: 2.0611 - val_mse: 6.7094\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9761 - mae: 0.9772 - mse: 1.9761 - val_loss: 8.6844 - val_mae: 2.3046 - val_mse: 8.6844\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0053 - mae: 0.9879 - mse: 2.0053 - val_loss: 6.9449 - val_mae: 2.0807 - val_mse: 6.9449\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3718 - mae: 1.0946 - mse: 2.3718 - val_loss: 8.9327 - val_mae: 2.4419 - val_mse: 8.9327\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3395 - mae: 1.0536 - mse: 2.3395 - val_loss: 10.6395 - val_mae: 2.5498 - val_mse: 10.6395\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3896 - mae: 1.1204 - mse: 2.3896 - val_loss: 6.7574 - val_mae: 2.0823 - val_mse: 6.7574\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6465 - mae: 0.8408 - mse: 1.6465 - val_loss: 7.2512 - val_mae: 2.1168 - val_mse: 7.2512\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7293 - mae: 0.9134 - mse: 1.7293 - val_loss: 7.3792 - val_mae: 2.1087 - val_mse: 7.3792\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1009 - mae: 1.0519 - mse: 2.1009 - val_loss: 6.2909 - val_mae: 1.9926 - val_mse: 6.2909\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5571 - mae: 0.8241 - mse: 1.5571 - val_loss: 6.8590 - val_mae: 2.0807 - val_mse: 6.8590\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8568 - mae: 0.9409 - mse: 1.8568 - val_loss: 7.1031 - val_mae: 2.1215 - val_mse: 7.1031\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6589 - mae: 0.8569 - mse: 1.6589 - val_loss: 8.1102 - val_mae: 2.2394 - val_mse: 8.1102\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.4676 - mae: 1.1942 - mse: 2.4676 - val_loss: 7.0131 - val_mae: 2.0906 - val_mse: 7.0131\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9845 - mae: 1.0807 - mse: 1.9845 - val_loss: 8.0048 - val_mae: 2.2003 - val_mse: 8.0048\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1771 - mae: 1.0874 - mse: 2.1771 - val_loss: 7.0122 - val_mae: 2.1160 - val_mse: 7.0122\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6836 - mae: 0.8913 - mse: 1.6836 - val_loss: 6.8520 - val_mae: 2.1068 - val_mse: 6.8520\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5794 - mae: 0.8512 - mse: 1.5794 - val_loss: 7.3852 - val_mae: 2.1512 - val_mse: 7.3852\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5404 - mae: 0.8652 - mse: 1.5404 - val_loss: 6.6814 - val_mae: 2.0486 - val_mse: 6.6814\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6084 - mae: 0.8755 - mse: 1.6084 - val_loss: 6.9484 - val_mae: 2.1173 - val_mse: 6.9484\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8120 - mae: 0.8762 - mse: 1.8120 - val_loss: 7.2642 - val_mae: 2.1443 - val_mse: 7.2642\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5364 - mae: 0.8432 - mse: 1.5364 - val_loss: 6.5733 - val_mae: 2.0373 - val_mse: 6.5733\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5038 - mae: 0.8265 - mse: 1.5038 - val_loss: 7.2428 - val_mae: 2.1696 - val_mse: 7.2428\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6472 - mae: 0.9185 - mse: 1.6472 - val_loss: 6.9444 - val_mae: 2.1168 - val_mse: 6.9444\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6467 - mae: 0.8644 - mse: 1.6467 - val_loss: 7.3783 - val_mae: 2.1305 - val_mse: 7.3783\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0903 - mae: 1.0168 - mse: 2.0903 - val_loss: 6.7431 - val_mae: 2.0451 - val_mse: 6.7431\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9447 - mae: 0.9360 - mse: 1.9447 - val_loss: 7.9061 - val_mae: 2.2309 - val_mse: 7.9061\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7007 - mae: 0.9038 - mse: 1.7007 - val_loss: 6.5822 - val_mae: 2.0502 - val_mse: 6.5822\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.4203 - mae: 1.0201 - mse: 2.4203 - val_loss: 6.6715 - val_mae: 2.0620 - val_mse: 6.6715\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8987 - mae: 0.9565 - mse: 1.8987 - val_loss: 6.6076 - val_mae: 2.0172 - val_mse: 6.6076\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0869 - mae: 1.0163 - mse: 2.0869 - val_loss: 9.3392 - val_mae: 2.4691 - val_mse: 9.3392\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6101 - mae: 0.8891 - mse: 1.6101 - val_loss: 6.4661 - val_mae: 2.0787 - val_mse: 6.4661\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1984 - mae: 1.0564 - mse: 2.1984 - val_loss: 6.6219 - val_mae: 2.0471 - val_mse: 6.6219\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6179 - mae: 0.8587 - mse: 1.6179 - val_loss: 7.1952 - val_mae: 2.2139 - val_mse: 7.1952\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7223 - mae: 0.8767 - mse: 1.7223 - val_loss: 8.6243 - val_mae: 2.3562 - val_mse: 8.6243\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.4018 - mae: 2.0098 - mse: 6.4018 - val_loss: 6.8761 - val_mae: 2.0939 - val_mse: 6.8761\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.5722 - mae: 1.1739 - mse: 2.5722 - val_loss: 6.8433 - val_mae: 2.0293 - val_mse: 6.8433\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7724 - mae: 0.9035 - mse: 1.7724 - val_loss: 7.6180 - val_mae: 2.1755 - val_mse: 7.6180\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4584 - mae: 0.8300 - mse: 1.4584 - val_loss: 7.1374 - val_mae: 2.1399 - val_mse: 7.1374\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5173 - mae: 0.8555 - mse: 1.5173 - val_loss: 6.4581 - val_mae: 2.0439 - val_mse: 6.4581\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9352 - mae: 0.9820 - mse: 1.9352 - val_loss: 7.5158 - val_mae: 2.1544 - val_mse: 7.5158\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8486 - mae: 0.9633 - mse: 1.8486 - val_loss: 8.6693 - val_mae: 2.2276 - val_mse: 8.6693\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8463 - mae: 0.9482 - mse: 1.8463 - val_loss: 7.2635 - val_mae: 2.1673 - val_mse: 7.2635\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0176 - mae: 0.9229 - mse: 2.0176 - val_loss: 7.3255 - val_mae: 2.1645 - val_mse: 7.3255\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.9868 - mae: 1.8526 - mse: 5.9868 - val_loss: 11.8639 - val_mae: 2.7896 - val_mse: 11.8639\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9208 - mae: 0.9920 - mse: 1.9208 - val_loss: 6.9454 - val_mae: 2.1199 - val_mse: 6.9454\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7447 - mae: 0.9116 - mse: 1.7447 - val_loss: 7.3326 - val_mae: 2.0868 - val_mse: 7.3326\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7106 - mae: 0.8374 - mse: 1.7106 - val_loss: 7.0933 - val_mae: 2.0892 - val_mse: 7.0933\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9184 - mae: 0.9162 - mse: 1.9184 - val_loss: 6.9202 - val_mae: 2.0925 - val_mse: 6.9202\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4487 - mae: 0.7681 - mse: 1.4487 - val_loss: 7.4858 - val_mae: 2.1325 - val_mse: 7.4858\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7509 - mae: 0.9446 - mse: 1.7509 - val_loss: 7.4560 - val_mae: 2.1642 - val_mse: 7.4560\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8568 - mae: 1.2100 - mse: 2.8568 - val_loss: 11.8767 - val_mae: 2.8147 - val_mse: 11.8767\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.4628 - mae: 1.1879 - mse: 2.4628 - val_loss: 7.5983 - val_mae: 2.2137 - val_mse: 7.5983\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7685 - mae: 0.9094 - mse: 1.7685 - val_loss: 7.3624 - val_mae: 2.2420 - val_mse: 7.3624\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5447 - mae: 0.8548 - mse: 1.5447 - val_loss: 6.6573 - val_mae: 2.0780 - val_mse: 6.6573\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5320 - mae: 0.8599 - mse: 1.5320 - val_loss: 6.7981 - val_mae: 2.0804 - val_mse: 6.7981\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7186 - mae: 0.8699 - mse: 1.7186 - val_loss: 7.6832 - val_mae: 2.2817 - val_mse: 7.6832\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6216 - mae: 0.8708 - mse: 1.6216 - val_loss: 7.8956 - val_mae: 2.2714 - val_mse: 7.8956\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1934 - mae: 1.0313 - mse: 2.1934 - val_loss: 7.1165 - val_mae: 2.1091 - val_mse: 7.1165\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4464 - mae: 0.7538 - mse: 1.4464 - val_loss: 7.2684 - val_mae: 2.1744 - val_mse: 7.2684\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4838 - mae: 0.7914 - mse: 1.4838 - val_loss: 7.1545 - val_mae: 2.1709 - val_mse: 7.1545\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2569 - mae: 0.7197 - mse: 1.2569 - val_loss: 6.7218 - val_mae: 2.1178 - val_mse: 6.7218\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4319 - mae: 0.8014 - mse: 1.4319 - val_loss: 7.5926 - val_mae: 2.1322 - val_mse: 7.5926\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6784 - mae: 0.8695 - mse: 1.6784 - val_loss: 7.6160 - val_mae: 2.2688 - val_mse: 7.6160\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8842 - mae: 0.9321 - mse: 1.8842 - val_loss: 12.1737 - val_mae: 2.7077 - val_mse: 12.1737\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.0463 - mae: 1.2574 - mse: 3.0463 - val_loss: 7.6697 - val_mae: 2.2493 - val_mse: 7.6697\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6683 - mae: 0.8600 - mse: 1.6683 - val_loss: 7.2290 - val_mae: 2.1435 - val_mse: 7.2290\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4754 - mae: 0.7765 - mse: 1.4754 - val_loss: 8.0159 - val_mae: 2.3384 - val_mse: 8.0159\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7231 - mae: 0.8619 - mse: 1.7231 - val_loss: 6.5919 - val_mae: 2.0529 - val_mse: 6.5919\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4014 - mae: 0.7570 - mse: 1.4014 - val_loss: 7.7610 - val_mae: 2.1738 - val_mse: 7.7610\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4721 - mae: 0.8257 - mse: 1.4721 - val_loss: 7.4845 - val_mae: 2.2149 - val_mse: 7.4845\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9775 - mae: 0.9299 - mse: 1.9775 - val_loss: 7.2986 - val_mae: 2.0581 - val_mse: 7.2986\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4684 - mae: 0.7829 - mse: 1.4684 - val_loss: 7.7462 - val_mae: 2.1407 - val_mse: 7.7462\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7436 - mae: 0.9143 - mse: 1.7436 - val_loss: 6.9530 - val_mae: 2.1021 - val_mse: 6.9530\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6022 - mae: 0.7678 - mse: 1.6022 - val_loss: 10.7447 - val_mae: 2.5434 - val_mse: 10.7447\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9664 - mae: 0.9688 - mse: 1.9664 - val_loss: 6.8415 - val_mae: 2.1081 - val_mse: 6.8415\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2547 - mae: 0.7307 - mse: 1.2547 - val_loss: 6.7740 - val_mae: 2.0541 - val_mse: 6.7740\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4358 - mae: 0.7884 - mse: 1.4358 - val_loss: 7.1307 - val_mae: 2.1387 - val_mse: 7.1307\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9417 - mae: 0.9241 - mse: 1.9417 - val_loss: 7.4230 - val_mae: 2.1139 - val_mse: 7.4230\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4687 - mae: 0.8086 - mse: 1.4687 - val_loss: 7.3773 - val_mae: 2.1215 - val_mse: 7.3773\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2985 - mae: 0.7712 - mse: 1.2985 - val_loss: 8.2725 - val_mae: 2.2365 - val_mse: 8.2725\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4844 - mae: 1.0347 - mse: 2.4844 - val_loss: 7.1900 - val_mae: 2.1414 - val_mse: 7.1900\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7454 - mae: 0.9467 - mse: 1.7454 - val_loss: 7.1024 - val_mae: 2.1572 - val_mse: 7.1024\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3492 - mae: 0.7716 - mse: 1.3492 - val_loss: 7.3706 - val_mae: 2.1704 - val_mse: 7.3706\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3402 - mae: 0.7829 - mse: 1.3402 - val_loss: 7.1058 - val_mae: 2.1237 - val_mse: 7.1058\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7178 - mae: 0.9178 - mse: 1.7178 - val_loss: 6.8563 - val_mae: 2.1167 - val_mse: 6.8563\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1984 - mae: 0.7132 - mse: 1.1984 - val_loss: 7.0788 - val_mae: 2.1703 - val_mse: 7.0788\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3754 - mae: 0.7622 - mse: 1.3754 - val_loss: 6.3143 - val_mae: 2.0081 - val_mse: 6.3143\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3758 - mae: 1.0724 - mse: 2.3758 - val_loss: 7.8100 - val_mae: 2.2613 - val_mse: 7.8100\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8945 - mae: 0.9855 - mse: 1.8945 - val_loss: 7.6935 - val_mae: 2.2330 - val_mse: 7.6935\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6130 - mae: 0.8233 - mse: 1.6130 - val_loss: 7.7374 - val_mae: 2.2365 - val_mse: 7.7374\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5404 - mae: 0.8325 - mse: 1.5404 - val_loss: 8.2810 - val_mae: 2.2384 - val_mse: 8.2810\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8300 - mae: 0.9197 - mse: 1.8300 - val_loss: 7.7662 - val_mae: 2.2341 - val_mse: 7.7662\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4110 - mae: 0.7927 - mse: 1.4110 - val_loss: 6.9328 - val_mae: 2.1243 - val_mse: 6.9328\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2330 - mae: 0.7145 - mse: 1.2330 - val_loss: 8.2264 - val_mae: 2.2707 - val_mse: 8.2264\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1747 - mae: 1.0865 - mse: 2.1747 - val_loss: 6.7779 - val_mae: 2.0839 - val_mse: 6.7779\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4132 - mae: 0.7443 - mse: 1.4132 - val_loss: 10.5619 - val_mae: 2.5610 - val_mse: 10.5619\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2001 - mae: 1.0574 - mse: 2.2001 - val_loss: 7.8020 - val_mae: 2.1828 - val_mse: 7.8020\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7997 - mae: 0.9105 - mse: 1.7997 - val_loss: 7.8232 - val_mae: 2.1826 - val_mse: 7.8232\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3071 - mae: 0.7540 - mse: 1.3071 - val_loss: 7.6178 - val_mae: 2.1524 - val_mse: 7.6178\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1641 - mae: 0.6627 - mse: 1.1641 - val_loss: 7.5318 - val_mae: 2.1990 - val_mse: 7.5318\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4105 - mae: 0.7908 - mse: 1.4105 - val_loss: 8.7230 - val_mae: 2.2352 - val_mse: 8.7230\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8704 - mae: 0.9786 - mse: 1.8704 - val_loss: 6.9685 - val_mae: 2.0975 - val_mse: 6.9685\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5919 - mae: 0.8890 - mse: 1.5919 - val_loss: 7.0713 - val_mae: 2.1519 - val_mse: 7.0713\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6527 - mae: 0.8859 - mse: 1.6527 - val_loss: 7.4946 - val_mae: 2.1973 - val_mse: 7.4946\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4243 - mae: 0.7841 - mse: 1.4243 - val_loss: 6.9192 - val_mae: 2.1085 - val_mse: 6.9192\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8502 - mae: 0.8644 - mse: 1.8502 - val_loss: 7.1118 - val_mae: 2.0972 - val_mse: 7.1118\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2909 - mae: 0.7006 - mse: 1.2909 - val_loss: 6.9971 - val_mae: 2.1240 - val_mse: 6.9971\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5057 - mae: 0.7444 - mse: 1.5057 - val_loss: 7.2947 - val_mae: 2.1623 - val_mse: 7.2947\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8569 - mae: 0.8319 - mse: 1.8569 - val_loss: 8.0082 - val_mae: 2.2532 - val_mse: 8.0082\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8011 - mae: 0.9450 - mse: 1.8011 - val_loss: 7.2545 - val_mae: 2.1020 - val_mse: 7.2545\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3266 - mae: 0.7393 - mse: 1.3266 - val_loss: 7.6478 - val_mae: 2.1646 - val_mse: 7.6478\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5725 - mae: 0.8968 - mse: 1.5725 - val_loss: 7.8726 - val_mae: 2.2067 - val_mse: 7.8726\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6212 - mae: 0.7886 - mse: 1.6212 - val_loss: 10.3045 - val_mae: 2.4206 - val_mse: 10.3045\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0897 - mae: 0.9779 - mse: 2.0897 - val_loss: 8.2162 - val_mae: 2.2990 - val_mse: 8.2162\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4237 - mae: 0.8141 - mse: 1.4237 - val_loss: 7.1237 - val_mae: 2.1854 - val_mse: 7.1237\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6312 - mae: 0.8682 - mse: 1.6312 - val_loss: 7.4745 - val_mae: 2.2652 - val_mse: 7.4745\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2052 - mae: 0.6814 - mse: 1.2052 - val_loss: 7.7662 - val_mae: 2.1910 - val_mse: 7.7662\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7242 - mae: 0.9231 - mse: 1.7242 - val_loss: 7.3882 - val_mae: 2.1769 - val_mse: 7.3882\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6295 - mae: 0.8106 - mse: 1.6295 - val_loss: 7.0076 - val_mae: 2.1246 - val_mse: 7.0076\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2477 - mae: 0.6915 - mse: 1.2477 - val_loss: 7.2285 - val_mae: 2.2241 - val_mse: 7.2285\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1514 - mae: 0.6499 - mse: 1.1514 - val_loss: 6.6912 - val_mae: 2.0241 - val_mse: 6.6912\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4215 - mae: 0.7336 - mse: 1.4215 - val_loss: 7.1319 - val_mae: 2.1855 - val_mse: 7.1319\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2521 - mae: 0.7171 - mse: 1.2521 - val_loss: 7.3622 - val_mae: 2.2095 - val_mse: 7.3622\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4832 - mae: 0.7788 - mse: 1.4832 - val_loss: 8.7252 - val_mae: 2.3169 - val_mse: 8.7252\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7146 - mae: 0.9617 - mse: 1.7146 - val_loss: 9.1675 - val_mae: 2.4545 - val_mse: 9.1675\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3290 - mae: 0.7155 - mse: 1.3290 - val_loss: 7.8385 - val_mae: 2.2040 - val_mse: 7.8385\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9656 - mae: 0.9771 - mse: 1.9656 - val_loss: 8.3890 - val_mae: 2.3377 - val_mse: 8.3890\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4604 - mae: 0.8566 - mse: 1.4604 - val_loss: 7.7172 - val_mae: 2.1733 - val_mse: 7.7172\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3677 - mae: 0.7292 - mse: 1.3677 - val_loss: 7.7569 - val_mae: 2.1960 - val_mse: 7.7569\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6923 - mae: 0.8531 - mse: 1.6923 - val_loss: 7.1975 - val_mae: 2.1439 - val_mse: 7.1975\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2556 - mae: 0.7047 - mse: 1.2556 - val_loss: 7.2293 - val_mae: 2.1331 - val_mse: 7.2293\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3110 - mae: 0.7646 - mse: 1.3110 - val_loss: 6.7788 - val_mae: 2.0758 - val_mse: 6.7788\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0559 - mae: 0.9923 - mse: 2.0559 - val_loss: 9.5906 - val_mae: 2.4226 - val_mse: 9.5906\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3942 - mae: 0.8052 - mse: 1.3942 - val_loss: 7.3969 - val_mae: 2.1037 - val_mse: 7.3969\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3134 - mae: 0.7760 - mse: 1.3134 - val_loss: 7.7563 - val_mae: 2.2085 - val_mse: 7.7563\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2892 - mae: 1.0000 - mse: 2.2892 - val_loss: 8.0630 - val_mae: 2.2993 - val_mse: 8.0630\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7009 - mae: 0.9320 - mse: 1.7009 - val_loss: 7.1440 - val_mae: 2.0833 - val_mse: 7.1440\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.8056 - mae: 0.9120 - mse: 1.8056 - val_loss: 6.9212 - val_mae: 2.0727 - val_mse: 6.9212\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3209 - mae: 0.7376 - mse: 1.3209 - val_loss: 7.6106 - val_mae: 2.1716 - val_mse: 7.6106\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3091 - mae: 0.7059 - mse: 1.3091 - val_loss: 8.6995 - val_mae: 2.2418 - val_mse: 8.6995\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8092 - mae: 0.8844 - mse: 1.8092 - val_loss: 8.3123 - val_mae: 2.1248 - val_mse: 8.3123\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4310 - mae: 0.7823 - mse: 1.4310 - val_loss: 6.9836 - val_mae: 2.1203 - val_mse: 6.9836\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1970 - mae: 0.6669 - mse: 1.1970 - val_loss: 8.0130 - val_mae: 2.1937 - val_mse: 8.0130\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2030 - mae: 0.7356 - mse: 1.2030 - val_loss: 7.4505 - val_mae: 2.1780 - val_mse: 7.4505\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7871 - mae: 0.8214 - mse: 1.7871 - val_loss: 8.9635 - val_mae: 2.3059 - val_mse: 8.9635\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8486 - mae: 0.8489 - mse: 1.8486 - val_loss: 8.1570 - val_mae: 2.2535 - val_mse: 8.1570\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7916 - mae: 0.8722 - mse: 1.7916 - val_loss: 7.2044 - val_mae: 2.1403 - val_mse: 7.2044\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2447 - mae: 0.6739 - mse: 1.2447 - val_loss: 7.2920 - val_mae: 2.1695 - val_mse: 7.2920\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2368 - mae: 0.6842 - mse: 1.2368 - val_loss: 7.2335 - val_mae: 2.1600 - val_mse: 7.2335\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2105 - mae: 0.6869 - mse: 1.2105 - val_loss: 6.9233 - val_mae: 2.0918 - val_mse: 6.9233\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9570 - mae: 0.9322 - mse: 1.9570 - val_loss: 7.9672 - val_mae: 2.1804 - val_mse: 7.9672\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3509 - mae: 0.7980 - mse: 1.3509 - val_loss: 8.8908 - val_mae: 2.3292 - val_mse: 8.8908\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3190 - mae: 0.7166 - mse: 1.3190 - val_loss: 7.2962 - val_mae: 2.1931 - val_mse: 7.2962\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4872 - mae: 0.8255 - mse: 1.4872 - val_loss: 6.8801 - val_mae: 2.0446 - val_mse: 6.8801\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4419 - mae: 0.8044 - mse: 1.4419 - val_loss: 8.4424 - val_mae: 2.2126 - val_mse: 8.4424\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4504 - mae: 0.8363 - mse: 1.4504 - val_loss: 8.7495 - val_mae: 2.4142 - val_mse: 8.7495\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6587 - mae: 0.8461 - mse: 1.6587 - val_loss: 9.5956 - val_mae: 2.4466 - val_mse: 9.5956\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2514 - mae: 1.0362 - mse: 2.2514 - val_loss: 8.6777 - val_mae: 2.3565 - val_mse: 8.6777\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0277 - mae: 1.0299 - mse: 2.0277 - val_loss: 8.1919 - val_mae: 2.2370 - val_mse: 8.1919\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3562 - mae: 0.7208 - mse: 1.3562 - val_loss: 8.9731 - val_mae: 2.2503 - val_mse: 8.9731\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7248 - mae: 0.9068 - mse: 1.7248 - val_loss: 7.8146 - val_mae: 2.2318 - val_mse: 7.8146\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.0007 - mae: 1.0429 - mse: 2.0007 - val_loss: 6.5719 - val_mae: 2.0179 - val_mse: 6.5719\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7306 - mae: 0.8726 - mse: 1.7306 - val_loss: 6.9550 - val_mae: 2.0965 - val_mse: 6.9550\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2177 - mae: 0.7342 - mse: 1.2177 - val_loss: 7.1412 - val_mae: 2.1310 - val_mse: 7.1412\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6166 - mae: 0.8594 - mse: 1.6166 - val_loss: 7.0913 - val_mae: 2.1157 - val_mse: 7.0913\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4292 - mae: 0.7828 - mse: 1.4292 - val_loss: 6.7220 - val_mae: 2.0718 - val_mse: 6.7220\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1566 - mae: 0.6836 - mse: 1.1566 - val_loss: 6.8909 - val_mae: 2.1048 - val_mse: 6.8909\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1688 - mae: 0.6744 - mse: 1.1688 - val_loss: 7.3038 - val_mae: 2.1845 - val_mse: 7.3038\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6145 - mae: 0.8198 - mse: 1.6145 - val_loss: 7.6365 - val_mae: 2.2216 - val_mse: 7.6365\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4672 - mae: 0.8001 - mse: 1.4672 - val_loss: 7.4265 - val_mae: 2.1199 - val_mse: 7.4265\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1822 - mae: 0.7037 - mse: 1.1822 - val_loss: 7.6321 - val_mae: 2.2103 - val_mse: 7.6321\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9679 - mae: 0.9441 - mse: 1.9679 - val_loss: 6.7530 - val_mae: 2.0896 - val_mse: 6.7530\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5728 - mae: 0.8253 - mse: 1.5728 - val_loss: 6.6901 - val_mae: 2.0666 - val_mse: 6.6901\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4655 - mae: 0.7695 - mse: 1.4655 - val_loss: 8.3110 - val_mae: 2.2165 - val_mse: 8.3110\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6967 - mae: 0.8452 - mse: 1.6967 - val_loss: 7.5460 - val_mae: 2.2477 - val_mse: 7.5460\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2450 - mae: 0.6987 - mse: 1.2450 - val_loss: 7.2779 - val_mae: 2.1106 - val_mse: 7.2779\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0980 - mae: 0.5969 - mse: 1.0980 - val_loss: 7.5703 - val_mae: 2.1970 - val_mse: 7.5703\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0826 - mae: 0.6439 - mse: 1.0826 - val_loss: 7.7219 - val_mae: 2.1568 - val_mse: 7.7219\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3593 - mae: 0.7737 - mse: 1.3593 - val_loss: 7.5560 - val_mae: 2.2488 - val_mse: 7.5560\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2722 - mae: 0.7053 - mse: 1.2722 - val_loss: 7.2982 - val_mae: 2.1823 - val_mse: 7.2982\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7689 - mae: 0.8777 - mse: 1.7689 - val_loss: 7.3729 - val_mae: 2.1805 - val_mse: 7.3729\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9304 - mae: 0.9750 - mse: 1.9304 - val_loss: 7.4741 - val_mae: 2.1864 - val_mse: 7.4741\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2950 - mae: 0.7538 - mse: 1.2950 - val_loss: 7.4065 - val_mae: 2.1655 - val_mse: 7.4065\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4873 - mae: 0.7765 - mse: 1.4873 - val_loss: 7.6138 - val_mae: 2.2449 - val_mse: 7.6138\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2004 - mae: 0.7319 - mse: 1.2004 - val_loss: 7.6777 - val_mae: 2.2082 - val_mse: 7.6777\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8062 - mae: 0.8681 - mse: 1.8062 - val_loss: 7.4333 - val_mae: 2.0517 - val_mse: 7.4333\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3475 - mae: 0.7496 - mse: 1.3475 - val_loss: 7.8653 - val_mae: 2.1782 - val_mse: 7.8653\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7939 - mae: 0.9339 - mse: 1.7939 - val_loss: 7.8690 - val_mae: 2.2775 - val_mse: 7.8690\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3802 - mae: 0.8236 - mse: 1.3802 - val_loss: 8.8577 - val_mae: 2.3856 - val_mse: 8.8577\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.1846 - mae: 1.2225 - mse: 3.1846 - val_loss: 7.7238 - val_mae: 2.2293 - val_mse: 7.7238\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4040 - mae: 0.8084 - mse: 1.4040 - val_loss: 8.8075 - val_mae: 2.4437 - val_mse: 8.8075\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5250 - mae: 0.8813 - mse: 1.5250 - val_loss: 8.0649 - val_mae: 2.2012 - val_mse: 8.0649\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6752 - mae: 0.8197 - mse: 1.6752 - val_loss: 8.2302 - val_mae: 2.2846 - val_mse: 8.2302\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2946 - mae: 0.7248 - mse: 1.2946 - val_loss: 6.8229 - val_mae: 2.1000 - val_mse: 6.8229\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2473 - mae: 1.0287 - mse: 2.2473 - val_loss: 7.8089 - val_mae: 2.2413 - val_mse: 7.8089\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3845 - mae: 0.7582 - mse: 1.3845 - val_loss: 7.7044 - val_mae: 2.2589 - val_mse: 7.7044\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1961 - mae: 0.6927 - mse: 1.1961 - val_loss: 7.5658 - val_mae: 2.2261 - val_mse: 7.5658\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1995 - mae: 0.7293 - mse: 1.1995 - val_loss: 7.7963 - val_mae: 2.1004 - val_mse: 7.7963\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3530 - mae: 0.7816 - mse: 1.3530 - val_loss: 7.4690 - val_mae: 2.2071 - val_mse: 7.4690\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5305 - mae: 0.8086 - mse: 1.5305 - val_loss: 7.4423 - val_mae: 2.1642 - val_mse: 7.4423\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3936 - mae: 0.7780 - mse: 1.3936 - val_loss: 6.5913 - val_mae: 2.0600 - val_mse: 6.5913\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6703 - mae: 0.8180 - mse: 1.6703 - val_loss: 8.2210 - val_mae: 2.2971 - val_mse: 8.2210\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4805 - mae: 0.8101 - mse: 1.4805 - val_loss: 8.0182 - val_mae: 2.2469 - val_mse: 8.0182\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2649 - mae: 0.7106 - mse: 1.2649 - val_loss: 7.6371 - val_mae: 2.1234 - val_mse: 7.6371\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6227 - mae: 0.8323 - mse: 1.6227 - val_loss: 7.3854 - val_mae: 2.1030 - val_mse: 7.3854\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7112 - mae: 0.8871 - mse: 1.7112 - val_loss: 9.5502 - val_mae: 2.3874 - val_mse: 9.5502\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3579 - mae: 0.7703 - mse: 1.3579 - val_loss: 8.4532 - val_mae: 2.2454 - val_mse: 8.4532\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3285 - mae: 0.7413 - mse: 1.3285 - val_loss: 7.2941 - val_mae: 2.1671 - val_mse: 7.2941\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0392 - mae: 0.6088 - mse: 1.0392 - val_loss: 6.6137 - val_mae: 2.0446 - val_mse: 6.6137\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1857 - mae: 0.6825 - mse: 1.1857 - val_loss: 7.3071 - val_mae: 2.0942 - val_mse: 7.3071\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1108 - mae: 0.6476 - mse: 1.1108 - val_loss: 7.0166 - val_mae: 2.1075 - val_mse: 7.0166\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0984 - mae: 0.6795 - mse: 1.0984 - val_loss: 7.7032 - val_mae: 2.1812 - val_mse: 7.7032\n",
            "Epoch 501/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3038 - mae: 0.6873 - mse: 1.3038 - val_loss: 8.2061 - val_mae: 2.2402 - val_mse: 8.2061\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4301 - mae: 0.7192 - mse: 1.4301 - val_loss: 7.6233 - val_mae: 2.1528 - val_mse: 7.6233\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3823 - mae: 1.0033 - mse: 2.3823 - val_loss: 7.3214 - val_mae: 2.1494 - val_mse: 7.3214\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6020 - mae: 0.8430 - mse: 1.6020 - val_loss: 8.6345 - val_mae: 2.2063 - val_mse: 8.6345\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5972 - mae: 0.8207 - mse: 1.5972 - val_loss: 8.0347 - val_mae: 2.2796 - val_mse: 8.0347\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3905 - mae: 0.7068 - mse: 1.3905 - val_loss: 7.1394 - val_mae: 2.1107 - val_mse: 7.1394\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3527 - mae: 0.7612 - mse: 1.3527 - val_loss: 7.3562 - val_mae: 2.1783 - val_mse: 7.3562\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2066 - mae: 0.7258 - mse: 1.2066 - val_loss: 7.8471 - val_mae: 2.1000 - val_mse: 7.8471\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7020 - mae: 0.8924 - mse: 1.7020 - val_loss: 7.2368 - val_mae: 2.0924 - val_mse: 7.2368\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5420 - mae: 0.7623 - mse: 1.5420 - val_loss: 10.4977 - val_mae: 2.4780 - val_mse: 10.4977\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2905 - mae: 1.0149 - mse: 2.2905 - val_loss: 9.6031 - val_mae: 2.4545 - val_mse: 9.6031\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8665 - mae: 0.9240 - mse: 1.8665 - val_loss: 6.9541 - val_mae: 2.1159 - val_mse: 6.9541\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1967 - mae: 0.6776 - mse: 1.1967 - val_loss: 7.4190 - val_mae: 2.1417 - val_mse: 7.4190\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4635 - mae: 0.7216 - mse: 1.4635 - val_loss: 7.8938 - val_mae: 2.1505 - val_mse: 7.8938\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1248 - mae: 0.9798 - mse: 2.1248 - val_loss: 6.9515 - val_mae: 2.1361 - val_mse: 6.9515\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4171 - mae: 1.1192 - mse: 2.4171 - val_loss: 8.7505 - val_mae: 2.3704 - val_mse: 8.7505\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4967 - mae: 0.7947 - mse: 1.4967 - val_loss: 6.4289 - val_mae: 2.0553 - val_mse: 6.4289\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1686 - mae: 0.9535 - mse: 2.1686 - val_loss: 8.9781 - val_mae: 2.3842 - val_mse: 8.9781\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3605 - mae: 1.0492 - mse: 2.3605 - val_loss: 7.7282 - val_mae: 2.2090 - val_mse: 7.7282\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1297 - mae: 0.6600 - mse: 1.1297 - val_loss: 6.9332 - val_mae: 2.1276 - val_mse: 6.9332\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4788 - mae: 0.7561 - mse: 1.4788 - val_loss: 7.0722 - val_mae: 2.1136 - val_mse: 7.0722\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2394 - mae: 0.7181 - mse: 1.2394 - val_loss: 6.9420 - val_mae: 2.1176 - val_mse: 6.9420\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7728 - mae: 0.8220 - mse: 1.7728 - val_loss: 7.7357 - val_mae: 2.1904 - val_mse: 7.7357\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8241 - mae: 0.9324 - mse: 1.8241 - val_loss: 8.0627 - val_mae: 2.2098 - val_mse: 8.0627\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3612 - mae: 0.8200 - mse: 1.3612 - val_loss: 6.7530 - val_mae: 2.0688 - val_mse: 6.7530\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5901 - mae: 0.8720 - mse: 1.5901 - val_loss: 6.9513 - val_mae: 2.0924 - val_mse: 6.9513\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1457 - mae: 0.6676 - mse: 1.1457 - val_loss: 6.3856 - val_mae: 2.0252 - val_mse: 6.3856\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2413 - mae: 0.6687 - mse: 1.2413 - val_loss: 6.8167 - val_mae: 2.1163 - val_mse: 6.8167\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5449 - mae: 0.8430 - mse: 1.5449 - val_loss: 6.7684 - val_mae: 2.0634 - val_mse: 6.7684\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4302 - mae: 0.8418 - mse: 1.4302 - val_loss: 7.6690 - val_mae: 2.2014 - val_mse: 7.6690\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1968 - mae: 0.6627 - mse: 1.1968 - val_loss: 7.0259 - val_mae: 2.1320 - val_mse: 7.0259\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3346 - mae: 0.7723 - mse: 1.3346 - val_loss: 7.5257 - val_mae: 2.2784 - val_mse: 7.5257\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2849 - mae: 0.6931 - mse: 1.2849 - val_loss: 9.0923 - val_mae: 2.4253 - val_mse: 9.0923\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8709 - mae: 0.9480 - mse: 1.8709 - val_loss: 7.5831 - val_mae: 2.2104 - val_mse: 7.5831\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4695 - mae: 0.7725 - mse: 1.4695 - val_loss: 8.6863 - val_mae: 2.2414 - val_mse: 8.6863\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5021 - mae: 0.8126 - mse: 1.5021 - val_loss: 8.0368 - val_mae: 2.2825 - val_mse: 8.0368\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2596 - mae: 0.7222 - mse: 1.2596 - val_loss: 9.4672 - val_mae: 2.2830 - val_mse: 9.4672\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2443 - mae: 0.7341 - mse: 1.2443 - val_loss: 7.6136 - val_mae: 2.1629 - val_mse: 7.6136\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5600 - mae: 0.7951 - mse: 1.5600 - val_loss: 7.6770 - val_mae: 2.1548 - val_mse: 7.6770\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3954 - mae: 0.7055 - mse: 1.3954 - val_loss: 8.7796 - val_mae: 2.3750 - val_mse: 8.7796\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1487 - mae: 0.7217 - mse: 1.1487 - val_loss: 7.6001 - val_mae: 2.1216 - val_mse: 7.6001\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2836 - mae: 0.7951 - mse: 1.2836 - val_loss: 6.4950 - val_mae: 2.0954 - val_mse: 6.4950\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8982 - mae: 1.2130 - mse: 2.8982 - val_loss: 8.2984 - val_mae: 2.2755 - val_mse: 8.2984\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 3.6747 - mae: 1.3468 - mse: 3.6747 - val_loss: 8.1732 - val_mae: 2.2341 - val_mse: 8.1732\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0594 - mae: 0.9596 - mse: 2.0594 - val_loss: 7.6390 - val_mae: 2.2077 - val_mse: 7.6390\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3071 - mae: 0.7363 - mse: 1.3071 - val_loss: 7.0102 - val_mae: 2.0581 - val_mse: 7.0102\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4577 - mae: 0.7513 - mse: 1.4577 - val_loss: 8.0156 - val_mae: 2.1734 - val_mse: 8.0156\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8748 - mae: 0.9073 - mse: 1.8748 - val_loss: 7.3245 - val_mae: 2.1160 - val_mse: 7.3245\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7605 - mae: 0.8952 - mse: 1.7605 - val_loss: 6.7899 - val_mae: 2.0737 - val_mse: 6.7899\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0614 - mae: 0.6286 - mse: 1.0614 - val_loss: 6.7149 - val_mae: 2.0357 - val_mse: 6.7149\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0269 - mae: 1.0022 - mse: 2.0269 - val_loss: 7.5760 - val_mae: 2.1252 - val_mse: 7.5760\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2033 - mae: 0.7335 - mse: 1.2033 - val_loss: 7.7279 - val_mae: 2.2001 - val_mse: 7.7279\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1347 - mae: 0.6259 - mse: 1.1347 - val_loss: 7.2842 - val_mae: 2.1139 - val_mse: 7.2842\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5785 - mae: 0.8100 - mse: 1.5785 - val_loss: 9.3466 - val_mae: 2.4348 - val_mse: 9.3466\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7641 - mae: 0.9536 - mse: 1.7641 - val_loss: 6.8397 - val_mae: 2.0797 - val_mse: 6.8397\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2622 - mae: 0.7101 - mse: 1.2622 - val_loss: 9.6122 - val_mae: 2.4340 - val_mse: 9.6122\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3881 - mae: 0.7628 - mse: 1.3881 - val_loss: 6.6540 - val_mae: 2.0793 - val_mse: 6.6540\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0073 - mae: 0.6080 - mse: 1.0073 - val_loss: 7.6481 - val_mae: 2.2542 - val_mse: 7.6481\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1119 - mae: 0.6425 - mse: 1.1119 - val_loss: 8.0788 - val_mae: 2.2017 - val_mse: 8.0788\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4481 - mae: 0.7404 - mse: 1.4481 - val_loss: 7.1444 - val_mae: 2.1539 - val_mse: 7.1444\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9782 - mae: 0.5887 - mse: 0.9782 - val_loss: 6.9615 - val_mae: 2.1121 - val_mse: 6.9615\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1613 - mae: 0.6506 - mse: 1.1613 - val_loss: 6.6484 - val_mae: 2.0485 - val_mse: 6.6484\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4913 - mae: 0.8593 - mse: 1.4913 - val_loss: 6.9384 - val_mae: 2.1677 - val_mse: 6.9384\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1126 - mae: 0.6829 - mse: 1.1126 - val_loss: 7.4933 - val_mae: 2.1534 - val_mse: 7.4933\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9566 - mae: 0.5860 - mse: 0.9566 - val_loss: 7.4574 - val_mae: 2.1419 - val_mse: 7.4574\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8924 - mae: 0.5416 - mse: 0.8924 - val_loss: 7.7056 - val_mae: 2.1557 - val_mse: 7.7056\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1035 - mae: 0.6405 - mse: 1.1035 - val_loss: 7.5428 - val_mae: 2.1479 - val_mse: 7.5428\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3750 - mae: 0.7363 - mse: 1.3750 - val_loss: 6.6875 - val_mae: 2.0539 - val_mse: 6.6875\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1262 - mae: 0.6991 - mse: 1.1262 - val_loss: 8.4601 - val_mae: 2.2757 - val_mse: 8.4601\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3722 - mae: 0.7364 - mse: 1.3722 - val_loss: 8.2568 - val_mae: 2.2325 - val_mse: 8.2568\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1110 - mae: 0.6404 - mse: 1.1110 - val_loss: 7.4170 - val_mae: 2.1587 - val_mse: 7.4170\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4301 - mae: 0.8108 - mse: 1.4301 - val_loss: 6.1936 - val_mae: 1.9431 - val_mse: 6.1936\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1694 - mae: 0.6538 - mse: 1.1694 - val_loss: 6.9630 - val_mae: 2.0846 - val_mse: 6.9630\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1598 - mae: 0.6371 - mse: 1.1598 - val_loss: 7.6066 - val_mae: 2.2222 - val_mse: 7.6066\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0831 - mae: 0.6060 - mse: 1.0831 - val_loss: 7.7401 - val_mae: 2.1539 - val_mse: 7.7401\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0121 - mae: 0.6241 - mse: 1.0121 - val_loss: 7.5057 - val_mae: 2.0969 - val_mse: 7.5057\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4533 - mae: 0.7105 - mse: 1.4533 - val_loss: 10.0705 - val_mae: 2.4766 - val_mse: 10.0705\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3338 - mae: 0.7604 - mse: 1.3338 - val_loss: 7.5791 - val_mae: 2.1699 - val_mse: 7.5791\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3868 - mae: 0.7348 - mse: 1.3868 - val_loss: 7.2534 - val_mae: 2.0761 - val_mse: 7.2534\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7422 - mae: 0.9024 - mse: 1.7422 - val_loss: 7.0648 - val_mae: 2.1622 - val_mse: 7.0648\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0494 - mae: 0.6928 - mse: 1.0494 - val_loss: 6.9046 - val_mae: 2.0834 - val_mse: 6.9046\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3439 - mae: 0.7165 - mse: 1.3439 - val_loss: 8.6479 - val_mae: 2.1937 - val_mse: 8.6479\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3743 - mae: 0.7749 - mse: 1.3743 - val_loss: 7.9431 - val_mae: 2.1583 - val_mse: 7.9431\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.7478 - mae: 1.2651 - mse: 2.7478 - val_loss: 7.3939 - val_mae: 2.1622 - val_mse: 7.3939\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4620 - mae: 0.7963 - mse: 1.4620 - val_loss: 11.2859 - val_mae: 2.6709 - val_mse: 11.2859\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9905 - mae: 0.9308 - mse: 1.9905 - val_loss: 7.1780 - val_mae: 2.1673 - val_mse: 7.1780\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0244 - mae: 0.5957 - mse: 1.0244 - val_loss: 7.0477 - val_mae: 2.1351 - val_mse: 7.0477\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2833 - mae: 0.6702 - mse: 1.2833 - val_loss: 6.6839 - val_mae: 2.0766 - val_mse: 6.6839\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0053 - mae: 0.6242 - mse: 1.0053 - val_loss: 7.1186 - val_mae: 2.1294 - val_mse: 7.1186\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1118 - mae: 0.9696 - mse: 2.1118 - val_loss: 7.1053 - val_mae: 2.1621 - val_mse: 7.1053\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0953 - mae: 0.6661 - mse: 1.0953 - val_loss: 7.5833 - val_mae: 2.1734 - val_mse: 7.5833\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0197 - mae: 0.6108 - mse: 1.0197 - val_loss: 7.2330 - val_mae: 2.0607 - val_mse: 7.2330\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1578 - mae: 0.6207 - mse: 1.1578 - val_loss: 7.0025 - val_mae: 2.1107 - val_mse: 7.0025\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1050 - mae: 0.6642 - mse: 1.1050 - val_loss: 7.8916 - val_mae: 2.2387 - val_mse: 7.8916\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7027 - mae: 0.8903 - mse: 1.7027 - val_loss: 8.0845 - val_mae: 2.1812 - val_mse: 8.0845\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5510 - mae: 0.8010 - mse: 1.5510 - val_loss: 6.6403 - val_mae: 2.0720 - val_mse: 6.6403\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1153 - mae: 0.6467 - mse: 1.1153 - val_loss: 7.6540 - val_mae: 2.2531 - val_mse: 7.6540\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4430 - mae: 0.8073 - mse: 1.4430 - val_loss: 7.2977 - val_mae: 2.1779 - val_mse: 7.2977\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0319 - mae: 0.6425 - mse: 1.0319 - val_loss: 9.1306 - val_mae: 2.2821 - val_mse: 9.1306\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3852 - mae: 0.6866 - mse: 1.3852 - val_loss: 8.3888 - val_mae: 2.2070 - val_mse: 8.3888\n",
            "Epoch 601/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4628 - mae: 0.7051 - mse: 1.4628 - val_loss: 7.0658 - val_mae: 2.1287 - val_mse: 7.0658\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8195 - mae: 0.8769 - mse: 1.8195 - val_loss: 8.3801 - val_mae: 2.2714 - val_mse: 8.3801\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4456 - mae: 0.8303 - mse: 1.4456 - val_loss: 7.5421 - val_mae: 2.2403 - val_mse: 7.5421\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2428 - mae: 0.6512 - mse: 1.2428 - val_loss: 8.7946 - val_mae: 2.3190 - val_mse: 8.7946\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4240 - mae: 0.8164 - mse: 1.4240 - val_loss: 6.9520 - val_mae: 2.1425 - val_mse: 6.9520\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3624 - mae: 0.7355 - mse: 1.3624 - val_loss: 7.4351 - val_mae: 2.2028 - val_mse: 7.4351\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9692 - mae: 0.5959 - mse: 0.9692 - val_loss: 7.1961 - val_mae: 2.1469 - val_mse: 7.1961\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3436 - mae: 0.7742 - mse: 1.3436 - val_loss: 7.9923 - val_mae: 2.2389 - val_mse: 7.9923\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0576 - mae: 0.6079 - mse: 1.0576 - val_loss: 7.6262 - val_mae: 2.2156 - val_mse: 7.6262\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0739 - mae: 0.7090 - mse: 1.0739 - val_loss: 7.6377 - val_mae: 2.1457 - val_mse: 7.6377\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1359 - mae: 0.6567 - mse: 1.1359 - val_loss: 7.1250 - val_mae: 2.1269 - val_mse: 7.1250\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9483 - mae: 0.5618 - mse: 0.9483 - val_loss: 7.2956 - val_mae: 2.1533 - val_mse: 7.2956\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4661 - mae: 0.8525 - mse: 1.4661 - val_loss: 7.3547 - val_mae: 2.1700 - val_mse: 7.3547\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5494 - mae: 0.7918 - mse: 1.5494 - val_loss: 8.4751 - val_mae: 2.3295 - val_mse: 8.4751\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1331 - mae: 0.7241 - mse: 1.1331 - val_loss: 7.4033 - val_mae: 2.1410 - val_mse: 7.4033\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0431 - mae: 0.6413 - mse: 1.0431 - val_loss: 7.3483 - val_mae: 2.1555 - val_mse: 7.3483\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9729 - mae: 0.5726 - mse: 0.9729 - val_loss: 8.0887 - val_mae: 2.1971 - val_mse: 8.0887\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0914 - mae: 0.6470 - mse: 1.0914 - val_loss: 7.8792 - val_mae: 2.2124 - val_mse: 7.8792\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4758 - mae: 0.7751 - mse: 1.4758 - val_loss: 6.7877 - val_mae: 2.0736 - val_mse: 6.7877\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0463 - mae: 0.6074 - mse: 1.0463 - val_loss: 7.3374 - val_mae: 2.1816 - val_mse: 7.3374\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4146 - mae: 0.7982 - mse: 1.4146 - val_loss: 6.8395 - val_mae: 2.1234 - val_mse: 6.8395\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5408 - mae: 0.8825 - mse: 1.5408 - val_loss: 7.4008 - val_mae: 2.0484 - val_mse: 7.4008\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2665 - mae: 0.6646 - mse: 1.2665 - val_loss: 7.4033 - val_mae: 2.1522 - val_mse: 7.4033\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0717 - mae: 0.6491 - mse: 1.0717 - val_loss: 7.4013 - val_mae: 2.1753 - val_mse: 7.4013\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8156 - mae: 0.8594 - mse: 1.8156 - val_loss: 15.3878 - val_mae: 3.0827 - val_mse: 15.3878\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 5.4130 - mae: 1.7049 - mse: 5.4130 - val_loss: 17.4754 - val_mae: 3.4736 - val_mse: 17.4754\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3744 - mae: 1.0940 - mse: 2.3744 - val_loss: 7.6206 - val_mae: 2.2458 - val_mse: 7.6206\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2657 - mae: 0.7526 - mse: 1.2657 - val_loss: 7.5759 - val_mae: 2.1251 - val_mse: 7.5759\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1553 - mae: 0.6610 - mse: 1.1553 - val_loss: 8.3929 - val_mae: 2.3488 - val_mse: 8.3929\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4573 - mae: 0.7609 - mse: 1.4573 - val_loss: 8.2275 - val_mae: 2.1694 - val_mse: 8.2275\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1131 - mae: 0.6414 - mse: 1.1131 - val_loss: 7.9099 - val_mae: 2.1581 - val_mse: 7.9099\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5234 - mae: 0.8079 - mse: 1.5234 - val_loss: 9.6179 - val_mae: 2.3241 - val_mse: 9.6179\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8570 - mae: 0.9293 - mse: 1.8570 - val_loss: 8.9595 - val_mae: 2.2304 - val_mse: 8.9595\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3193 - mae: 0.7832 - mse: 1.3193 - val_loss: 8.4023 - val_mae: 2.3511 - val_mse: 8.4023\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4442 - mae: 0.8413 - mse: 1.4442 - val_loss: 7.8792 - val_mae: 2.2156 - val_mse: 7.8792\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3965 - mae: 0.7449 - mse: 1.3965 - val_loss: 7.2683 - val_mae: 2.2231 - val_mse: 7.2683\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3302 - mae: 0.7829 - mse: 1.3302 - val_loss: 7.3017 - val_mae: 2.1924 - val_mse: 7.3017\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0006 - mae: 0.6381 - mse: 1.0006 - val_loss: 7.2529 - val_mae: 2.1812 - val_mse: 7.2529\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8593 - mae: 0.5406 - mse: 0.8593 - val_loss: 7.4279 - val_mae: 2.1465 - val_mse: 7.4279\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8316 - mae: 0.5218 - mse: 0.8316 - val_loss: 7.7899 - val_mae: 2.2358 - val_mse: 7.7899\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8560 - mae: 0.5641 - mse: 0.8560 - val_loss: 7.4945 - val_mae: 2.2173 - val_mse: 7.4945\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2072 - mae: 0.7301 - mse: 1.2072 - val_loss: 8.1855 - val_mae: 2.3052 - val_mse: 8.1855\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.8158 - mae: 1.1533 - mse: 2.8158 - val_loss: 7.0479 - val_mae: 2.0604 - val_mse: 7.0479\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2498 - mae: 0.7210 - mse: 1.2498 - val_loss: 7.6770 - val_mae: 2.1651 - val_mse: 7.6770\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1903 - mae: 0.6217 - mse: 1.1903 - val_loss: 7.8224 - val_mae: 2.2052 - val_mse: 7.8224\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9538 - mae: 0.6035 - mse: 0.9538 - val_loss: 7.2451 - val_mae: 2.1711 - val_mse: 7.2451\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1411 - mae: 0.7339 - mse: 1.1411 - val_loss: 6.7346 - val_mae: 2.0453 - val_mse: 6.7346\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4736 - mae: 0.7996 - mse: 1.4736 - val_loss: 7.4024 - val_mae: 2.1614 - val_mse: 7.4024\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3356 - mae: 0.7308 - mse: 1.3356 - val_loss: 10.0101 - val_mae: 2.4143 - val_mse: 10.0101\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3112 - mae: 0.7502 - mse: 1.3112 - val_loss: 8.6197 - val_mae: 2.2784 - val_mse: 8.6197\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0116 - mae: 1.0058 - mse: 2.0116 - val_loss: 7.6096 - val_mae: 2.0885 - val_mse: 7.6096\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3882 - mae: 0.8013 - mse: 1.3882 - val_loss: 8.7511 - val_mae: 2.3897 - val_mse: 8.7511\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3664 - mae: 0.7264 - mse: 1.3664 - val_loss: 8.0527 - val_mae: 2.3535 - val_mse: 8.0527\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9325 - mae: 0.5983 - mse: 0.9325 - val_loss: 7.1395 - val_mae: 2.1036 - val_mse: 7.1395\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1200 - mae: 0.6578 - mse: 1.1200 - val_loss: 8.1235 - val_mae: 2.2066 - val_mse: 8.1235\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1904 - mae: 0.7328 - mse: 1.1904 - val_loss: 8.2066 - val_mae: 2.3289 - val_mse: 8.2066\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0351 - mae: 0.6148 - mse: 1.0351 - val_loss: 7.5012 - val_mae: 2.2409 - val_mse: 7.5012\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9939 - mae: 0.5993 - mse: 0.9939 - val_loss: 8.0237 - val_mae: 2.2338 - val_mse: 8.0237\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3721 - mae: 0.7708 - mse: 1.3721 - val_loss: 7.4832 - val_mae: 2.2460 - val_mse: 7.4832\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1153 - mae: 0.6871 - mse: 1.1153 - val_loss: 8.1037 - val_mae: 2.2155 - val_mse: 8.1037\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8105 - mae: 0.8701 - mse: 1.8105 - val_loss: 6.0824 - val_mae: 1.9374 - val_mse: 6.0824\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1164 - mae: 0.6941 - mse: 1.1164 - val_loss: 8.1944 - val_mae: 2.2793 - val_mse: 8.1944\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2542 - mae: 0.6994 - mse: 1.2542 - val_loss: 7.5439 - val_mae: 2.1665 - val_mse: 7.5439\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1742 - mae: 0.6706 - mse: 1.1742 - val_loss: 6.9566 - val_mae: 2.1570 - val_mse: 6.9566\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9327 - mae: 0.5546 - mse: 0.9327 - val_loss: 7.2245 - val_mae: 2.1750 - val_mse: 7.2245\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1252 - mae: 0.6529 - mse: 1.1252 - val_loss: 7.0301 - val_mae: 2.1276 - val_mse: 7.0301\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0379 - mae: 0.6170 - mse: 1.0379 - val_loss: 7.1516 - val_mae: 2.1456 - val_mse: 7.1516\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0598 - mae: 0.7049 - mse: 1.0598 - val_loss: 7.4499 - val_mae: 2.2355 - val_mse: 7.4499\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4112 - mae: 0.7185 - mse: 1.4112 - val_loss: 7.3904 - val_mae: 2.1658 - val_mse: 7.3904\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4408 - mae: 0.7467 - mse: 1.4408 - val_loss: 8.4387 - val_mae: 2.1572 - val_mse: 8.4387\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2143 - mae: 0.6747 - mse: 1.2143 - val_loss: 7.4604 - val_mae: 2.1816 - val_mse: 7.4604\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9662 - mae: 0.5951 - mse: 0.9662 - val_loss: 7.4254 - val_mae: 2.1039 - val_mse: 7.4254\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7686 - mae: 0.8866 - mse: 1.7686 - val_loss: 9.1479 - val_mae: 2.2752 - val_mse: 9.1479\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5906 - mae: 0.8491 - mse: 1.5906 - val_loss: 6.6670 - val_mae: 2.0937 - val_mse: 6.6670\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2278 - mae: 0.7239 - mse: 1.2278 - val_loss: 6.7380 - val_mae: 2.0756 - val_mse: 6.7380\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9106 - mae: 0.5718 - mse: 0.9106 - val_loss: 6.5542 - val_mae: 2.0489 - val_mse: 6.5542\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0174 - mae: 0.5869 - mse: 1.0174 - val_loss: 9.0019 - val_mae: 2.3034 - val_mse: 9.0019\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4672 - mae: 0.8920 - mse: 1.4672 - val_loss: 7.4490 - val_mae: 2.1441 - val_mse: 7.4490\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5339 - mae: 0.7742 - mse: 1.5339 - val_loss: 6.2897 - val_mae: 2.0057 - val_mse: 6.2897\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2718 - mae: 0.7271 - mse: 1.2718 - val_loss: 6.4918 - val_mae: 2.0702 - val_mse: 6.4918\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4197 - mae: 0.8349 - mse: 1.4197 - val_loss: 8.9649 - val_mae: 2.3104 - val_mse: 8.9649\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1970 - mae: 0.7371 - mse: 1.1970 - val_loss: 6.4845 - val_mae: 2.0107 - val_mse: 6.4845\n",
            "Epoch 683/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2472 - mae: 0.6629 - mse: 1.2472 - val_loss: 7.0062 - val_mae: 2.1669 - val_mse: 7.0062\n",
            "Epoch 684/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9090 - mae: 0.6002 - mse: 0.9090 - val_loss: 7.3141 - val_mae: 2.1623 - val_mse: 7.3141\n",
            "Epoch 685/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3899 - mae: 0.7762 - mse: 1.3899 - val_loss: 7.1989 - val_mae: 2.1151 - val_mse: 7.1989\n",
            "Epoch 686/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9198 - mae: 0.5552 - mse: 0.9198 - val_loss: 6.8119 - val_mae: 2.0492 - val_mse: 6.8119\n",
            "Epoch 687/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1179 - mae: 0.7253 - mse: 1.1179 - val_loss: 7.1349 - val_mae: 2.1711 - val_mse: 7.1349\n",
            "Epoch 688/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9086 - mae: 0.5236 - mse: 0.9086 - val_loss: 8.0948 - val_mae: 2.2516 - val_mse: 8.0948\n",
            "Epoch 689/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1206 - mae: 0.6766 - mse: 1.1206 - val_loss: 7.0058 - val_mae: 2.1082 - val_mse: 7.0058\n",
            "Epoch 690/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8617 - mae: 0.5770 - mse: 0.8617 - val_loss: 7.9030 - val_mae: 2.2558 - val_mse: 7.9030\n",
            "Epoch 691/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8049 - mae: 0.5276 - mse: 0.8049 - val_loss: 7.7844 - val_mae: 2.2130 - val_mse: 7.7844\n",
            "Epoch 692/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0353 - mae: 0.5707 - mse: 1.0353 - val_loss: 8.4367 - val_mae: 2.2542 - val_mse: 8.4367\n",
            "Epoch 693/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5760 - mae: 0.8738 - mse: 1.5760 - val_loss: 6.9413 - val_mae: 2.0172 - val_mse: 6.9413\n",
            "Epoch 694/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0187 - mae: 0.6654 - mse: 1.0187 - val_loss: 8.1198 - val_mae: 2.1860 - val_mse: 8.1198\n",
            "Epoch 695/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6861 - mae: 0.8124 - mse: 1.6861 - val_loss: 8.4852 - val_mae: 2.2689 - val_mse: 8.4852\n",
            "Epoch 696/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5495 - mae: 0.8298 - mse: 1.5495 - val_loss: 7.7826 - val_mae: 2.1157 - val_mse: 7.7826\n",
            "Epoch 697/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8455 - mae: 0.5599 - mse: 0.8455 - val_loss: 6.9034 - val_mae: 2.1094 - val_mse: 6.9034\n",
            "Epoch 698/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4201 - mae: 0.7244 - mse: 1.4201 - val_loss: 8.0346 - val_mae: 2.0789 - val_mse: 8.0346\n",
            "Epoch 699/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4645 - mae: 0.7434 - mse: 1.4645 - val_loss: 6.7348 - val_mae: 2.1076 - val_mse: 6.7348\n",
            "Epoch 700/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7030 - mae: 0.8927 - mse: 1.7030 - val_loss: 7.3347 - val_mae: 2.0721 - val_mse: 7.3347\n",
            "Epoch 701/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2389 - mae: 0.7188 - mse: 1.2389 - val_loss: 8.1219 - val_mae: 2.3466 - val_mse: 8.1219\n",
            "Epoch 702/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2169 - mae: 0.7552 - mse: 1.2169 - val_loss: 7.2527 - val_mae: 2.2137 - val_mse: 7.2527\n",
            "Epoch 703/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9583 - mae: 0.6197 - mse: 0.9583 - val_loss: 7.4212 - val_mae: 2.1503 - val_mse: 7.4212\n",
            "Epoch 704/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1829 - mae: 0.7139 - mse: 1.1829 - val_loss: 7.9315 - val_mae: 2.2310 - val_mse: 7.9315\n",
            "Epoch 705/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1908 - mae: 0.7086 - mse: 1.1908 - val_loss: 7.4376 - val_mae: 2.2089 - val_mse: 7.4376\n",
            "Epoch 706/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1819 - mae: 0.7069 - mse: 1.1819 - val_loss: 8.4105 - val_mae: 2.2776 - val_mse: 8.4105\n",
            "Epoch 707/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9009 - mae: 0.5539 - mse: 0.9009 - val_loss: 7.4900 - val_mae: 2.2877 - val_mse: 7.4900\n",
            "Epoch 708/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8277 - mae: 0.5298 - mse: 0.8277 - val_loss: 6.8060 - val_mae: 2.0849 - val_mse: 6.8060\n",
            "Epoch 709/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1552 - mae: 0.6265 - mse: 1.1552 - val_loss: 8.2032 - val_mae: 2.2536 - val_mse: 8.2032\n",
            "Epoch 710/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.0151 - mae: 1.0131 - mse: 2.0151 - val_loss: 9.0239 - val_mae: 2.4922 - val_mse: 9.0239\n",
            "Epoch 711/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8475 - mae: 0.8541 - mse: 1.8475 - val_loss: 7.6106 - val_mae: 2.1691 - val_mse: 7.6106\n",
            "Epoch 712/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1716 - mae: 0.6885 - mse: 1.1716 - val_loss: 8.6826 - val_mae: 2.2624 - val_mse: 8.6826\n",
            "Epoch 713/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1140 - mae: 0.6410 - mse: 1.1140 - val_loss: 7.5107 - val_mae: 2.2175 - val_mse: 7.5107\n",
            "Epoch 714/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9917 - mae: 0.5934 - mse: 0.9917 - val_loss: 7.3652 - val_mae: 2.2046 - val_mse: 7.3652\n",
            "Epoch 715/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3134 - mae: 0.7274 - mse: 1.3134 - val_loss: 7.5864 - val_mae: 2.2441 - val_mse: 7.5864\n",
            "Epoch 716/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9481 - mae: 0.5580 - mse: 0.9481 - val_loss: 9.8349 - val_mae: 2.4134 - val_mse: 9.8349\n",
            "Epoch 717/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.4916 - mae: 1.1018 - mse: 2.4916 - val_loss: 7.3884 - val_mae: 2.2249 - val_mse: 7.3884\n",
            "Epoch 718/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2677 - mae: 0.7304 - mse: 1.2677 - val_loss: 7.2881 - val_mae: 2.2043 - val_mse: 7.2881\n",
            "Epoch 719/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6719 - mae: 0.8785 - mse: 1.6719 - val_loss: 7.5373 - val_mae: 2.1652 - val_mse: 7.5373\n",
            "Epoch 720/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6104 - mae: 0.8229 - mse: 1.6104 - val_loss: 7.9537 - val_mae: 2.1471 - val_mse: 7.9537\n",
            "Epoch 721/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9861 - mae: 0.6358 - mse: 0.9861 - val_loss: 7.1270 - val_mae: 2.1649 - val_mse: 7.1270\n",
            "Epoch 722/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7383 - mae: 0.5245 - mse: 0.7383 - val_loss: 7.3596 - val_mae: 2.1713 - val_mse: 7.3596\n",
            "Epoch 723/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3200 - mae: 0.7333 - mse: 1.3200 - val_loss: 7.1201 - val_mae: 2.1498 - val_mse: 7.1201\n",
            "Epoch 724/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9302 - mae: 0.5270 - mse: 0.9302 - val_loss: 7.0500 - val_mae: 2.1185 - val_mse: 7.0500\n",
            "Epoch 725/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3813 - mae: 0.7689 - mse: 1.3813 - val_loss: 7.6219 - val_mae: 2.1910 - val_mse: 7.6219\n",
            "Epoch 726/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9216 - mae: 0.5767 - mse: 0.9216 - val_loss: 7.1557 - val_mae: 2.1333 - val_mse: 7.1557\n",
            "Epoch 727/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1355 - mae: 0.6195 - mse: 1.1355 - val_loss: 8.5736 - val_mae: 2.3532 - val_mse: 8.5736\n",
            "Epoch 728/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0805 - mae: 0.6321 - mse: 1.0805 - val_loss: 6.8509 - val_mae: 2.1139 - val_mse: 6.8509\n",
            "Epoch 729/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1793 - mae: 0.6119 - mse: 1.1793 - val_loss: 8.4298 - val_mae: 2.2272 - val_mse: 8.4298\n",
            "Epoch 730/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0221 - mae: 0.6457 - mse: 1.0221 - val_loss: 6.7880 - val_mae: 2.0527 - val_mse: 6.7880\n",
            "Epoch 731/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3378 - mae: 0.7470 - mse: 1.3378 - val_loss: 9.6017 - val_mae: 2.4082 - val_mse: 9.6017\n",
            "Epoch 732/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4297 - mae: 0.8362 - mse: 1.4297 - val_loss: 7.5000 - val_mae: 2.2653 - val_mse: 7.5000\n",
            "Epoch 733/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2967 - mae: 0.7280 - mse: 1.2967 - val_loss: 7.3079 - val_mae: 2.1501 - val_mse: 7.3079\n",
            "Epoch 734/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1843 - mae: 0.7343 - mse: 1.1843 - val_loss: 7.5697 - val_mae: 2.1528 - val_mse: 7.5697\n",
            "Epoch 735/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2078 - mae: 0.6312 - mse: 1.2078 - val_loss: 7.0019 - val_mae: 2.1289 - val_mse: 7.0019\n",
            "Epoch 736/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8818 - mae: 0.5750 - mse: 0.8818 - val_loss: 7.3652 - val_mae: 2.2187 - val_mse: 7.3652\n",
            "Epoch 737/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9051 - mae: 0.5434 - mse: 0.9051 - val_loss: 6.9341 - val_mae: 2.1205 - val_mse: 6.9341\n",
            "Epoch 738/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9355 - mae: 0.6106 - mse: 0.9355 - val_loss: 7.3150 - val_mae: 2.1727 - val_mse: 7.3150\n",
            "Epoch 739/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8073 - mae: 0.5350 - mse: 0.8073 - val_loss: 6.9664 - val_mae: 2.1328 - val_mse: 6.9664\n",
            "Epoch 740/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7147 - mae: 0.4938 - mse: 0.7147 - val_loss: 6.5952 - val_mae: 2.0416 - val_mse: 6.5952\n",
            "Epoch 741/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9854 - mae: 0.6212 - mse: 0.9854 - val_loss: 7.6634 - val_mae: 2.2246 - val_mse: 7.6634\n",
            "Epoch 742/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7127 - mae: 0.5360 - mse: 0.7127 - val_loss: 6.7080 - val_mae: 2.0486 - val_mse: 6.7080\n",
            "Epoch 743/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9490 - mae: 0.5740 - mse: 0.9490 - val_loss: 7.5491 - val_mae: 2.0822 - val_mse: 7.5491\n",
            "Epoch 744/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3204 - mae: 0.7023 - mse: 1.3204 - val_loss: 6.7141 - val_mae: 2.1080 - val_mse: 6.7141\n",
            "Epoch 745/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8107 - mae: 0.5541 - mse: 0.8107 - val_loss: 7.5704 - val_mae: 2.1351 - val_mse: 7.5704\n",
            "Epoch 746/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9735 - mae: 0.5567 - mse: 0.9735 - val_loss: 7.9076 - val_mae: 2.2963 - val_mse: 7.9076\n",
            "Epoch 747/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7666 - mae: 0.5195 - mse: 0.7666 - val_loss: 6.6758 - val_mae: 2.0514 - val_mse: 6.6758\n",
            "Epoch 748/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4563 - mae: 0.7068 - mse: 1.4563 - val_loss: 7.3014 - val_mae: 2.1449 - val_mse: 7.3014\n",
            "Epoch 749/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7714 - mae: 0.5194 - mse: 0.7714 - val_loss: 7.5948 - val_mae: 2.2680 - val_mse: 7.5948\n",
            "Epoch 750/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8276 - mae: 0.5653 - mse: 0.8276 - val_loss: 6.8449 - val_mae: 2.0362 - val_mse: 6.8449\n",
            "Epoch 751/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1333 - mae: 0.6469 - mse: 1.1333 - val_loss: 6.3063 - val_mae: 2.0306 - val_mse: 6.3063\n",
            "Epoch 752/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3056 - mae: 0.7463 - mse: 1.3056 - val_loss: 7.1654 - val_mae: 1.9923 - val_mse: 7.1654\n",
            "Epoch 753/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.2537 - mae: 1.0402 - mse: 2.2537 - val_loss: 9.0224 - val_mae: 2.2974 - val_mse: 9.0224\n",
            "Epoch 754/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4402 - mae: 0.7750 - mse: 1.4402 - val_loss: 6.8394 - val_mae: 2.0852 - val_mse: 6.8394\n",
            "Epoch 755/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1060 - mae: 0.7155 - mse: 1.1060 - val_loss: 7.0036 - val_mae: 2.1180 - val_mse: 7.0036\n",
            "Epoch 756/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8540 - mae: 0.5379 - mse: 0.8540 - val_loss: 7.0289 - val_mae: 2.1085 - val_mse: 7.0289\n",
            "Epoch 757/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7392 - mae: 0.5310 - mse: 0.7392 - val_loss: 7.1739 - val_mae: 2.1539 - val_mse: 7.1739\n",
            "Epoch 758/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8137 - mae: 0.5113 - mse: 0.8137 - val_loss: 7.4012 - val_mae: 2.1581 - val_mse: 7.4012\n",
            "Epoch 759/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5628 - mae: 0.8188 - mse: 1.5628 - val_loss: 8.2104 - val_mae: 2.3017 - val_mse: 8.2104\n",
            "Epoch 760/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9367 - mae: 0.9571 - mse: 1.9367 - val_loss: 9.7895 - val_mae: 2.3811 - val_mse: 9.7895\n",
            "Epoch 761/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8377 - mae: 0.8725 - mse: 1.8377 - val_loss: 8.3818 - val_mae: 2.3705 - val_mse: 8.3818\n",
            "Epoch 762/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1713 - mae: 0.7367 - mse: 1.1713 - val_loss: 7.4353 - val_mae: 2.1154 - val_mse: 7.4353\n",
            "Epoch 763/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0409 - mae: 0.5871 - mse: 1.0409 - val_loss: 6.3729 - val_mae: 2.0174 - val_mse: 6.3729\n",
            "Epoch 764/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8481 - mae: 0.5141 - mse: 0.8481 - val_loss: 7.6034 - val_mae: 2.2661 - val_mse: 7.6034\n",
            "Epoch 765/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9982 - mae: 0.5555 - mse: 0.9982 - val_loss: 8.0450 - val_mae: 2.2070 - val_mse: 8.0450\n",
            "Epoch 766/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9776 - mae: 0.6224 - mse: 0.9776 - val_loss: 7.5252 - val_mae: 2.2074 - val_mse: 7.5252\n",
            "Epoch 767/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9715 - mae: 0.6108 - mse: 0.9715 - val_loss: 7.5305 - val_mae: 2.2309 - val_mse: 7.5305\n",
            "Epoch 768/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7959 - mae: 0.5221 - mse: 0.7959 - val_loss: 6.8633 - val_mae: 2.1137 - val_mse: 6.8633\n",
            "Epoch 769/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8309 - mae: 0.5747 - mse: 0.8309 - val_loss: 7.5652 - val_mae: 2.1779 - val_mse: 7.5652\n",
            "Epoch 770/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9335 - mae: 0.5455 - mse: 0.9335 - val_loss: 6.8392 - val_mae: 2.1327 - val_mse: 6.8392\n",
            "Epoch 771/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1195 - mae: 0.6317 - mse: 1.1195 - val_loss: 9.1507 - val_mae: 2.3774 - val_mse: 9.1507\n",
            "Epoch 772/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6496 - mae: 0.8799 - mse: 1.6496 - val_loss: 9.3958 - val_mae: 2.3790 - val_mse: 9.3958\n",
            "Epoch 773/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3092 - mae: 1.0826 - mse: 2.3092 - val_loss: 8.3002 - val_mae: 2.3120 - val_mse: 8.3002\n",
            "Epoch 774/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7438 - mae: 0.7991 - mse: 1.7438 - val_loss: 9.1962 - val_mae: 2.3284 - val_mse: 9.1962\n",
            "Epoch 775/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1576 - mae: 0.7136 - mse: 1.1576 - val_loss: 8.7209 - val_mae: 2.3542 - val_mse: 8.7209\n",
            "Epoch 776/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2078 - mae: 0.7233 - mse: 1.2078 - val_loss: 7.6161 - val_mae: 2.2163 - val_mse: 7.6161\n",
            "Epoch 777/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9708 - mae: 0.5555 - mse: 0.9708 - val_loss: 7.8457 - val_mae: 2.1983 - val_mse: 7.8457\n",
            "Epoch 778/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8128 - mae: 0.5068 - mse: 0.8128 - val_loss: 7.3661 - val_mae: 2.1355 - val_mse: 7.3661\n",
            "Epoch 779/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9090 - mae: 0.5323 - mse: 0.9090 - val_loss: 7.4489 - val_mae: 2.1919 - val_mse: 7.4489\n",
            "Epoch 780/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7156 - mae: 0.5209 - mse: 0.7156 - val_loss: 8.2540 - val_mae: 2.2703 - val_mse: 8.2540\n",
            "Epoch 781/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0422 - mae: 0.6469 - mse: 1.0422 - val_loss: 7.6066 - val_mae: 2.2611 - val_mse: 7.6066\n",
            "Epoch 782/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0720 - mae: 0.6468 - mse: 1.0720 - val_loss: 7.8975 - val_mae: 2.0936 - val_mse: 7.8975\n",
            "Epoch 783/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1399 - mae: 0.6182 - mse: 1.1399 - val_loss: 8.3506 - val_mae: 2.3516 - val_mse: 8.3506\n",
            "Epoch 784/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8942 - mae: 0.5576 - mse: 0.8942 - val_loss: 8.0760 - val_mae: 2.2501 - val_mse: 8.0760\n",
            "Epoch 785/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.6850 - mae: 1.1474 - mse: 2.6850 - val_loss: 8.0541 - val_mae: 2.2771 - val_mse: 8.0541\n",
            "Epoch 786/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3018 - mae: 0.7816 - mse: 1.3018 - val_loss: 7.1964 - val_mae: 2.1479 - val_mse: 7.1964\n",
            "Epoch 787/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8888 - mae: 0.6224 - mse: 0.8888 - val_loss: 7.9942 - val_mae: 2.2422 - val_mse: 7.9942\n",
            "Epoch 788/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9566 - mae: 0.5890 - mse: 0.9566 - val_loss: 8.8145 - val_mae: 2.2915 - val_mse: 8.8145\n",
            "Epoch 789/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0283 - mae: 0.6272 - mse: 1.0283 - val_loss: 7.6526 - val_mae: 2.2247 - val_mse: 7.6526\n",
            "Epoch 790/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0021 - mae: 0.5966 - mse: 1.0021 - val_loss: 7.8354 - val_mae: 2.1878 - val_mse: 7.8354\n",
            "Epoch 791/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5928 - mae: 0.8799 - mse: 1.5928 - val_loss: 7.7742 - val_mae: 2.2203 - val_mse: 7.7742\n",
            "Epoch 792/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3075 - mae: 0.6692 - mse: 1.3075 - val_loss: 8.2810 - val_mae: 2.2952 - val_mse: 8.2810\n",
            "Epoch 793/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0289 - mae: 0.6619 - mse: 1.0289 - val_loss: 8.4827 - val_mae: 2.2675 - val_mse: 8.4827\n",
            "Epoch 794/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9590 - mae: 0.6400 - mse: 0.9590 - val_loss: 7.6228 - val_mae: 2.2248 - val_mse: 7.6228\n",
            "Epoch 795/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0889 - mae: 0.6614 - mse: 1.0889 - val_loss: 9.2031 - val_mae: 2.4469 - val_mse: 9.2031\n",
            "Epoch 796/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.9852 - mae: 0.9707 - mse: 1.9852 - val_loss: 8.9200 - val_mae: 2.4695 - val_mse: 8.9200\n",
            "Epoch 797/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6481 - mae: 0.8668 - mse: 1.6481 - val_loss: 10.1590 - val_mae: 2.3504 - val_mse: 10.1590\n",
            "Epoch 798/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1067 - mae: 0.6389 - mse: 1.1067 - val_loss: 8.3708 - val_mae: 2.3605 - val_mse: 8.3708\n",
            "Epoch 799/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9995 - mae: 0.6540 - mse: 0.9995 - val_loss: 8.7283 - val_mae: 2.2983 - val_mse: 8.7283\n",
            "Epoch 800/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1948 - mae: 0.7852 - mse: 1.1948 - val_loss: 8.3797 - val_mae: 2.3655 - val_mse: 8.3797\n",
            "Epoch 801/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1164 - mae: 0.5976 - mse: 1.1164 - val_loss: 7.8129 - val_mae: 2.0530 - val_mse: 7.8129\n",
            "Epoch 802/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1134 - mae: 0.6425 - mse: 1.1134 - val_loss: 7.5450 - val_mae: 2.1870 - val_mse: 7.5450\n",
            "Epoch 803/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2754 - mae: 0.7466 - mse: 1.2754 - val_loss: 7.5769 - val_mae: 2.2391 - val_mse: 7.5769\n",
            "Epoch 804/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2543 - mae: 0.6995 - mse: 1.2543 - val_loss: 7.1727 - val_mae: 2.1224 - val_mse: 7.1727\n",
            "Epoch 805/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4229 - mae: 0.8248 - mse: 1.4229 - val_loss: 7.8485 - val_mae: 2.2057 - val_mse: 7.8485\n",
            "Epoch 806/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0890 - mae: 0.6547 - mse: 1.0890 - val_loss: 14.0168 - val_mae: 2.8571 - val_mse: 14.0168\n",
            "Epoch 807/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8348 - mae: 1.1576 - mse: 2.8348 - val_loss: 7.3668 - val_mae: 2.1293 - val_mse: 7.3668\n",
            "Epoch 808/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4560 - mae: 0.7179 - mse: 1.4560 - val_loss: 7.6946 - val_mae: 2.1890 - val_mse: 7.6946\n",
            "Epoch 809/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8830 - mae: 0.6085 - mse: 0.8830 - val_loss: 7.7173 - val_mae: 2.2603 - val_mse: 7.7173\n",
            "Epoch 810/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3339 - mae: 0.7374 - mse: 1.3339 - val_loss: 7.6132 - val_mae: 2.1355 - val_mse: 7.6132\n",
            "Epoch 811/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0559 - mae: 0.6274 - mse: 1.0559 - val_loss: 7.8679 - val_mae: 2.3051 - val_mse: 7.8679\n",
            "Epoch 812/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1051 - mae: 0.9662 - mse: 2.1051 - val_loss: 9.1751 - val_mae: 2.4416 - val_mse: 9.1751\n",
            "Epoch 813/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1972 - mae: 0.7451 - mse: 1.1972 - val_loss: 7.6319 - val_mae: 2.1839 - val_mse: 7.6319\n",
            "Epoch 814/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1785 - mae: 0.6949 - mse: 1.1785 - val_loss: 7.0502 - val_mae: 2.1306 - val_mse: 7.0502\n",
            "Epoch 815/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1606 - mae: 0.6753 - mse: 1.1606 - val_loss: 8.2126 - val_mae: 2.2915 - val_mse: 8.2126\n",
            "Epoch 816/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3840 - mae: 0.7643 - mse: 1.3840 - val_loss: 7.8226 - val_mae: 2.1580 - val_mse: 7.8226\n",
            "Epoch 817/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1470 - mae: 0.6962 - mse: 1.1470 - val_loss: 8.3339 - val_mae: 2.2882 - val_mse: 8.3339\n",
            "Epoch 818/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0069 - mae: 0.6570 - mse: 1.0069 - val_loss: 7.2531 - val_mae: 2.1093 - val_mse: 7.2531\n",
            "Epoch 819/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6842 - mae: 0.8722 - mse: 1.6842 - val_loss: 7.5837 - val_mae: 2.2051 - val_mse: 7.5837\n",
            "Epoch 820/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8860 - mae: 0.5772 - mse: 0.8860 - val_loss: 7.3200 - val_mae: 2.2177 - val_mse: 7.3200\n",
            "Epoch 821/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8660 - mae: 0.5254 - mse: 0.8660 - val_loss: 7.7623 - val_mae: 2.2790 - val_mse: 7.7623\n",
            "Epoch 822/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8565 - mae: 0.5366 - mse: 0.8565 - val_loss: 8.1903 - val_mae: 2.3016 - val_mse: 8.1903\n",
            "Epoch 823/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4908 - mae: 0.8400 - mse: 1.4908 - val_loss: 7.6648 - val_mae: 2.2254 - val_mse: 7.6648\n",
            "Epoch 824/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9167 - mae: 0.9449 - mse: 1.9167 - val_loss: 9.5739 - val_mae: 2.3014 - val_mse: 9.5739\n",
            "Epoch 825/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5255 - mae: 0.8294 - mse: 1.5255 - val_loss: 10.7111 - val_mae: 2.5459 - val_mse: 10.7111\n",
            "Epoch 826/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.8933 - mae: 0.9552 - mse: 1.8933 - val_loss: 7.6383 - val_mae: 2.2231 - val_mse: 7.6383\n",
            "Epoch 827/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1823 - mae: 0.7403 - mse: 1.1823 - val_loss: 6.6990 - val_mae: 2.0856 - val_mse: 6.6990\n",
            "Epoch 828/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0363 - mae: 0.6428 - mse: 1.0363 - val_loss: 8.4976 - val_mae: 2.4174 - val_mse: 8.4976\n",
            "Epoch 829/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2862 - mae: 0.6979 - mse: 1.2862 - val_loss: 7.6203 - val_mae: 2.2094 - val_mse: 7.6203\n",
            "Epoch 830/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9287 - mae: 0.9254 - mse: 1.9287 - val_loss: 8.5720 - val_mae: 2.2829 - val_mse: 8.5720\n",
            "Epoch 831/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2016 - mae: 0.7122 - mse: 1.2016 - val_loss: 6.8439 - val_mae: 1.9790 - val_mse: 6.8439\n",
            "Epoch 832/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9118 - mae: 0.5256 - mse: 0.9118 - val_loss: 7.4201 - val_mae: 2.2110 - val_mse: 7.4201\n",
            "Epoch 833/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8679 - mae: 0.5713 - mse: 0.8679 - val_loss: 7.3321 - val_mae: 2.1789 - val_mse: 7.3321\n",
            "Epoch 834/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2192 - mae: 0.6532 - mse: 1.2192 - val_loss: 8.7727 - val_mae: 2.2988 - val_mse: 8.7727\n",
            "Epoch 835/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.6632 - mae: 0.7816 - mse: 1.6632 - val_loss: 7.9023 - val_mae: 2.2663 - val_mse: 7.9023\n",
            "Epoch 836/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3766 - mae: 0.7177 - mse: 1.3766 - val_loss: 8.2358 - val_mae: 2.3858 - val_mse: 8.2358\n",
            "Epoch 837/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8777 - mae: 0.5946 - mse: 0.8777 - val_loss: 6.8671 - val_mae: 2.0794 - val_mse: 6.8671\n",
            "Epoch 838/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8485 - mae: 0.5290 - mse: 0.8485 - val_loss: 8.1376 - val_mae: 2.3454 - val_mse: 8.1376\n",
            "Epoch 839/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1241 - mae: 0.6624 - mse: 1.1241 - val_loss: 7.1562 - val_mae: 2.1508 - val_mse: 7.1562\n",
            "Epoch 840/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3914 - mae: 0.7688 - mse: 1.3914 - val_loss: 8.3705 - val_mae: 2.3080 - val_mse: 8.3705\n",
            "Epoch 841/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9121 - mae: 0.5651 - mse: 0.9121 - val_loss: 7.9595 - val_mae: 2.3043 - val_mse: 7.9595\n",
            "Epoch 842/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6511 - mae: 0.4651 - mse: 0.6511 - val_loss: 7.8634 - val_mae: 2.2449 - val_mse: 7.8634\n",
            "Epoch 843/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9762 - mae: 0.5974 - mse: 0.9762 - val_loss: 7.7992 - val_mae: 2.2198 - val_mse: 7.7992\n",
            "Epoch 844/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8728 - mae: 0.5254 - mse: 0.8728 - val_loss: 8.9757 - val_mae: 2.4030 - val_mse: 8.9757\n",
            "Epoch 845/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4260 - mae: 0.8320 - mse: 1.4260 - val_loss: 7.4835 - val_mae: 2.1410 - val_mse: 7.4835\n",
            "Epoch 846/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7995 - mae: 0.5560 - mse: 0.7995 - val_loss: 7.4139 - val_mae: 2.1694 - val_mse: 7.4139\n",
            "Epoch 847/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8369 - mae: 0.5562 - mse: 0.8369 - val_loss: 8.3702 - val_mae: 2.3276 - val_mse: 8.3702\n",
            "Epoch 848/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1788 - mae: 0.7632 - mse: 1.1788 - val_loss: 8.6492 - val_mae: 2.3612 - val_mse: 8.6492\n",
            "Epoch 849/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.3524 - mae: 1.0132 - mse: 2.3524 - val_loss: 8.4120 - val_mae: 2.2231 - val_mse: 8.4120\n",
            "Epoch 850/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5820 - mae: 0.8268 - mse: 1.5820 - val_loss: 8.8292 - val_mae: 2.4107 - val_mse: 8.8292\n",
            "Epoch 851/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9809 - mae: 0.6308 - mse: 0.9809 - val_loss: 7.6222 - val_mae: 2.1980 - val_mse: 7.6222\n",
            "Epoch 852/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9526 - mae: 0.6220 - mse: 0.9526 - val_loss: 7.6945 - val_mae: 2.2240 - val_mse: 7.6945\n",
            "Epoch 853/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8058 - mae: 0.5264 - mse: 0.8058 - val_loss: 8.5896 - val_mae: 2.3311 - val_mse: 8.5896\n",
            "Epoch 854/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0671 - mae: 0.6943 - mse: 1.0671 - val_loss: 7.6996 - val_mae: 2.1535 - val_mse: 7.6996\n",
            "Epoch 855/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8119 - mae: 0.5532 - mse: 0.8119 - val_loss: 7.3255 - val_mae: 2.2106 - val_mse: 7.3255\n",
            "Epoch 856/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6488 - mae: 0.4465 - mse: 0.6488 - val_loss: 7.1745 - val_mae: 2.1144 - val_mse: 7.1745\n",
            "Epoch 857/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7282 - mae: 0.5300 - mse: 0.7282 - val_loss: 7.3617 - val_mae: 2.1160 - val_mse: 7.3617\n",
            "Epoch 858/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8036 - mae: 0.4988 - mse: 0.8036 - val_loss: 7.8110 - val_mae: 2.2100 - val_mse: 7.8110\n",
            "Epoch 859/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0316 - mae: 0.5529 - mse: 1.0316 - val_loss: 9.9671 - val_mae: 2.4251 - val_mse: 9.9671\n",
            "Epoch 860/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8707 - mae: 1.2494 - mse: 2.8707 - val_loss: 8.7089 - val_mae: 2.1989 - val_mse: 8.7089\n",
            "Epoch 861/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.1087 - mae: 0.9910 - mse: 2.1087 - val_loss: 7.5344 - val_mae: 2.2387 - val_mse: 7.5344\n",
            "Epoch 862/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8344 - mae: 0.5530 - mse: 0.8344 - val_loss: 7.3953 - val_mae: 2.1115 - val_mse: 7.3953\n",
            "Epoch 863/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5123 - mae: 0.8073 - mse: 1.5123 - val_loss: 8.0299 - val_mae: 2.3570 - val_mse: 8.0299\n",
            "Epoch 864/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7989 - mae: 0.8411 - mse: 1.7989 - val_loss: 7.9655 - val_mae: 2.1409 - val_mse: 7.9655\n",
            "Epoch 865/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1201 - mae: 0.7106 - mse: 1.1201 - val_loss: 7.8117 - val_mae: 2.2669 - val_mse: 7.8117\n",
            "Epoch 866/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1969 - mae: 0.5890 - mse: 1.1969 - val_loss: 11.1986 - val_mae: 2.6084 - val_mse: 11.1986\n",
            "Epoch 867/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3875 - mae: 0.7501 - mse: 1.3875 - val_loss: 7.9395 - val_mae: 2.3032 - val_mse: 7.9395\n",
            "Epoch 868/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9580 - mae: 0.6162 - mse: 0.9580 - val_loss: 7.9387 - val_mae: 2.3115 - val_mse: 7.9387\n",
            "Epoch 869/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0281 - mae: 0.5848 - mse: 1.0281 - val_loss: 7.5731 - val_mae: 2.2644 - val_mse: 7.5731\n",
            "Epoch 870/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4589 - mae: 0.8100 - mse: 1.4589 - val_loss: 7.5323 - val_mae: 2.1635 - val_mse: 7.5323\n",
            "Epoch 871/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9483 - mae: 0.5942 - mse: 0.9483 - val_loss: 7.1844 - val_mae: 2.1737 - val_mse: 7.1844\n",
            "Epoch 872/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1452 - mae: 0.6581 - mse: 1.1452 - val_loss: 8.1969 - val_mae: 2.1853 - val_mse: 8.1969\n",
            "Epoch 873/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9098 - mae: 0.5888 - mse: 0.9098 - val_loss: 8.0090 - val_mae: 2.1972 - val_mse: 8.0090\n",
            "Epoch 874/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1052 - mae: 0.7078 - mse: 1.1052 - val_loss: 6.8213 - val_mae: 2.0500 - val_mse: 6.8213\n",
            "Epoch 875/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7816 - mae: 0.5044 - mse: 0.7816 - val_loss: 7.3339 - val_mae: 2.1300 - val_mse: 7.3339\n",
            "Epoch 876/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6611 - mae: 0.4738 - mse: 0.6611 - val_loss: 7.5092 - val_mae: 2.2323 - val_mse: 7.5092\n",
            "Epoch 877/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6629 - mae: 0.4324 - mse: 0.6629 - val_loss: 7.3017 - val_mae: 2.1164 - val_mse: 7.3017\n",
            "Epoch 878/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9649 - mae: 0.5867 - mse: 0.9649 - val_loss: 7.3226 - val_mae: 2.1327 - val_mse: 7.3226\n",
            "Epoch 879/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6207 - mae: 0.4669 - mse: 0.6207 - val_loss: 7.8319 - val_mae: 2.2254 - val_mse: 7.8319\n",
            "Epoch 880/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3827 - mae: 0.7556 - mse: 1.3827 - val_loss: 7.8622 - val_mae: 2.2565 - val_mse: 7.8622\n",
            "Epoch 881/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7823 - mae: 0.5218 - mse: 0.7823 - val_loss: 8.2383 - val_mae: 2.2464 - val_mse: 8.2383\n",
            "Epoch 882/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7439 - mae: 0.5132 - mse: 0.7439 - val_loss: 7.1336 - val_mae: 2.1969 - val_mse: 7.1336\n",
            "Epoch 883/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6845 - mae: 0.4673 - mse: 0.6845 - val_loss: 7.3954 - val_mae: 2.1808 - val_mse: 7.3954\n",
            "Epoch 884/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8701 - mae: 0.5455 - mse: 0.8701 - val_loss: 7.0698 - val_mae: 2.0890 - val_mse: 7.0698\n",
            "Epoch 885/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6030 - mae: 0.4424 - mse: 0.6030 - val_loss: 7.5423 - val_mae: 2.1887 - val_mse: 7.5423\n",
            "Epoch 886/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7205 - mae: 0.4961 - mse: 0.7205 - val_loss: 7.5197 - val_mae: 2.1320 - val_mse: 7.5197\n",
            "Epoch 887/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7741 - mae: 0.5351 - mse: 0.7741 - val_loss: 8.7759 - val_mae: 2.3122 - val_mse: 8.7759\n",
            "Epoch 888/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3325 - mae: 0.7898 - mse: 1.3325 - val_loss: 7.4130 - val_mae: 2.1608 - val_mse: 7.4130\n",
            "Epoch 889/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0018 - mae: 0.6720 - mse: 1.0018 - val_loss: 7.1885 - val_mae: 2.1676 - val_mse: 7.1885\n",
            "Epoch 890/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9044 - mae: 0.5507 - mse: 0.9044 - val_loss: 7.4056 - val_mae: 2.1676 - val_mse: 7.4056\n",
            "Epoch 891/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8013 - mae: 0.4988 - mse: 0.8013 - val_loss: 6.9439 - val_mae: 2.0558 - val_mse: 6.9439\n",
            "Epoch 892/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6168 - mae: 0.4556 - mse: 0.6168 - val_loss: 7.3045 - val_mae: 2.2075 - val_mse: 7.3045\n",
            "Epoch 893/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7005 - mae: 0.4428 - mse: 0.7005 - val_loss: 7.8072 - val_mae: 2.1793 - val_mse: 7.8072\n",
            "Epoch 894/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8288 - mae: 0.5367 - mse: 0.8288 - val_loss: 7.7794 - val_mae: 2.1782 - val_mse: 7.7794\n",
            "Epoch 895/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9033 - mae: 0.5087 - mse: 0.9033 - val_loss: 10.0347 - val_mae: 2.4702 - val_mse: 10.0347\n",
            "Epoch 896/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2962 - mae: 0.7511 - mse: 1.2962 - val_loss: 8.3204 - val_mae: 2.2876 - val_mse: 8.3204\n",
            "Epoch 897/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6197 - mae: 0.7387 - mse: 1.6197 - val_loss: 10.9514 - val_mae: 2.5704 - val_mse: 10.9514\n",
            "Epoch 898/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5360 - mae: 1.1481 - mse: 2.5360 - val_loss: 7.6786 - val_mae: 2.2012 - val_mse: 7.6786\n",
            "Epoch 899/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9065 - mae: 0.5338 - mse: 0.9065 - val_loss: 7.7076 - val_mae: 2.1996 - val_mse: 7.7076\n",
            "Epoch 900/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0474 - mae: 0.6063 - mse: 1.0474 - val_loss: 10.6018 - val_mae: 2.5026 - val_mse: 10.6018\n",
            "Epoch 901/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5130 - mae: 0.8339 - mse: 1.5130 - val_loss: 7.5001 - val_mae: 2.1896 - val_mse: 7.5001\n",
            "Epoch 902/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8709 - mae: 0.5699 - mse: 0.8709 - val_loss: 7.9504 - val_mae: 2.2611 - val_mse: 7.9504\n",
            "Epoch 903/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7030 - mae: 0.9023 - mse: 1.7030 - val_loss: 8.0637 - val_mae: 2.2901 - val_mse: 8.0637\n",
            "Epoch 904/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1929 - mae: 0.6850 - mse: 1.1929 - val_loss: 8.4691 - val_mae: 2.3444 - val_mse: 8.4691\n",
            "Epoch 905/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8621 - mae: 0.5938 - mse: 0.8621 - val_loss: 8.3570 - val_mae: 2.3741 - val_mse: 8.3570\n",
            "Epoch 906/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7787 - mae: 0.5874 - mse: 0.7787 - val_loss: 7.3097 - val_mae: 2.1736 - val_mse: 7.3097\n",
            "Epoch 907/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5963 - mae: 0.4166 - mse: 0.5963 - val_loss: 7.5546 - val_mae: 2.2166 - val_mse: 7.5546\n",
            "Epoch 908/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5334 - mae: 0.4018 - mse: 0.5334 - val_loss: 7.2810 - val_mae: 2.1549 - val_mse: 7.2810\n",
            "Epoch 909/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7652 - mae: 0.4565 - mse: 0.7652 - val_loss: 7.4510 - val_mae: 2.2135 - val_mse: 7.4510\n",
            "Epoch 910/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9099 - mae: 0.6031 - mse: 0.9099 - val_loss: 7.3598 - val_mae: 2.1694 - val_mse: 7.3598\n",
            "Epoch 911/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6977 - mae: 0.5423 - mse: 0.6977 - val_loss: 7.5778 - val_mae: 2.1984 - val_mse: 7.5778\n",
            "Epoch 912/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1481 - mae: 0.6808 - mse: 1.1481 - val_loss: 7.5289 - val_mae: 2.2370 - val_mse: 7.5289\n",
            "Epoch 913/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2276 - mae: 0.6922 - mse: 1.2276 - val_loss: 7.5074 - val_mae: 2.2076 - val_mse: 7.5074\n",
            "Epoch 914/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2634 - mae: 0.6916 - mse: 1.2634 - val_loss: 7.0897 - val_mae: 2.1397 - val_mse: 7.0897\n",
            "Epoch 915/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0042 - mae: 0.6090 - mse: 1.0042 - val_loss: 7.3332 - val_mae: 2.1687 - val_mse: 7.3332\n",
            "Epoch 916/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8167 - mae: 0.4924 - mse: 0.8167 - val_loss: 7.9333 - val_mae: 2.3368 - val_mse: 7.9333\n",
            "Epoch 917/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9693 - mae: 0.5554 - mse: 0.9693 - val_loss: 7.5804 - val_mae: 2.1873 - val_mse: 7.5804\n",
            "Epoch 918/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5987 - mae: 0.4559 - mse: 0.5987 - val_loss: 7.3663 - val_mae: 2.1911 - val_mse: 7.3663\n",
            "Epoch 919/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8807 - mae: 0.4763 - mse: 0.8807 - val_loss: 7.1526 - val_mae: 2.1811 - val_mse: 7.1526\n",
            "Epoch 920/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6184 - mae: 0.7783 - mse: 1.6184 - val_loss: 7.6869 - val_mae: 2.1410 - val_mse: 7.6869\n",
            "Epoch 921/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0203 - mae: 0.6494 - mse: 1.0203 - val_loss: 7.9062 - val_mae: 2.3224 - val_mse: 7.9062\n",
            "Epoch 922/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8691 - mae: 0.5985 - mse: 0.8691 - val_loss: 6.8631 - val_mae: 2.1213 - val_mse: 6.8631\n",
            "Epoch 923/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7623 - mae: 0.5040 - mse: 0.7623 - val_loss: 7.4376 - val_mae: 2.2082 - val_mse: 7.4376\n",
            "Epoch 924/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8577 - mae: 0.5687 - mse: 0.8577 - val_loss: 7.7390 - val_mae: 2.2184 - val_mse: 7.7390\n",
            "Epoch 925/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7060 - mae: 0.4849 - mse: 0.7060 - val_loss: 7.5483 - val_mae: 2.2484 - val_mse: 7.5483\n",
            "Epoch 926/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0809 - mae: 0.6709 - mse: 1.0809 - val_loss: 7.9733 - val_mae: 2.2688 - val_mse: 7.9733\n",
            "Epoch 927/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6848 - mae: 0.5183 - mse: 0.6848 - val_loss: 7.9265 - val_mae: 2.2842 - val_mse: 7.9265\n",
            "Epoch 928/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5877 - mae: 0.7629 - mse: 1.5877 - val_loss: 8.9757 - val_mae: 2.3393 - val_mse: 8.9757\n",
            "Epoch 929/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0746 - mae: 0.6379 - mse: 1.0746 - val_loss: 9.6477 - val_mae: 2.5881 - val_mse: 9.6477\n",
            "Epoch 930/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8480 - mae: 0.6026 - mse: 0.8480 - val_loss: 7.8251 - val_mae: 2.1723 - val_mse: 7.8251\n",
            "Epoch 931/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2104 - mae: 0.6563 - mse: 1.2104 - val_loss: 7.4330 - val_mae: 2.2205 - val_mse: 7.4330\n",
            "Epoch 932/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6797 - mae: 0.5418 - mse: 0.6797 - val_loss: 7.4342 - val_mae: 2.1326 - val_mse: 7.4342\n",
            "Epoch 933/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7774 - mae: 0.4593 - mse: 0.7774 - val_loss: 7.6620 - val_mae: 2.1754 - val_mse: 7.6620\n",
            "Epoch 934/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2033 - mae: 0.6876 - mse: 1.2033 - val_loss: 7.9371 - val_mae: 2.1902 - val_mse: 7.9371\n",
            "Epoch 935/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6056 - mae: 0.8295 - mse: 1.6056 - val_loss: 8.7091 - val_mae: 2.3108 - val_mse: 8.7091\n",
            "Epoch 936/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7125 - mae: 0.9181 - mse: 1.7125 - val_loss: 7.5976 - val_mae: 2.1456 - val_mse: 7.5976\n",
            "Epoch 937/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9620 - mae: 0.6477 - mse: 0.9620 - val_loss: 8.9495 - val_mae: 2.3183 - val_mse: 8.9495\n",
            "Epoch 938/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4120 - mae: 0.8267 - mse: 1.4120 - val_loss: 8.0293 - val_mae: 2.2394 - val_mse: 8.0293\n",
            "Epoch 939/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8816 - mae: 0.5176 - mse: 0.8816 - val_loss: 9.0917 - val_mae: 2.2815 - val_mse: 9.0917\n",
            "Epoch 940/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3305 - mae: 0.6744 - mse: 1.3305 - val_loss: 7.6325 - val_mae: 2.2473 - val_mse: 7.6325\n",
            "Epoch 941/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9063 - mae: 0.5463 - mse: 0.9063 - val_loss: 7.5050 - val_mae: 2.1915 - val_mse: 7.5050\n",
            "Epoch 942/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5851 - mae: 0.4606 - mse: 0.5851 - val_loss: 7.6662 - val_mae: 2.2154 - val_mse: 7.6662\n",
            "Epoch 943/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5379 - mae: 0.4124 - mse: 0.5379 - val_loss: 7.2913 - val_mae: 2.1567 - val_mse: 7.2913\n",
            "Epoch 944/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6666 - mae: 0.4502 - mse: 0.6666 - val_loss: 7.3087 - val_mae: 2.1318 - val_mse: 7.3087\n",
            "Epoch 945/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6845 - mae: 0.4467 - mse: 0.6845 - val_loss: 7.8011 - val_mae: 2.2508 - val_mse: 7.8011\n",
            "Epoch 946/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8321 - mae: 0.4987 - mse: 0.8321 - val_loss: 8.1947 - val_mae: 2.2865 - val_mse: 8.1947\n",
            "Epoch 947/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3303 - mae: 0.7894 - mse: 1.3303 - val_loss: 7.5341 - val_mae: 2.1857 - val_mse: 7.5341\n",
            "Epoch 948/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1120 - mae: 0.6724 - mse: 1.1120 - val_loss: 8.9662 - val_mae: 2.2455 - val_mse: 8.9662\n",
            "Epoch 949/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5507 - mae: 0.7816 - mse: 1.5507 - val_loss: 7.6488 - val_mae: 2.2847 - val_mse: 7.6488\n",
            "Epoch 950/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8630 - mae: 0.5826 - mse: 0.8630 - val_loss: 7.6318 - val_mae: 2.2424 - val_mse: 7.6318\n",
            "Epoch 951/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8436 - mae: 0.5928 - mse: 0.8436 - val_loss: 8.0075 - val_mae: 2.3162 - val_mse: 8.0075\n",
            "Epoch 952/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6483 - mae: 0.5286 - mse: 0.6483 - val_loss: 8.1592 - val_mae: 2.2580 - val_mse: 8.1592\n",
            "Epoch 953/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2316 - mae: 0.7167 - mse: 1.2316 - val_loss: 7.5170 - val_mae: 2.1914 - val_mse: 7.5170\n",
            "Epoch 954/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9971 - mae: 0.6216 - mse: 0.9971 - val_loss: 7.3780 - val_mae: 2.1679 - val_mse: 7.3780\n",
            "Epoch 955/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7758 - mae: 0.5238 - mse: 0.7758 - val_loss: 7.4758 - val_mae: 2.1861 - val_mse: 7.4758\n",
            "Epoch 956/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7548 - mae: 0.5308 - mse: 0.7548 - val_loss: 8.4611 - val_mae: 2.4285 - val_mse: 8.4611\n",
            "Epoch 957/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8819 - mae: 0.5983 - mse: 0.8819 - val_loss: 8.3741 - val_mae: 2.3214 - val_mse: 8.3741\n",
            "Epoch 958/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1436 - mae: 0.7503 - mse: 1.1436 - val_loss: 7.6414 - val_mae: 2.1676 - val_mse: 7.6414\n",
            "Epoch 959/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6609 - mae: 0.4783 - mse: 0.6609 - val_loss: 7.5360 - val_mae: 2.2177 - val_mse: 7.5360\n",
            "Epoch 960/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8134 - mae: 0.4971 - mse: 0.8134 - val_loss: 7.7349 - val_mae: 2.2327 - val_mse: 7.7349\n",
            "Epoch 961/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.3832 - mae: 0.7610 - mse: 1.3832 - val_loss: 7.9877 - val_mae: 2.2253 - val_mse: 7.9877\n",
            "Epoch 962/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9639 - mae: 0.6086 - mse: 0.9639 - val_loss: 7.1157 - val_mae: 2.1536 - val_mse: 7.1157\n",
            "Epoch 963/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8520 - mae: 0.5326 - mse: 0.8520 - val_loss: 8.4077 - val_mae: 2.2711 - val_mse: 8.4077\n",
            "Epoch 964/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5495 - mae: 0.8810 - mse: 1.5495 - val_loss: 7.5994 - val_mae: 2.1032 - val_mse: 7.5994\n",
            "Epoch 965/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0061 - mae: 0.5571 - mse: 1.0061 - val_loss: 7.3830 - val_mae: 2.2245 - val_mse: 7.3830\n",
            "Epoch 966/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8358 - mae: 0.5170 - mse: 0.8358 - val_loss: 7.4940 - val_mae: 2.1885 - val_mse: 7.4940\n",
            "Epoch 967/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.0488 - mae: 0.6819 - mse: 1.0488 - val_loss: 8.4644 - val_mae: 2.3011 - val_mse: 8.4644\n",
            "Epoch 968/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9577 - mae: 0.6450 - mse: 0.9577 - val_loss: 8.1692 - val_mae: 2.2298 - val_mse: 8.1692\n",
            "Epoch 969/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8123 - mae: 0.5393 - mse: 0.8123 - val_loss: 7.7542 - val_mae: 2.1609 - val_mse: 7.7542\n",
            "Epoch 970/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.8192 - mae: 0.5154 - mse: 0.8192 - val_loss: 9.5774 - val_mae: 2.4148 - val_mse: 9.5774\n",
            "Epoch 971/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1516 - mae: 0.6969 - mse: 1.1516 - val_loss: 7.8040 - val_mae: 2.2420 - val_mse: 7.8040\n",
            "Epoch 972/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7189 - mae: 0.5293 - mse: 0.7189 - val_loss: 7.8429 - val_mae: 2.2545 - val_mse: 7.8429\n",
            "Epoch 973/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8337 - mae: 0.5529 - mse: 0.8337 - val_loss: 8.9502 - val_mae: 2.4901 - val_mse: 8.9502\n",
            "Epoch 974/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6776 - mae: 0.4533 - mse: 0.6776 - val_loss: 7.6563 - val_mae: 2.2234 - val_mse: 7.6563\n",
            "Epoch 975/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6329 - mae: 0.4253 - mse: 0.6329 - val_loss: 7.7019 - val_mae: 2.2557 - val_mse: 7.7019\n",
            "Epoch 976/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.4630 - mae: 0.7320 - mse: 1.4630 - val_loss: 7.5988 - val_mae: 2.2270 - val_mse: 7.5988\n",
            "Epoch 977/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9759 - mae: 0.5891 - mse: 0.9759 - val_loss: 8.8620 - val_mae: 2.3195 - val_mse: 8.8620\n",
            "Epoch 978/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.7615 - mae: 0.9679 - mse: 1.7615 - val_loss: 7.1939 - val_mae: 2.1793 - val_mse: 7.1939\n",
            "Epoch 979/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2281 - mae: 0.7326 - mse: 1.2281 - val_loss: 8.0644 - val_mae: 2.1919 - val_mse: 8.0644\n",
            "Epoch 980/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.9573 - mae: 0.6155 - mse: 0.9573 - val_loss: 8.0810 - val_mae: 2.3060 - val_mse: 8.0810\n",
            "Epoch 981/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7168 - mae: 0.5443 - mse: 0.7168 - val_loss: 8.8645 - val_mae: 2.3317 - val_mse: 8.8645\n",
            "Epoch 982/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6279 - mae: 0.7948 - mse: 1.6279 - val_loss: 8.5364 - val_mae: 2.3420 - val_mse: 8.5364\n",
            "Epoch 983/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9178 - mae: 0.5863 - mse: 0.9178 - val_loss: 9.4873 - val_mae: 2.4222 - val_mse: 9.4873\n",
            "Epoch 984/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8551 - mae: 0.5824 - mse: 0.8551 - val_loss: 7.3993 - val_mae: 2.1503 - val_mse: 7.3993\n",
            "Epoch 985/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6212 - mae: 0.4706 - mse: 0.6212 - val_loss: 8.1875 - val_mae: 2.2649 - val_mse: 8.1875\n",
            "Epoch 986/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9214 - mae: 0.5800 - mse: 0.9214 - val_loss: 7.9198 - val_mae: 2.2732 - val_mse: 7.9198\n",
            "Epoch 987/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.2003 - mae: 0.7467 - mse: 1.2003 - val_loss: 7.4362 - val_mae: 2.0434 - val_mse: 7.4362\n",
            "Epoch 988/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7271 - mae: 0.5317 - mse: 0.7271 - val_loss: 8.3372 - val_mae: 2.2749 - val_mse: 8.3372\n",
            "Epoch 989/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.1018 - mae: 0.7029 - mse: 1.1018 - val_loss: 9.8816 - val_mae: 2.4232 - val_mse: 9.8816\n",
            "Epoch 990/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.1603 - mae: 0.9356 - mse: 2.1603 - val_loss: 7.4800 - val_mae: 2.1694 - val_mse: 7.4800\n",
            "Epoch 991/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7452 - mae: 0.5164 - mse: 0.7452 - val_loss: 7.6182 - val_mae: 2.1811 - val_mse: 7.6182\n",
            "Epoch 992/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6349 - mae: 0.5052 - mse: 0.6349 - val_loss: 6.9215 - val_mae: 2.0579 - val_mse: 6.9215\n",
            "Epoch 993/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5909 - mae: 0.4799 - mse: 0.5909 - val_loss: 7.0599 - val_mae: 2.1168 - val_mse: 7.0599\n",
            "Epoch 994/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5058 - mae: 0.4559 - mse: 0.5058 - val_loss: 7.7828 - val_mae: 2.2402 - val_mse: 7.7828\n",
            "Epoch 995/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4848 - mae: 0.4512 - mse: 0.4848 - val_loss: 7.6100 - val_mae: 2.2069 - val_mse: 7.6100\n",
            "Epoch 996/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4640 - mae: 0.3845 - mse: 0.4640 - val_loss: 7.5823 - val_mae: 2.2114 - val_mse: 7.5823\n",
            "Epoch 997/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6640 - mae: 0.4717 - mse: 0.6640 - val_loss: 7.9801 - val_mae: 2.2752 - val_mse: 7.9801\n",
            "Epoch 998/1000\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.6250 - mae: 0.6567 - mse: 1.6250 - val_loss: 10.5893 - val_mae: 2.5283 - val_mse: 10.5893\n",
            "Epoch 999/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.9004 - mae: 1.6243 - mse: 4.9004 - val_loss: 12.1340 - val_mae: 2.6239 - val_mse: 12.1340\n",
            "Epoch 1000/1000\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.4832 - mae: 1.3101 - mse: 3.4832 - val_loss: 7.2731 - val_mae: 2.1037 - val_mse: 7.2731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehZTtgJ0ckpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "7f8872d0-fddf-4013-c645-d72526533f28"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mae</th>\n",
              "      <th>val_mse</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>455.243011</td>\n",
              "      <td>19.493290</td>\n",
              "      <td>455.243011</td>\n",
              "      <td>183.089294</td>\n",
              "      <td>11.354987</td>\n",
              "      <td>183.089294</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>211.967224</td>\n",
              "      <td>12.142350</td>\n",
              "      <td>211.967224</td>\n",
              "      <td>262.453430</td>\n",
              "      <td>14.389376</td>\n",
              "      <td>262.453430</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>110.964966</td>\n",
              "      <td>8.270107</td>\n",
              "      <td>110.964966</td>\n",
              "      <td>15.202570</td>\n",
              "      <td>3.135247</td>\n",
              "      <td>15.202570</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26.698393</td>\n",
              "      <td>3.779571</td>\n",
              "      <td>26.698393</td>\n",
              "      <td>18.235312</td>\n",
              "      <td>3.263858</td>\n",
              "      <td>18.235312</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>38.453354</td>\n",
              "      <td>4.530128</td>\n",
              "      <td>38.453354</td>\n",
              "      <td>19.228006</td>\n",
              "      <td>3.133916</td>\n",
              "      <td>19.228006</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0.464038</td>\n",
              "      <td>0.384452</td>\n",
              "      <td>0.464038</td>\n",
              "      <td>7.582271</td>\n",
              "      <td>2.211386</td>\n",
              "      <td>7.582271</td>\n",
              "      <td>995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0.664012</td>\n",
              "      <td>0.471737</td>\n",
              "      <td>0.664012</td>\n",
              "      <td>7.980059</td>\n",
              "      <td>2.275152</td>\n",
              "      <td>7.980059</td>\n",
              "      <td>996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1.624959</td>\n",
              "      <td>0.656666</td>\n",
              "      <td>1.624959</td>\n",
              "      <td>10.589282</td>\n",
              "      <td>2.528329</td>\n",
              "      <td>10.589282</td>\n",
              "      <td>997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>4.900444</td>\n",
              "      <td>1.624340</td>\n",
              "      <td>4.900444</td>\n",
              "      <td>12.134035</td>\n",
              "      <td>2.623864</td>\n",
              "      <td>12.134035</td>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>3.483240</td>\n",
              "      <td>1.310077</td>\n",
              "      <td>3.483240</td>\n",
              "      <td>7.273057</td>\n",
              "      <td>2.103741</td>\n",
              "      <td>7.273057</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           loss        mae         mse  ...    val_mae     val_mse  epoch\n",
              "0    455.243011  19.493290  455.243011  ...  11.354987  183.089294      0\n",
              "1    211.967224  12.142350  211.967224  ...  14.389376  262.453430      1\n",
              "2    110.964966   8.270107  110.964966  ...   3.135247   15.202570      2\n",
              "3     26.698393   3.779571   26.698393  ...   3.263858   18.235312      3\n",
              "4     38.453354   4.530128   38.453354  ...   3.133916   19.228006      4\n",
              "..          ...        ...         ...  ...        ...         ...    ...\n",
              "995    0.464038   0.384452    0.464038  ...   2.211386    7.582271    995\n",
              "996    0.664012   0.471737    0.664012  ...   2.275152    7.980059    996\n",
              "997    1.624959   0.656666    1.624959  ...   2.528329   10.589282    997\n",
              "998    4.900444   1.624340    4.900444  ...   2.623864   12.134035    998\n",
              "999    3.483240   1.310077    3.483240  ...   2.103741    7.273057    999\n",
              "\n",
              "[1000 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGfmqL8thnG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "4244baeb-bbc3-4c63-b392-e881b2cd5402"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist['epoch'], hist['mse'])\n",
        "plt.plot(hist['epoch'], hist['val_mse'])\n",
        "plt.show()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEJR4lq1iA9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "33997049-a626-4991-82d7-6262f384a66f"
      },
      "source": [
        "############################################\n",
        "# 주택가격 예측하기_회귀\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "(train_X, train_Y), (test_X, test_Y) = boston_housing.load_data()\n",
        "train_X\n",
        "\n",
        "# 보스턴 주택 가격 데이터세트는 1978년 미국 보스턴 지역의 주택 가격으로,\n",
        "# [01]  CRIM 자치시(town) 별 1인당 범죄율  \n",
        "# [02]  ZN 25,000 평방피트를 초과하는 거주지역의 비율  \n",
        "# [03]  INDUS 비소매상업지역이 점유하고 있는 토지의 비율  \n",
        "# [04]  CHAS 찰스강에 대한 더미변수(강의 경계에 위치한 경우는 1, 아니면 0) \n",
        "# [05]  NOX 10ppm 당 농축 일산화질소 \n",
        "# [06]  RM 주택 1가구당 평균 방의 개수  \n",
        "# [07]  AGE 1940년 이전에 건축된 소유주택의 비율\n",
        "# [08]  DIS 5개의 보스턴 직업센터까지의 접근성 지수 \n",
        "# [09]  RAD 방사형 도로까지의 접근성 지수 \n",
        "# [10]  TAX 10,000 달러 당 재산세율 \n",
        "# [11]  PTRATIO 자치시(town)별 학생/교사 비율  \n",
        "# [12]  B 1000(Bk-0.63)^2, 여기서 Bk는 자치시별 흑인의 비율을 말함.\n",
        "# [13]  LSTAT 모집단의 하위계층의 비율(%) \n",
        "# [14]  MEDV 본인 소유의 주택가격(중앙값) (단위: $1,000)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
              "        3.96900e+02, 1.87200e+01],\n",
              "       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
              "        3.95380e+02, 3.11000e+00],\n",
              "       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
              "        3.75520e+02, 3.26000e+00],\n",
              "       ...,\n",
              "       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
              "        3.62250e+02, 7.83000e+00],\n",
              "       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
              "        2.61950e+02, 1.57900e+01],\n",
              "       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
              "        3.76700e+02, 4.38000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CdR4Xb6k6_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40b8ac6e-fb89-4b54-b805-024fd748292f"
      },
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# data = scaler.fit_transform(train_X)\n",
        "# data[0]\n",
        "\n",
        "x_mean = train_X.mean(axis=0)\n",
        "x_std = train_X.std(axis=0)\n",
        "\n",
        "train_X = train_X - x_mean\n",
        "train_X = train_X / x_std\n",
        "\n",
        "test_X = test_X - x_mean\n",
        "test_X = test_X / x_std\n",
        "\n",
        "###################################\n",
        "y_mean = train_Y.mean(axis=0)\n",
        "y_std = train_Y.std(axis=0)\n",
        "\n",
        "train_Y = train_Y - y_mean\n",
        "train_Y = train_Y / y_std\n",
        "\n",
        "test_Y = test_Y - y_mean\n",
        "test_Y = test_Y / y_std\n",
        "\n",
        "###################################\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu', input_shape=(13,)),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.07), loss='mse', metrics=\"mse\")\n",
        "model.summary()\n",
        "\n",
        "##################################\n",
        "\n",
        "tf.keras.utils.plot_model(model)\n",
        "\n",
        "##################################\n",
        "\n",
        "history = model.fit(train_X, train_Y, epochs=100, batch_size=32, validation_split=0.25, verbose=1)\n",
        "\n",
        "history.history.keys()\n",
        "\n",
        "##################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss') \n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 64)                896       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 3,009\n",
            "Trainable params: 3,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.4949 - mse: 1.4949 - val_loss: 0.6229 - val_mse: 0.6229\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4248 - mse: 0.4248 - val_loss: 0.5041 - val_mse: 0.5041\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2916 - mse: 0.2916 - val_loss: 0.3445 - val_mse: 0.3445\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1987 - mse: 0.1987 - val_loss: 0.2931 - val_mse: 0.2931\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1939 - mse: 0.1939 - val_loss: 0.2596 - val_mse: 0.2596\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2064 - mse: 0.2064 - val_loss: 0.2631 - val_mse: 0.2631\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1813 - mse: 0.1813 - val_loss: 0.2096 - val_mse: 0.2096\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1225 - mse: 0.1225 - val_loss: 0.2063 - val_mse: 0.2063\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1329 - mse: 0.1329 - val_loss: 0.2299 - val_mse: 0.2299\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1454 - mse: 0.1454 - val_loss: 0.2016 - val_mse: 0.2016\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0987 - mse: 0.0987 - val_loss: 0.1604 - val_mse: 0.1604\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0839 - mse: 0.0839 - val_loss: 0.1844 - val_mse: 0.1844\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0808 - mse: 0.0808 - val_loss: 0.1652 - val_mse: 0.1652\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0877 - mse: 0.0877 - val_loss: 0.2646 - val_mse: 0.2646\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1710 - mse: 0.1710 - val_loss: 0.1922 - val_mse: 0.1922\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1096 - mse: 0.1096 - val_loss: 0.1576 - val_mse: 0.1576\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0780 - mse: 0.0780 - val_loss: 0.2963 - val_mse: 0.2963\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1016 - mse: 0.1016 - val_loss: 0.1393 - val_mse: 0.1393\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1292 - mse: 0.1292 - val_loss: 0.2185 - val_mse: 0.2185\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1419 - mse: 0.1419 - val_loss: 0.1854 - val_mse: 0.1854\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1169 - mse: 0.1169 - val_loss: 0.1554 - val_mse: 0.1554\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0920 - mse: 0.0920 - val_loss: 0.1439 - val_mse: 0.1439\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 0.1906 - val_mse: 0.1906\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1219 - mse: 0.1219 - val_loss: 0.1565 - val_mse: 0.1565\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.1451 - val_mse: 0.1451\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.1311 - val_mse: 0.1311\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0881 - mse: 0.0881 - val_loss: 0.1394 - val_mse: 0.1394\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.1439 - val_mse: 0.1439\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 0.1131 - val_mse: 0.1131\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0606 - mse: 0.0606 - val_loss: 0.1401 - val_mse: 0.1401\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.1523 - val_mse: 0.1523\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0642 - mse: 0.0642 - val_loss: 0.1440 - val_mse: 0.1440\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0584 - mse: 0.0584 - val_loss: 0.1141 - val_mse: 0.1141\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0564 - mse: 0.0564 - val_loss: 0.1113 - val_mse: 0.1113\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0585 - mse: 0.0585 - val_loss: 0.1161 - val_mse: 0.1161\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0622 - mse: 0.0622 - val_loss: 0.1229 - val_mse: 0.1229\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0594 - mse: 0.0594 - val_loss: 0.1271 - val_mse: 0.1271\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0456 - mse: 0.0456 - val_loss: 0.1201 - val_mse: 0.1201\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.1154 - val_mse: 0.1154\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0529 - mse: 0.0529 - val_loss: 0.1296 - val_mse: 0.1296\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589 - val_loss: 0.1177 - val_mse: 0.1177\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0735 - mse: 0.0735 - val_loss: 0.1223 - val_mse: 0.1223\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1063 - mse: 0.1063 - val_loss: 0.1266 - val_mse: 0.1266\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 0.1747 - val_mse: 0.1747\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0797 - mse: 0.0797 - val_loss: 0.2402 - val_mse: 0.2402\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1465 - mse: 0.1465 - val_loss: 0.3564 - val_mse: 0.3564\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1175 - mse: 0.1175 - val_loss: 0.2284 - val_mse: 0.2284\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1228 - mse: 0.1228 - val_loss: 0.1570 - val_mse: 0.1570\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1120 - mse: 0.1120 - val_loss: 0.2808 - val_mse: 0.2808\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1475 - mse: 0.1475 - val_loss: 0.4957 - val_mse: 0.4957\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1843 - mse: 0.1843 - val_loss: 0.3216 - val_mse: 0.3216\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1271 - mse: 0.1271 - val_loss: 0.2358 - val_mse: 0.2358\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0874 - mse: 0.0874 - val_loss: 0.2065 - val_mse: 0.2065\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0807 - mse: 0.0807 - val_loss: 0.2405 - val_mse: 0.2405\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0730 - mse: 0.0730 - val_loss: 0.1860 - val_mse: 0.1860\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574 - val_loss: 0.1789 - val_mse: 0.1789\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.1724 - val_mse: 0.1724\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.1676 - val_mse: 0.1676\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553 - val_loss: 0.2196 - val_mse: 0.2196\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0919 - mse: 0.0919 - val_loss: 0.1833 - val_mse: 0.1833\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 0.1915 - val_mse: 0.1915\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0765 - mse: 0.0765 - val_loss: 0.1687 - val_mse: 0.1687\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0589 - mse: 0.0589 - val_loss: 0.1663 - val_mse: 0.1663\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0541 - mse: 0.0541 - val_loss: 0.2390 - val_mse: 0.2390\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.1582 - val_mse: 0.1582\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0485 - mse: 0.0485 - val_loss: 0.1966 - val_mse: 0.1966\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0658 - mse: 0.0658 - val_loss: 0.2195 - val_mse: 0.2195\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0746 - mse: 0.0746 - val_loss: 0.2298 - val_mse: 0.2298\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1291 - mse: 0.1291 - val_loss: 0.1942 - val_mse: 0.1942\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1070 - mse: 0.1070 - val_loss: 0.1703 - val_mse: 0.1703\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0962 - mse: 0.0962 - val_loss: 0.2074 - val_mse: 0.2074\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0981 - mse: 0.0981 - val_loss: 0.1742 - val_mse: 0.1742\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0758 - mse: 0.0758 - val_loss: 0.2131 - val_mse: 0.2131\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.1487 - val_mse: 0.1487\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.1534 - val_mse: 0.1534\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0589 - mse: 0.0589 - val_loss: 0.1212 - val_mse: 0.1212\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.1593 - val_mse: 0.1593\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.1214 - val_mse: 0.1214\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.1444 - val_mse: 0.1444\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.1349 - val_mse: 0.1349\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.1382 - val_mse: 0.1382\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0596 - mse: 0.0596 - val_loss: 0.2137 - val_mse: 0.2137\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1108 - mse: 0.1108 - val_loss: 0.1957 - val_mse: 0.1957\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.1476 - val_mse: 0.1476\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.1706 - val_mse: 0.1706\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.1533 - val_mse: 0.1533\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0427 - mse: 0.0427 - val_loss: 0.1744 - val_mse: 0.1744\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.1571 - val_mse: 0.1571\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0664 - mse: 0.0664 - val_loss: 0.1909 - val_mse: 0.1909\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.1498 - val_mse: 0.1498\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.1669 - val_mse: 0.1669\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.1510 - val_mse: 0.1510\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0443 - mse: 0.0443 - val_loss: 0.1435 - val_mse: 0.1435\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.1325 - val_mse: 0.1325\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.1258 - val_mse: 0.1258\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.1240 - val_mse: 0.1240\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.1307 - val_mse: 0.1307\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.1377 - val_mse: 0.1377\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.1493 - val_mse: 0.1493\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.1992 - val_mse: 0.1992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A45nrhE2Edp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a62f9096-972f-4af6-cebf-e65f4244d4a2"
      },
      "source": [
        "#학습하다가 val_loss가 3회 최적화 되지 않으면 종료됨.\n",
        "history = model.fit(train_X, train_Y, epochs=25, batch_size=32, validation_split=0.25, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss')])\n",
        "\n",
        "\n",
        "# 가중치 확인\n",
        "model.weights\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.1368 - val_mse: 0.1368\n",
            "Epoch 2/25\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.1741 - val_mse: 0.1741\n",
            "Epoch 3/25\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0542 - mse: 0.0542 - val_loss: 0.2184 - val_mse: 0.2184\n",
            "Epoch 4/25\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.1854 - val_mse: 0.1854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_16/kernel:0' shape=(13, 64) dtype=float32, numpy=\n",
              " array([[ 3.11587334e-01, -3.02802026e-01,  2.24360619e-02,\n",
              "         -4.03334498e-02, -4.03468072e-01, -2.03630075e-01,\n",
              "          5.04090637e-02, -7.05856159e-02, -5.93305938e-02,\n",
              "         -5.73949106e-02, -6.57015219e-02, -1.46281213e-01,\n",
              "          1.12360537e+00, -6.93396330e-01, -2.47183815e-01,\n",
              "         -4.38190550e-01, -4.80601013e-01, -9.39331353e-01,\n",
              "         -3.35036218e-01, -2.72823989e-01,  3.02555650e-01,\n",
              "         -3.12741548e-01,  5.93677089e-02, -6.20862126e-01,\n",
              "          5.07067502e-01, -3.02027792e-01,  2.53087189e-02,\n",
              "         -2.99342155e-01, -4.08691883e-01,  1.02317199e-01,\n",
              "         -1.03327000e+00, -1.97697029e-01,  7.09398985e-02,\n",
              "         -3.78502347e-02, -1.59663424e-01, -2.97652394e-01,\n",
              "         -3.34785700e-01,  6.32219091e-02, -2.82438308e-01,\n",
              "         -6.50296211e-01, -3.09667289e-01, -2.24722266e-01,\n",
              "          6.35855734e-01, -1.86311662e-01, -9.51990858e-02,\n",
              "         -2.41552055e-01, -5.42476512e-02, -6.37702495e-02,\n",
              "          8.76398608e-02, -4.98236895e-01, -2.75925756e-01,\n",
              "         -9.53442395e-01, -4.42551225e-01, -3.07468563e-01,\n",
              "         -2.85722129e-02, -4.20787483e-01, -1.14619449e-01,\n",
              "         -4.44305837e-01, -1.18779004e+00,  1.64193690e-01,\n",
              "         -5.29704988e-01, -2.50036955e-01,  8.72174382e-01,\n",
              "         -2.08858643e-02],\n",
              "        [-1.10304523e+00,  1.76273733e-01, -5.00021338e-01,\n",
              "         -1.24348193e-01, -8.89952034e-02, -2.72147749e-02,\n",
              "          2.87185401e-01, -5.74172772e-02, -1.68070063e-01,\n",
              "          6.58960938e-02, -7.30689317e-02, -5.42958200e-01,\n",
              "         -3.00279826e-01, -1.86784178e-01, -7.48354614e-01,\n",
              "         -9.73364949e-01, -3.49128157e-01, -8.16687047e-02,\n",
              "         -2.99875915e-01, -2.90751338e-01,  4.91388261e-01,\n",
              "         -1.03234850e-01, -3.59406322e-01, -2.33063102e-01,\n",
              "         -4.08512622e-01, -3.46419632e-01, -3.86176854e-01,\n",
              "         -5.06295085e-01, -6.38865411e-01, -1.98027164e-01,\n",
              "         -9.69087481e-01, -1.13297319e+00, -1.80381715e-01,\n",
              "          6.71139956e-01, -2.79500604e-01, -8.46627504e-02,\n",
              "          5.45223475e-01,  6.42111376e-02, -3.59522641e-01,\n",
              "         -4.52646166e-02,  7.40741566e-02, -4.06971902e-01,\n",
              "         -2.17578799e-01, -1.12699367e-01, -3.74256670e-01,\n",
              "         -2.26980612e-01, -5.20363510e-01,  2.45728455e-02,\n",
              "         -3.98556828e-01, -1.49041295e+00,  3.42478827e-02,\n",
              "         -5.75343482e-02,  6.78110197e-02,  4.52781767e-02,\n",
              "         -4.93923604e-01,  8.06087196e-01, -5.00875413e-01,\n",
              "         -3.01425636e-01,  2.89375782e-01, -2.03740537e-01,\n",
              "         -4.95520294e-01,  1.08518445e+00, -1.91448867e-01,\n",
              "         -7.17148304e-01],\n",
              "        [-6.61481202e-01, -3.38457786e-02, -4.36075717e-01,\n",
              "         -3.64906043e-01, -2.26767361e-01, -3.71598840e-01,\n",
              "         -4.87961769e-01, -1.92416787e-01, -1.34381607e-01,\n",
              "          6.70704663e-01,  2.72582263e-01,  7.95543671e-01,\n",
              "         -4.93318066e-02,  5.18086731e-01, -4.55024429e-02,\n",
              "         -1.81193739e-01, -2.40719661e-01,  3.48586887e-01,\n",
              "          1.46360815e-01,  7.66967759e-02,  3.92564505e-01,\n",
              "          1.65315419e-01, -5.60083352e-02,  2.64797509e-01,\n",
              "          6.09120369e-01,  2.07115889e-01, -2.36027583e-01,\n",
              "          1.25857502e-01, -2.77124166e-01,  1.35210291e-01,\n",
              "          1.58403122e+00, -9.02150124e-02,  7.66808271e-01,\n",
              "          7.67012000e-01,  3.03494614e-02, -4.42745000e-01,\n",
              "          3.38202983e-01, -1.83583960e-01,  4.15010899e-02,\n",
              "          5.04981458e-01, -3.01355928e-01,  1.41914442e-01,\n",
              "          6.35600388e-02,  2.51540363e-01, -3.88475507e-02,\n",
              "          6.93025813e-02, -5.09015143e-01, -8.16713423e-02,\n",
              "          3.45982730e-01,  9.06592786e-01, -2.52060834e-02,\n",
              "         -7.65466467e-02, -3.57028842e-01, -1.46200716e-01,\n",
              "         -4.25586015e-01, -2.39339739e-01,  3.12947571e-01,\n",
              "         -1.45677432e-01,  3.68432790e-01,  6.68578222e-02,\n",
              "          4.46389198e-01,  6.86348081e-01, -5.71920574e-02,\n",
              "          4.22104388e-01],\n",
              "        [-6.16647303e-04,  1.71297401e-01, -2.22669512e-01,\n",
              "          2.37651661e-01, -3.31900984e-01,  1.34450376e-01,\n",
              "          1.34875327e-01,  4.83968705e-02, -7.52801061e-01,\n",
              "         -3.00505310e-01,  6.33568764e-02, -1.13683365e-01,\n",
              "          6.13227665e-01,  9.02234688e-02,  4.03490543e-01,\n",
              "          5.75429499e-01,  8.49126652e-02,  2.07920939e-01,\n",
              "         -1.90821424e-01, -7.21135512e-02,  3.97089124e-01,\n",
              "         -2.27294397e-02, -7.45898128e-01, -9.89312399e-03,\n",
              "         -4.03235525e-01,  1.51016921e-01,  3.04630119e-02,\n",
              "          3.18695039e-01,  2.52635460e-02, -6.75559565e-02,\n",
              "          5.73501527e-01,  4.14537132e-01,  2.52425671e-01,\n",
              "          2.39779323e-01, -2.84234226e-01, -1.78378284e-01,\n",
              "          2.40383983e-01, -5.44667765e-02,  2.48426825e-01,\n",
              "          2.43540064e-01,  5.25403202e-01,  6.95386622e-03,\n",
              "         -7.83420503e-02,  8.64838362e-02, -2.08005756e-01,\n",
              "          4.74455766e-02, -3.30466896e-01,  2.80947089e-01,\n",
              "         -2.79909015e-01, -4.74559963e-01, -1.92829475e-01,\n",
              "          1.19678967e-01,  8.07540715e-01,  8.74176621e-02,\n",
              "         -5.44350371e-02,  3.84868830e-01,  2.53433902e-02,\n",
              "          1.80557705e-02, -1.68734387e-01,  1.79117694e-01,\n",
              "          8.44308674e-01, -1.57328606e-01, -3.83585215e-01,\n",
              "         -2.71666870e-02],\n",
              "        [-5.60968876e-01, -3.67950052e-01,  2.05739483e-01,\n",
              "          8.12685609e-01, -1.60522103e-01, -4.97335494e-01,\n",
              "         -3.89875978e-01, -5.07290900e-01, -2.08365858e-01,\n",
              "         -7.38790691e-01,  1.75521582e-01, -1.16865702e-01,\n",
              "          1.33191597e+00,  1.64400563e-01, -5.29993057e-01,\n",
              "         -1.72564268e-01,  7.03821182e-02,  4.53514218e-01,\n",
              "         -1.72024205e-01, -1.61568925e-01, -1.34878016e+00,\n",
              "          2.47771665e-02, -3.06212544e-01,  3.80226254e-01,\n",
              "          7.67693147e-02, -2.09364966e-01, -3.10119659e-01,\n",
              "          4.28987630e-02, -2.47967988e-01, -1.20304868e-01,\n",
              "         -1.24150181e+00, -7.39467591e-02,  1.52177617e-01,\n",
              "          2.87008047e-01,  1.55802310e-01,  3.68950255e-02,\n",
              "         -8.04234564e-01,  5.71156204e-01, -2.06643581e-01,\n",
              "          2.85416484e-01, -9.67510164e-01, -2.08432481e-01,\n",
              "          9.38057959e-01,  3.37873459e-01,  1.52856633e-02,\n",
              "         -2.41042271e-01, -5.18373251e-01, -2.54475653e-01,\n",
              "          3.51397872e-01,  2.56221071e-02,  3.03933173e-01,\n",
              "         -9.18613553e-01, -1.11220813e+00, -1.62273534e-02,\n",
              "         -3.32113892e-01, -2.24995112e+00,  5.26417084e-02,\n",
              "         -2.46188100e-02,  1.38632762e+00, -1.58698127e-01,\n",
              "         -1.07208776e+00,  2.71329749e-02, -4.00467664e-01,\n",
              "         -1.37015685e-01],\n",
              "        [-9.46704745e-02, -1.03941131e+00,  8.86156335e-02,\n",
              "         -1.72350898e-01,  2.50616252e-01, -3.75503689e-01,\n",
              "          3.35003108e-01, -9.62012947e-01,  5.34905851e-01,\n",
              "          7.37007201e-01,  2.75035113e-01,  2.38557383e-01,\n",
              "          1.02668084e-01,  4.45052892e-01,  1.31616163e+00,\n",
              "         -1.59898013e-01, -9.24519837e-01,  1.27521110e+00,\n",
              "          5.69470704e-01,  5.34019828e-01,  1.52494550e+00,\n",
              "          1.55681157e-02,  7.22315073e-01,  1.73995718e-01,\n",
              "          3.61270308e-01,  9.59590375e-02, -2.79104203e-01,\n",
              "          2.09922266e+00, -1.64063647e-01, -2.85759807e-01,\n",
              "          1.04035056e+00, -1.57094657e-01, -2.08757177e-01,\n",
              "          9.22192395e-01,  5.88044703e-01,  9.12152603e-02,\n",
              "          8.51087987e-01,  6.82967249e-03, -1.36626422e-01,\n",
              "         -7.56420255e-01, -9.48793411e-01,  4.47765775e-02,\n",
              "          2.26456881e-01,  7.26228952e-01, -5.51899299e-02,\n",
              "         -4.57895435e-02,  6.40537798e-01,  1.52574569e-01,\n",
              "          1.44052148e+00, -2.01960966e-01, -6.64597511e-01,\n",
              "         -1.69878030e+00, -7.06317902e-01, -1.33272968e-02,\n",
              "         -5.10026693e-01, -1.29146671e+00,  2.03347996e-01,\n",
              "         -4.97167170e-01,  7.96480298e-01, -7.98952103e-01,\n",
              "          1.32914793e+00,  6.87524676e-01,  1.46548176e+00,\n",
              "          5.88989377e-01],\n",
              "        [ 3.26584637e-01,  3.25335652e-01,  1.35082677e-02,\n",
              "         -1.04468755e-01,  1.94432400e-02, -1.49850637e-01,\n",
              "          4.21276867e-01,  2.05464691e-01, -3.58384579e-01,\n",
              "         -9.60983410e-02, -3.70085388e-01,  2.45652527e-01,\n",
              "         -1.61663890e-01,  9.23497751e-02, -3.97628397e-01,\n",
              "         -8.02860558e-01,  3.97224784e-01, -2.19916433e-01,\n",
              "         -3.19719583e-01, -1.76270545e-01,  5.95521986e-01,\n",
              "          2.41742004e-02, -4.43373561e-01, -6.49068534e-01,\n",
              "         -3.07500154e-01, -3.31837609e-02, -1.95406288e-01,\n",
              "         -5.06542385e-01, -2.52018929e-01, -2.69829094e-01,\n",
              "         -2.29924574e-01,  1.50325954e-01, -4.27387476e-01,\n",
              "         -6.77176476e-01, -1.07071829e+00,  5.66263676e-01,\n",
              "          9.67069983e-01, -3.01908776e-02,  1.91818014e-01,\n",
              "          5.11331022e-01,  1.79868305e+00, -2.07534164e-01,\n",
              "          8.34730119e-02,  3.13208401e-02, -1.02224000e-01,\n",
              "          1.44200146e-01, -8.37897733e-02, -7.17635453e-02,\n",
              "         -7.05803990e-01, -2.54972816e+00, -3.48015577e-01,\n",
              "          1.61612380e+00,  2.01601759e-01,  2.08164141e-01,\n",
              "          2.84476519e-01,  5.55720210e-01, -3.96799833e-01,\n",
              "         -3.42465669e-01, -8.23304594e-01, -6.66731596e-01,\n",
              "          8.16787004e-01, -1.19787300e+00,  1.70574844e-01,\n",
              "         -1.02213971e-01],\n",
              "        [ 2.34645560e-01,  4.61657256e-01,  8.18379462e-01,\n",
              "          8.40192676e-01,  2.59930640e-02, -2.47490212e-01,\n",
              "          3.80434692e-02,  7.71232724e-01, -2.59391852e-02,\n",
              "         -9.23383832e-01, -4.20370512e-02, -1.38501227e-02,\n",
              "          5.44634938e-01,  6.27430260e-01, -6.49263382e-01,\n",
              "          3.72503437e-02,  2.72444338e-01,  6.22736752e-01,\n",
              "          1.39044493e-01,  6.17372394e-02, -1.34478068e+00,\n",
              "          2.21507356e-01, -2.95522362e-01,  6.24839604e-01,\n",
              "          1.04387116e+00,  8.55369568e-02, -4.84161615e-01,\n",
              "          3.35060507e-01, -3.17039602e-02,  3.87758732e-01,\n",
              "          7.67062902e-01,  7.51604915e-01,  1.08662486e-01,\n",
              "         -4.49070722e-01, -2.56554604e-01, -2.62560636e-01,\n",
              "         -4.58430916e-01, -2.63108253e-01, -6.77441806e-02,\n",
              "          1.96031332e-01, -9.51617658e-01,  4.46160942e-01,\n",
              "         -8.32839236e-02,  1.07833602e-01,  1.65233985e-01,\n",
              "         -9.12319005e-01,  9.57306102e-02,  5.64368181e-02,\n",
              "          1.33808076e+00,  9.73425582e-02,  3.14768046e-01,\n",
              "          4.33454722e-01, -5.02409756e-01, -1.76915243e-01,\n",
              "         -1.38679206e-01, -1.39312375e+00,  1.52211174e-01,\n",
              "          1.62000671e-01,  1.07821953e+00,  1.14358437e+00,\n",
              "          5.34538329e-01, -2.05441809e+00,  8.25864434e-01,\n",
              "          2.43987739e-01],\n",
              "        [ 3.45164955e-01, -6.54949188e-01, -3.11213732e-01,\n",
              "          5.11397533e-02, -6.67689368e-02, -2.57050186e-01,\n",
              "         -3.71563546e-02,  2.40948603e-01, -3.61286551e-01,\n",
              "          3.13703418e-01, -1.22458123e-01, -6.28375933e-02,\n",
              "         -4.06935126e-01, -1.41378388e-01, -3.39964330e-02,\n",
              "         -7.64852464e-01, -1.65616855e-01,  1.39678746e-01,\n",
              "         -2.98062474e-01, -1.16535492e-01,  1.14247954e+00,\n",
              "         -1.93762034e-01, -5.48031628e-01,  5.24804711e-01,\n",
              "          4.39587325e-01,  1.36587739e-01,  1.99239835e-01,\n",
              "          3.35274279e-01,  6.39600120e-03, -1.75157264e-01,\n",
              "          9.85357165e-01,  2.04249352e-01, -5.62321007e-01,\n",
              "         -2.19293460e-01,  2.27296874e-01, -1.77536711e-01,\n",
              "          2.75473773e-01, -3.13181192e-01,  5.11750132e-02,\n",
              "         -1.04173005e+00,  7.98711240e-01, -2.13107184e-01,\n",
              "         -6.12940490e-01,  5.26351213e-01, -1.54801190e-01,\n",
              "          4.16565239e-01, -2.97603905e-01,  3.05196587e-02,\n",
              "          3.52904528e-01,  7.33931959e-01, -8.56925100e-02,\n",
              "         -1.70685041e+00, -4.14076120e-01, -4.70118046e-01,\n",
              "          6.12904847e-01,  2.18300164e-01, -7.87089486e-03,\n",
              "         -5.79351306e-01,  1.97043583e-01,  2.60891259e-01,\n",
              "         -1.19713414e-02, -7.20737353e-02,  5.74795157e-03,\n",
              "          1.28282011e-01],\n",
              "        [-1.00181437e+00, -6.19212389e-01, -5.80875576e-01,\n",
              "         -5.30823767e-01, -2.55795792e-02,  1.51323542e-01,\n",
              "         -1.07334375e+00, -3.43284369e-01, -1.08411038e+00,\n",
              "         -6.07515275e-01, -1.30778328e-01, -8.38371292e-02,\n",
              "          1.34609595e-01,  1.26639798e-01, -4.31333691e-01,\n",
              "         -7.75518179e-01,  8.22551642e-03, -9.64176655e-03,\n",
              "         -4.36837673e-01, -2.95021106e-02,  5.04189193e-01,\n",
              "         -2.97612280e-01, -2.74369508e-01, -1.15039900e-01,\n",
              "          9.66553628e-01, -1.34974346e-01, -1.01696575e+00,\n",
              "          1.48071378e-01, -5.09247184e-01, -3.65722477e-01,\n",
              "         -5.54289997e-01, -1.94731250e-01, -6.32038116e-01,\n",
              "          4.57699656e-01,  9.97391865e-02, -8.14830884e-02,\n",
              "         -5.48634827e-01, -2.56164461e-01, -6.38930574e-02,\n",
              "         -3.98293197e-01, -3.23164463e-01,  3.59562129e-01,\n",
              "         -2.27904931e-01, -3.47655356e-01, -6.11919522e-01,\n",
              "         -6.15262926e-01, -1.39312044e-01, -2.70641372e-02,\n",
              "          2.22847581e-01,  3.20719749e-01, -3.70308161e-01,\n",
              "          2.57540286e-01, -1.56825498e-01,  7.70264119e-02,\n",
              "         -4.62131947e-01,  3.25722903e-01,  2.30521649e-01,\n",
              "         -1.81155518e-01,  3.59674603e-01, -5.69134235e-01,\n",
              "         -5.91803551e-01,  9.37160492e-01, -1.41817898e-01,\n",
              "         -8.90060365e-01],\n",
              "        [-6.84039533e-01,  9.48408023e-02,  8.89726460e-01,\n",
              "          1.47117198e+00,  2.94968307e-01,  9.55735818e-02,\n",
              "          9.60118115e-01, -9.49073732e-01, -1.28419399e+00,\n",
              "         -1.15603602e+00,  4.58424985e-01, -3.85480642e-01,\n",
              "          4.76794869e-01,  1.39227003e-01, -9.62480903e-02,\n",
              "          3.39262605e-01, -2.15564027e-01,  2.48780787e-01,\n",
              "         -3.77474934e-01,  1.53409734e-01,  4.21209037e-01,\n",
              "          2.68362239e-02, -1.37864172e-01,  2.62419969e-01,\n",
              "          8.00475121e-01, -1.62425116e-01, -3.37629795e-01,\n",
              "          1.33656189e-01, -2.16505617e-01, -4.94405478e-01,\n",
              "          1.41046308e-02,  3.88437212e-01,  9.42987025e-01,\n",
              "         -6.44788206e-01,  4.24827099e-01, -2.70606011e-01,\n",
              "         -2.44203672e-01, -5.59662759e-01, -1.33019954e-01,\n",
              "          2.49841213e-01,  1.23911090e-02, -9.60952416e-02,\n",
              "          2.07760245e-01, -3.89997452e-01, -8.05322155e-02,\n",
              "         -3.83687556e-01,  1.50915653e-01,  7.78179709e-03,\n",
              "          3.28199357e-01,  9.31083411e-02, -1.69910163e-01,\n",
              "         -2.48908103e-01,  3.61354768e-01,  2.37074569e-01,\n",
              "         -2.08091978e-02, -5.98661602e-01,  3.79245877e-02,\n",
              "         -1.20054722e-01, -3.08950365e-01, -2.59544939e-01,\n",
              "         -2.08217576e-01, -1.12925911e+00,  6.56418860e-01,\n",
              "         -3.80529910e-01],\n",
              "        [-4.52290535e-01, -1.34978175e-01, -2.98732460e-01,\n",
              "          5.28425276e-02, -1.70512557e-01,  4.83329684e-01,\n",
              "         -3.01024050e-01, -6.71874464e-01,  1.33231208e-01,\n",
              "         -1.71999559e-01,  2.16147631e-01, -1.54328868e-01,\n",
              "         -1.45594466e+00, -1.75815165e-01, -4.27038297e-02,\n",
              "         -2.20679462e-01, -2.54342169e-01,  4.37736250e-02,\n",
              "         -9.48968157e-02, -1.49946898e-01,  4.92974907e-01,\n",
              "          3.92477095e-01, -1.18354008e-01,  3.61236036e-01,\n",
              "          2.37789059e+00, -3.91739942e-02,  1.21285237e-01,\n",
              "          1.72538415e-01,  2.65163004e-01, -1.64632946e-01,\n",
              "          3.76505256e-01, -8.77558142e-02, -3.23091358e-01,\n",
              "         -1.62197605e-01, -8.28159213e-01,  4.20492023e-01,\n",
              "         -5.51998377e-01,  8.17686737e-01,  5.50775170e-01,\n",
              "          7.13929474e-01, -3.22933346e-01,  6.75779462e-01,\n",
              "          1.89581200e-01, -5.58368303e-02,  9.83696207e-02,\n",
              "          2.57815123e-01,  3.01355004e-01,  2.33568579e-01,\n",
              "          4.67711508e-01,  7.57394373e-01, -4.69622731e-01,\n",
              "          1.81072235e-01, -2.71661997e-01,  6.08591557e-01,\n",
              "          3.84353660e-02,  1.98479593e-01,  1.62462458e-01,\n",
              "          6.42723367e-02,  4.00050312e-01,  1.59251466e-01,\n",
              "         -1.07240987e+00, -3.54139805e-01,  3.47387075e-01,\n",
              "         -1.53307930e-01],\n",
              "        [ 5.55798650e-01, -1.55563220e-01,  1.73525676e-01,\n",
              "          4.88775223e-01,  4.13445011e-02,  3.41896653e-01,\n",
              "          3.95401329e-01,  1.30883053e-01,  1.79182068e-02,\n",
              "         -3.92359257e-01,  3.95669252e-01, -1.75035164e-01,\n",
              "          2.41041350e+00, -1.36260524e-01, -6.94084108e-01,\n",
              "          4.33150500e-01, -7.83166945e-01, -9.91993964e-01,\n",
              "         -1.13396458e-01, -2.45328933e-01, -3.09423304e+00,\n",
              "         -5.86219691e-02,  2.28483886e-01, -3.82812738e-01,\n",
              "          2.13233280e+00, -4.92730737e-01, -5.41442707e-02,\n",
              "         -3.43054444e-01,  1.10185303e-01,  2.01084286e-01,\n",
              "         -9.99028325e-01, -4.56098497e-01,  2.99420375e-02,\n",
              "         -2.51808703e-01, -4.03857917e-01, -2.00122446e-01,\n",
              "          1.30435720e-01,  6.36245489e-01, -5.19129932e-01,\n",
              "         -6.01234809e-02, -1.15653431e+00,  6.92890882e-02,\n",
              "          7.09123373e-01, -3.65102232e-01, -4.09829691e-02,\n",
              "         -8.63370821e-02, -5.45845404e-02, -1.28958955e-01,\n",
              "          7.43782580e-01, -6.05552614e-01, -9.27828550e-02,\n",
              "         -3.72977227e-01,  1.12852216e+00,  2.60103075e-03,\n",
              "         -5.40225565e-01,  1.17037547e+00, -1.04509234e-01,\n",
              "         -1.30088732e-01,  1.62863582e-01,  3.85212570e-01,\n",
              "         -1.98935531e-02, -9.36737478e-01,  5.55494308e-01,\n",
              "         -7.26006851e-02]], dtype=float32)>,\n",
              " <tf.Variable 'dense_16/bias:0' shape=(64,) dtype=float32, numpy=\n",
              " array([-1.3071563 , -0.5963284 , -0.45889044, -0.7469682 , -1.1262007 ,\n",
              "        -0.36637655, -0.5263435 , -1.2516181 , -0.9606679 , -1.5735514 ,\n",
              "        -0.91233236, -1.0615888 ,  0.2402237 , -0.6844463 , -0.89578104,\n",
              "        -2.7903724 , -0.9368123 , -0.7346031 , -1.0703932 , -0.5365758 ,\n",
              "        -1.3177973 , -0.5723995 , -0.5113102 , -1.2503124 , -1.3565667 ,\n",
              "        -0.70593774, -1.2061529 , -0.5222259 , -0.5559388 , -0.8953668 ,\n",
              "        -1.063586  , -0.9310462 , -0.6647054 , -0.8497196 , -0.5109516 ,\n",
              "        -0.94908553, -1.2837969 , -0.71587735, -0.5392618 , -0.03505868,\n",
              "        -1.6564311 , -0.5485555 , -0.06450497, -0.56130713, -0.907164  ,\n",
              "        -0.91141224, -0.5338631 , -0.5086159 , -0.5922075 , -1.8295925 ,\n",
              "        -0.41575196, -0.79112023, -0.92829126, -0.04397726, -1.0618964 ,\n",
              "        -1.8892713 , -0.95627564, -1.2110013 , -0.30351186, -0.9233174 ,\n",
              "        -1.4360518 , -1.2427708 , -0.4706975 , -1.1519629 ], dtype=float32)>,\n",
              " <tf.Variable 'dense_17/kernel:0' shape=(64, 32) dtype=float32, numpy=\n",
              " array([[-0.2901886 , -0.5514588 , -0.81675845, ..., -0.61775106,\n",
              "         -0.29156002, -0.26009047],\n",
              "        [-0.21074528, -0.72029525, -0.37430832, ..., -0.50943154,\n",
              "         -0.18105747, -0.3584208 ],\n",
              "        [ 0.2976299 , -0.21145333, -0.25040695, ..., -0.3519376 ,\n",
              "         -0.19568364, -0.6367428 ],\n",
              "        ...,\n",
              "        [-0.23582481, -0.346938  , -2.3154747 , ..., -0.19581138,\n",
              "         -0.20264855, -0.33113518],\n",
              "        [ 0.3637703 , -0.00380143, -0.40747032, ...,  0.1552292 ,\n",
              "         -0.6013342 ,  0.35824266],\n",
              "        [-0.42347172, -0.40214702, -0.56010646, ..., -0.3340039 ,\n",
              "         -0.33224982, -0.33544025]], dtype=float32)>,\n",
              " <tf.Variable 'dense_17/bias:0' shape=(32,) dtype=float32, numpy=\n",
              " array([-0.76540595, -0.5389247 , -0.75606775, -0.28554872, -0.959735  ,\n",
              "        -0.1208467 , -0.43304268, -0.4203823 , -0.03553475, -0.42036948,\n",
              "        -0.41653046, -0.19690543, -0.4203333 , -0.7200155 , -0.42036024,\n",
              "         0.27385694, -0.37307188, -0.5175909 , -0.5399248 , -0.49573737,\n",
              "        -0.41268268, -0.3716356 ,  1.189325  , -0.16773619, -0.5816699 ,\n",
              "        -0.42036995, -1.1553947 ,  0.36325678, -0.84376466, -0.47327426,\n",
              "        -0.42036745, -0.46078762], dtype=float32)>,\n",
              " <tf.Variable 'dense_18/kernel:0' shape=(32, 1) dtype=float32, numpy=\n",
              " array([[-0.040959  ],\n",
              "        [-0.05689823],\n",
              "        [-0.19755231],\n",
              "        [-0.01192266],\n",
              "        [ 0.3167704 ],\n",
              "        [-0.01843801],\n",
              "        [-0.00240013],\n",
              "        [-0.05464588],\n",
              "        [-0.13939515],\n",
              "        [-0.27868062],\n",
              "        [-0.05794106],\n",
              "        [ 0.05501359],\n",
              "        [-0.10029305],\n",
              "        [-0.36972493],\n",
              "        [-0.2619485 ],\n",
              "        [ 0.3252477 ],\n",
              "        [ 0.13355133],\n",
              "        [-0.13927576],\n",
              "        [-0.08757891],\n",
              "        [ 0.09070166],\n",
              "        [-0.33118597],\n",
              "        [-0.22913466],\n",
              "        [-0.16274574],\n",
              "        [-0.24861374],\n",
              "        [ 0.31592852],\n",
              "        [-0.27165356],\n",
              "        [-0.1349631 ],\n",
              "        [ 0.18178174],\n",
              "        [ 0.04671172],\n",
              "        [-0.27909178],\n",
              "        [-0.34265813],\n",
              "        [-0.18813999]], dtype=float32)>,\n",
              " <tf.Variable 'dense_18/bias:0' shape=(1,) dtype=float32, numpy=array([-0.08062156], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vinidNwRjQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "red = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
        "white = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')\n",
        "\n",
        "\n",
        "# fixed acidity\t고정산, 와인의 산도를 제어\t\t\t\t\t\t\t\t\n",
        "# volatile acidity\t휘발산, 와인의 향과 연관\t\t\t\t\t\t\t\t\t\n",
        "# citric acid\t구연산, 와인의 신선함을 올림\t\t\t\t\t\t\t\t\n",
        "# residual sugar\t잔여 당분, 와인의 단 맛 올림\t\t\t\t\t\t\t\t\n",
        "# chlorides\t염화물, 와인의 짠 맛의 원인\t\t\t\t\t\t\t\t\n",
        "# free sulfur dioxide\t황 화합물, 와인을 오래 보관하게 함\t\t\t\t\t\t\t\n",
        "# total sulfur dioxide\t황 화합물, 와인을 오래 보관하게 함\t\t\t\t\t\t\t\t\n",
        "# density\t밀도, 와인의 무게감을 나타냄\t\t\t\t\t\t\t\n",
        "# pH\t산성도, 와인의 신 맛의 정도\t\t\t\t\t\t\t\t\n",
        "# sulphates\t황 화합물, 와인을 오래 보관하게 함\t\t\t\t\t\t\t\t\n",
        "# alcohol\t알코올, 와인의 단 맛과 무게감에 영향\t\t\t\t\t\t\t\n",
        "# quality\t와인의 품질\t3,4,5,6,7,8\t\n",
        "\n",
        "# 실습문제\n",
        "# red 와인은 0, white 와인은 1로 type컬럼에 추가하시오.\n",
        "# red와 white를 합치시오. concat 사용\n",
        "# red와 white의 각각의 개수를 구하시오.\n",
        "# minmaxscale로 정규화하시오.\n",
        "# 데이터를 섞은 후 80:20으로 분할 하시오. train_X, test_X, train_Y, test_Y\n",
        "# numpy 배열로 변환하시오. ( to_numpy()사용 )\n",
        "\n",
        "#==========================================\n",
        "\n",
        "# train_Y, test_Y는 원핫 인코딩으로 변환하시오.\n",
        "# 모델생성.... "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmDVhWY7Rod-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "56986241-6d88-494b-8c33-b7db939153ec"
      },
      "source": [
        "red.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1599 non-null   float64\n",
            " 1   volatile acidity      1599 non-null   float64\n",
            " 2   citric acid           1599 non-null   float64\n",
            " 3   residual sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free sulfur dioxide   1599 non-null   float64\n",
            " 6   total sulfur dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k_gmOxARs1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red['type']=0"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2AW7V66SOa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "8561cbf1-41d8-4615-e884-d11bb606e5f8"
      },
      "source": [
        "red.sample(6)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.49</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.070</td>\n",
              "      <td>23.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>0.99220</td>\n",
              "      <td>3.12</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>8.3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.9</td>\n",
              "      <td>0.089</td>\n",
              "      <td>17.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99803</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0.55</td>\n",
              "      <td>9.5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>922</th>\n",
              "      <td>8.4</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.072</td>\n",
              "      <td>38.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.99504</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.89</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>8.8</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.38</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.060</td>\n",
              "      <td>19.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.99543</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.72</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1324</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.077</td>\n",
              "      <td>18.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99480</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.60</td>\n",
              "      <td>10.6</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>967</th>\n",
              "      <td>8.5</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.20</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.097</td>\n",
              "      <td>23.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>0.99733</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.48</td>\n",
              "      <td>9.2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  type\n",
              "591             6.6              0.39         0.49  ...     11.5        6     0\n",
              "750             8.3              0.65         0.10  ...      9.5        5     0\n",
              "922             8.4              0.62         0.12  ...     11.8        6     0\n",
              "936             8.8              0.30         0.38  ...     11.8        6     0\n",
              "1324            6.7              0.46         0.24  ...     10.6        6     0\n",
              "967             8.5              0.66         0.20  ...      9.2        5     0\n",
              "\n",
              "[6 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-QHYi8TSQfb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e387725a-7aa7-4f0a-a977-86127ed9cd5d"
      },
      "source": [
        "white['type']=1\n",
        "white.sample(6)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.31</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.058</td>\n",
              "      <td>38.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>0.99310</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.53</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>5.7</td>\n",
              "      <td>0.245</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.049</td>\n",
              "      <td>28.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.99270</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.42</td>\n",
              "      <td>9.3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4046</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.170</td>\n",
              "      <td>0.28</td>\n",
              "      <td>17.55</td>\n",
              "      <td>0.050</td>\n",
              "      <td>33.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>0.99971</td>\n",
              "      <td>2.94</td>\n",
              "      <td>0.43</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3574</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.170</td>\n",
              "      <td>0.21</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.036</td>\n",
              "      <td>24.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>0.99396</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.52</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0.29</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.040</td>\n",
              "      <td>15.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0.99380</td>\n",
              "      <td>3.32</td>\n",
              "      <td>0.74</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2085</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.170</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.053</td>\n",
              "      <td>47.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.99480</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0.76</td>\n",
              "      <td>9.6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  alcohol  quality  type\n",
              "45              7.4             0.180         0.31  ...     10.0        7     1\n",
              "1251            5.7             0.245         0.33  ...      9.3        5     1\n",
              "4046            7.2             0.170         0.28  ...      9.0        7     1\n",
              "3574            8.1             0.170         0.21  ...     10.1        6     1\n",
              "208             6.8             0.570         0.29  ...     10.2        5     1\n",
              "2085            7.9             0.170         0.32  ...      9.6        6     1\n",
              "\n",
              "[6 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uuTPyZ-SgkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wine = pd.concat([red, white], axis=0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZYXXRkTS2z9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "cd1ff47f-fbce-43e7-f800-28808952e9bd"
      },
      "source": [
        "wine.describe()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.215307</td>\n",
              "      <td>0.339666</td>\n",
              "      <td>0.318633</td>\n",
              "      <td>5.443235</td>\n",
              "      <td>0.056034</td>\n",
              "      <td>30.525319</td>\n",
              "      <td>115.744574</td>\n",
              "      <td>0.994697</td>\n",
              "      <td>3.218501</td>\n",
              "      <td>0.531268</td>\n",
              "      <td>10.491801</td>\n",
              "      <td>5.818378</td>\n",
              "      <td>0.753886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.296434</td>\n",
              "      <td>0.164636</td>\n",
              "      <td>0.145318</td>\n",
              "      <td>4.757804</td>\n",
              "      <td>0.035034</td>\n",
              "      <td>17.749400</td>\n",
              "      <td>56.521855</td>\n",
              "      <td>0.002999</td>\n",
              "      <td>0.160787</td>\n",
              "      <td>0.148806</td>\n",
              "      <td>1.192712</td>\n",
              "      <td>0.873255</td>\n",
              "      <td>0.430779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.800000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.009000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.987110</td>\n",
              "      <td>2.720000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.038000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>0.992340</td>\n",
              "      <td>3.110000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.290000</td>\n",
              "      <td>0.310000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.047000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.994890</td>\n",
              "      <td>3.210000</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>10.300000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.700000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.996990</td>\n",
              "      <td>3.320000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>11.300000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>15.900000</td>\n",
              "      <td>1.580000</td>\n",
              "      <td>1.660000</td>\n",
              "      <td>65.800000</td>\n",
              "      <td>0.611000</td>\n",
              "      <td>289.000000</td>\n",
              "      <td>440.000000</td>\n",
              "      <td>1.038980</td>\n",
              "      <td>4.010000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.900000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       fixed acidity  volatile acidity  ...      quality         type\n",
              "count    6497.000000       6497.000000  ...  6497.000000  6497.000000\n",
              "mean        7.215307          0.339666  ...     5.818378     0.753886\n",
              "std         1.296434          0.164636  ...     0.873255     0.430779\n",
              "min         3.800000          0.080000  ...     3.000000     0.000000\n",
              "25%         6.400000          0.230000  ...     5.000000     1.000000\n",
              "50%         7.000000          0.290000  ...     6.000000     1.000000\n",
              "75%         7.700000          0.400000  ...     6.000000     1.000000\n",
              "max        15.900000          1.580000  ...     9.000000     1.000000\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl_Mw-inTJNB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "872e0e0e-580a-4c35-e9ec-f8c2370050b8"
      },
      "source": [
        "wine.info()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6497 entries, 0 to 4897\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         6497 non-null   float64\n",
            " 1   volatile acidity      6497 non-null   float64\n",
            " 2   citric acid           6497 non-null   float64\n",
            " 3   residual sugar        6497 non-null   float64\n",
            " 4   chlorides             6497 non-null   float64\n",
            " 5   free sulfur dioxide   6497 non-null   float64\n",
            " 6   total sulfur dioxide  6497 non-null   float64\n",
            " 7   density               6497 non-null   float64\n",
            " 8   pH                    6497 non-null   float64\n",
            " 9   sulphates             6497 non-null   float64\n",
            " 10  alcohol               6497 non-null   float64\n",
            " 11  quality               6497 non-null   int64  \n",
            " 12  type                  6497 non-null   int64  \n",
            "dtypes: float64(11), int64(2)\n",
            "memory usage: 710.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zO0GfBnUP7g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19341868-f4cf-47cc-9086-20a7902ece22"
      },
      "source": [
        "wine['type'][wine['type']==1].count()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtT0yMyUVYCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "637d479a-d73b-4895-a45a-cd674ba36460"
      },
      "source": [
        "wine['type'][wine['type']==0].count()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1599"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmKV8ryuVhRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0dd0d07f-a39e-4d52-ebe7-b91af1fba0e9"
      },
      "source": [
        "wine['type'].value_counts()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(wine['type'])\n",
        "plt.xticks([0, 1])\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq4CwwYcaiUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 최소값이 0 최대값1로 스케일\n",
        "# type 0 1\n",
        "wine_norm = (wine - wine.min()) / (wine.max() - wine.min())\n",
        "wine_norm\n",
        "\n",
        "# 데이터 섞기\n",
        "import numpy as np\n",
        "wine_shuffle = wine_norm.sample(frac=1)  # frac=1은 100% 즉 모든 데이터를 뽑아서 썪는다.\n",
        "\n",
        "# 넘파이\n",
        "wine_np = wine_shuffle.to_numpy()  # numpy로 변경하기"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWps6tA-Y2VV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#80%로 나누기\n",
        "train_idx = int(len(wine_np) * 0.8)\n",
        "\n",
        "train_X = wine_np[:train_idx, :-1]\n",
        "train_Y = wine_np[:train_idx, -1]\n",
        "\n",
        "test_X = wine_np[train_idx:, :-1]\n",
        "test_Y = wine_np[train_idx:, -1]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtyJy7mqaRAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "919b9ebf-1d0e-4a29-c8d0-33ca7340339b"
      },
      "source": [
        "# 원핫\n",
        "import tensorflow as tf\n",
        "\n",
        "# num_classes 는 종류 : 지금은 0과 1만 있음.\n",
        "train_Y = tf.keras.utils.to_categorical(train_Y, num_classes=2) \n",
        "test_Y = tf.keras.utils.to_categorical(test_Y, num_classes=2)\n",
        "\n",
        "train_Y[4:30] # 확인용"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fzpGcUJbHOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "fbf2cc68-f042-4838-f2f7-d6bc17148b57"
      },
      "source": [
        "# softmax\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import numpy as np\n",
        "x = np.arange(-2, 2, 0.01)\n",
        "e_x = math.e ** x\n",
        "\n",
        "plt.axhline(0, color='gray')\n",
        "plt.axvline(0, color='gray')\n",
        "plt.plot(x, x, 'b-', label='y=x')\n",
        "plt.plot(x, e_x, 'g.', label='y=e^x')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI-j79aIez57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d1b5272e-a4dd-4253-d15f-e52a19cc2159"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(units=48, activation='relu', input_shape=(12,)),\n",
        "  tf.keras.layers.Dense(units=24, activation='relu'),   \n",
        "  tf.keras.layers.Dense(units=12, activation='relu') ,\n",
        "  tf.keras.layers.Dense(units=2, activation='softmax')   #2는 구하고자 하는 개수            \n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_19 (Dense)             (None, 48)                624       \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 24)                1176      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 12)                300       \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 2)                 26        \n",
            "=================================================================\n",
            "Total params: 2,126\n",
            "Trainable params: 2,126\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp2scvOUgXmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 분류하고자 하는 label값이 원핫 일경우  : categorical_crossentropy\n",
        "# 측정지표 = accuracy\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.04) #최적화 함수 : Adam\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpACzbZBhAIg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "outputId": "a66a5de5-e118-40a9-f829-4ffa16107d79"
      },
      "source": [
        "history = model.fit(train_X, train_Y, epochs=25, batch_size=32, validation_split=0.25)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "122/122 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9446 - val_loss: 0.0368 - val_accuracy: 0.9931\n",
            "Epoch 2/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9833 - val_loss: 0.0477 - val_accuracy: 0.9931\n",
            "Epoch 3/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9859 - val_loss: 0.0265 - val_accuracy: 0.9923\n",
            "Epoch 4/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9885 - val_loss: 0.0293 - val_accuracy: 0.9908\n",
            "Epoch 5/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 0.0261 - val_accuracy: 0.9931\n",
            "Epoch 6/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9877 - val_loss: 0.0517 - val_accuracy: 0.9815\n",
            "Epoch 7/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9885 - val_loss: 0.0171 - val_accuracy: 0.9938\n",
            "Epoch 8/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9908 - val_loss: 0.0270 - val_accuracy: 0.9885\n",
            "Epoch 9/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9841 - val_loss: 0.0201 - val_accuracy: 0.9923\n",
            "Epoch 10/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9897 - val_loss: 0.0200 - val_accuracy: 0.9931\n",
            "Epoch 11/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9920 - val_loss: 0.0181 - val_accuracy: 0.9931\n",
            "Epoch 12/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9931 - val_loss: 0.0139 - val_accuracy: 0.9946\n",
            "Epoch 13/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9923 - val_loss: 0.0233 - val_accuracy: 0.9946\n",
            "Epoch 14/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.0172 - val_accuracy: 0.9954\n",
            "Epoch 15/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9885 - val_loss: 0.0159 - val_accuracy: 0.9954\n",
            "Epoch 16/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9910 - val_loss: 0.0144 - val_accuracy: 0.9938\n",
            "Epoch 17/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9900 - val_loss: 0.0154 - val_accuracy: 0.9938\n",
            "Epoch 18/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9902 - val_loss: 0.0290 - val_accuracy: 0.9885\n",
            "Epoch 19/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9926 - val_loss: 0.0261 - val_accuracy: 0.9938\n",
            "Epoch 20/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9933 - val_loss: 0.0843 - val_accuracy: 0.9715\n",
            "Epoch 21/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9861 - val_loss: 0.0146 - val_accuracy: 0.9962\n",
            "Epoch 22/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9941 - val_loss: 0.0124 - val_accuracy: 0.9954\n",
            "Epoch 23/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9923 - val_loss: 0.0302 - val_accuracy: 0.9915\n",
            "Epoch 24/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9908 - val_loss: 0.0125 - val_accuracy: 0.9969\n",
            "Epoch 25/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9913 - val_loss: 0.0150 - val_accuracy: 0.9969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIaRiH2xhomP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7337486a-da4c-4724-cd7d-39822031f61b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAEKCAYAAADpSmgQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3jUVdbA8e9NI4EECCEkdFCRJiISEAvYdhVxBRtNEbCgIuCigoKr4ovYULFSxF6oIiq7gtgFFJFOgFAiEEgIkEACBAhp5/3jTkISUmaSSSblfJ5nnpn51TOTYThzf+fea0QEpZRSSimlVOG8PB2AUkoppZRSFZ0mzUoppZRSShVDk2allFJKKaWKoUmzUkoppZRSxdCkWSmllFJKqWJo0qyUUkoppVQxNGlWSqkqxhjzoTHmkDFmcyHrjTHmLWNMtDFmkzHm4lzrhhhjdjpuQ8ovaqWUqtg0aVZKqarnY6BnEetvAFo5bvcD0wGMMfWACcAlQFdggjEmuEwjVUqpSkKTZqWUqmJEZBlwpIhN+gCfivUnUNcY0xC4HvhBRI6ISBLwA0Un30opVW34eDqA/OrXry8tWrTwdBhKKVUia9euTRSRUE/HUYzGwL5cz2MdywpbfhZjzP3YVmpq1arVuU2bNmUTqVJKlSFXvrMrXNLcokUL1qxZ4+kwlFKqRIwxMZ6OoTyIyExgJkBERITo97ZSqizs27ePlJSUPMv8/Pw499xzAYiJieHkyZO0aNGCgIAAl4/vynd2hUualVJKlbk4oGmu500cy+KAq/It/7XcolKqFDIzM/Hy8sIYQ1paGunp6WdtU7NmzTzr/f398fb29kC0FdOKFSuYM2cOtWrVIigoiNGjRxMUFMTWrVvZtWsXQUFBBAYGEhgYSFBQEOHh4Xh5ua/Sd/fu3cyfP58NGzYwZ84cAIYPH863336bZ7vWrVuzbds2AAYPHsyyZcv4888/ueSSS9wWS0E0aVZKqepnETDSGDMX2+nvqIjEG2OWAi/k6vx3HTDeU0Gqyi81NZUDBw5w4MAB4uPjufzyy2nQoAFRUVEsWLDgrO2HDh1K06ZN2bhxI4sWLUJEOH36NMePHyclJYVJkybRqFEj5syZw8svv0xKSkrOupMnTxIbG0vjxo2ZPHkyTz/99FnHP3LkCMHBwTz99NNMnjwZLy8vGjRoQMOGDWnYsCELFy6kRo0arFy5kvj4+Jzl4eHh+Pv7l8db5jEHDhzgpptuIjU1FbB/uxEjRgDw6aef8vLLL5+9T9IB6gbW5celP5KYmEiPHj1o0aIFxhinz7t//37mzJnDvHnzWL16NQCXXHIJx44do3bt2jz++OPcddddefYJCgrKeTxhwgQSEhI477zzXH7NrtKkWSmlqhhjzBxsi3F9Y0wsdkQMXwARmQEsBnoB0cBJ4G7HuiPGmOeA1Y5DTRSRojoUltimTZtYv379WcsHDBhAjRo1WLt2LZs3nxkxz9fXl8DAQHr16oWPjw+HDh3i9OnTOS1fPj5l+9/ZkSNHSE1NpVGjRmVy/N9//52HH36Yhg0bMmzYMPr06VMm58kmIpw4cSIn4cxOPps2bUrLli1JSUnhyy+/PGu/Ll260K5dO5KTk/nmm29yjnXkyBHi4+MZMGAAnTt3Zvny5fTp04ekpKQ8+4+fNp52l7cj8tdIJj8z+azjd7+yO02bNmXDhg0888wzAHh7exMUFERQUBBjxoyhUaNGBAYG0rx58zwtn4GBgdSsWROAa6+9lho1apx1/OzL97169SIkJIRjx47lJPRJSUn4+fkBMG3aND7//PM8+5577rlER0cDMGjQIBYvXpxnfYsWLVi3bh0AN998M7GxsfTr14++ffvSsmXLYv4iztm2bRtDhgyhWfNmTP9oOifST5CSlkJKWgrH047b+9PH8yxLz0znlra30LVx1yKP/e9//5tTp06xceNGWrduTUZGRk4r/OjRo7nttttyPic74newYMMCGr7ZEEGosaAGpzefBqBWSC1adWrFJT0u4a4hd9G0TlMaBTXCx+vMv9H9+/cTEBBAcHAwP/30E2PGjKFz585MnjyZvn37krtvW48ePYqM+5prrinhu+k6IyLldjJnaG2cUp6Vnp5ObGxsTmuDKpi/vz9NmjTB19c3z3JjzFoRifBQWB5Rku/t559/nqeeeuqs5YcPH6ZevXqMHz+el1566az1aWlp+Pr6MmLECKZNm5az3N/fn3r16hEXFwfAm2++ydq1awkPD89pLWzcuDHdu3cvNKa0tLScpGny5MlERkayc+dOdu7cyZEjR7jzzjv5/PPPycrKYuvWrVxwwQUuveaCiAhvvfUWY8aMoXHjxmRlZdG3b19ee+01MjMzWbBgATfeeCOBgYEuHzs5OZnff/+dZcuW8fvvv3Po0CHuvvtuxo8fz5EjRwgJCTlrn+eee46nnnqKvXv30rx587PWv/HGGwwfOZylK5fSu3vvPOu8fL1oOqgpXh29SNyfyPFfjkMgEIS9DwRCgBqAOG75GfD19qWWTy2CagQR6BfIufXO5ZIml9ClURe6NO5CvYB6Lr8XrkpMTGTfvn3Ex8fnJNWpqak899xzALz33ntERkbm2SckJIQJEyYA8NZbb/H555/ntJx27dqVkSNHntViWpSjqUf5fcvvzJ03l1P+p/Dv5E9UXBQbnt9A5oFMex3osuKP4228yZRMujfrzpjLxvCv8/+Flzm7pGLDhg1s2rSJwYMHF3qs7YnbmbR8ErMjZ+Pv48/9F99PvYB67E3eS1RUFLs27CIhKoGMXRlQHxjq2PEHqFO/DnVr1iVlfQqHtx/m+uHXc9s9t1HH1MH3lC9dO3QlLDAsT3LtjMysTE5lnOJ0xmlCap79mS6OK9/ZmjQrpfLYvXs3QUFBhISEuHSJrToREQ4fPszx48fPakHSpNk5ycnJZ7VCAjRr1gxvb2+OHDnC0aNHc5anpaVx4sQJLr7YzsPy559/snnz5jwtpZmZmbz66qsAjB07li+++IL4+HjS0tJyjh0TY/v83H777axfv56GDRsCsHPnTtq2bcuvv/4KwIUXXkhycjKtWrXi/PPPp1WrVnTt2pUrrriCadOm8fDDD/Pcc8/x+OOPl6omdvbs2dx555307t2bTz75hNq1a3Pq1Clq1arFr7/+ytVXX42/vz89e/Wk+w3dady5MXtP7mXnkZ2ICPd0uoduTbphjOHgwYMcPHiQCy+8kIyMDIKDg0lJScHX15cuXbrQvHlzbrrpJgYOHEh6ejpvvvlmnvrUwMBAWrVqRbNmzUhNS+XPLX+yO2k3e47uYU/SHnYn72Zf+j72nt5LVnoWHLevoXaN2jQMbUhIcAjBAcEEBwRTt0Zde+9fl2B/x73jeU3fmpxMP3lWi2hBraTHTh8jKjGKbYnbct6z8+qdR5dGXejauCtdGnWhU8NO1PStWeK/QX4iwsETB9masJWohCiiEu0tJjmGWn618r6mfK8t93M/bz/27N7D4q8Xs3TRUi695lLue+w+TqWe4pvZ33DpPy+ldv3aZGRlcCrjFLuSdrHzyE62/L2FqOVRpKxLgb2OoC6EZnc3o1W9VpwXfB6/Tf6Nnat28tSnT9GuQzuC/OwPjEC/wJwfG0F+QQT4BnAi7QQfrP+A1/98nb1H93J+yPk82u1RBnccTIBvAJmZmcV+hvMnyyO6jGDMZWNoUKtBgdsfTT3KtrhtJEkSew7v4am+T3F432EAajSsgdcFXpxqewry/f4xGOrXrE/DoIaEB4YDkJqRyqn0U6RmpObcTmWceZ6RlQFATd+anHjyhMt/b02alVIlFhUVRZs2bTRhLoaIsG3bNtq2bZtnuSbNFYuIkJSURHx8PCdOnKBrV3uJ+vXXX2f16tXEx8cjIrRq1YqIiAgeeOABADIyMgot+UhOTubBBx9k3rx5XHPNNXz22Wcul21kHz8jI4O5c+dyxx13kCEZ7E7azc4jO9l5eCc7EnewetVqdvy2g+Prj8MJbJHNfVC/ZX1OJZ7ixM4ThCSE4LvPlwMxB+jcuXPOCFSffPIJzZs355JLLnFqVIHjp4/z1bavmBU5i192/0J61pmOdEF+QZwfcj6tQlrRqp7j5nhcktY9Vx1NPcra+LX8FfcXq/ev5q+4v4g9FgvYltQOYR3o0qgLF4VfRO0atfH38c+5BfgE5H3ue+b5oROH8iTHWxO2EpUYRXJqcp7X3ja0LecEn8Op9FMkpSaRnJpM0il7fzztuHMvIgs7O8Yu4FPHsuZAe+BcIAQaBTXi1IenSNqSRPg54Vx949XcMeAOru1yLQG+Z/6GiYmJXHjhhdSpU4f169c7VW+dkZXBl1u/5NWVr7Jm/xrq16zPiC4jiP44mgDfAGbOnHnW976ryXJRYmNjOXnyJOeffz4AaZlpHEw5SHxKPPHH4zmQcuDM4xMHOJhyEGNMoX/H/Mtq+tZkRNcRLselSbNSqsSioqLOSgRVwQp6rzRprpiyJIuY5JicpCh3klS7Rm3GXDaG+y6+z+kWSxHho48+YtSoUQQEBDBr1iyuv/76POtX7F3BsphlZ1pRHfc7f9vJzi930mJ0C1IDUnNaWE9nns5zjrr+dXOS03PrnEvm7kx2rdrFW1PeIjQolJtvvZlvvvoGrwAvsppmEXBuALf0vIWJgyZybr1znXodaZlpfBf9HbMiZ7Fo+yJSM1JpWbclt7a9lfah7XMS4wa1GlS4H9Lxx+NzEujs+9zJrqsa1GpA2/pt7S20Le1C29G2flsaBTUq8rVnZGVwNPVonmQ6KTWJjKwMfLx8zrr5evkStyuO3xb/xk//+4ndO3YD8Pfevzmn6TmsXbuWgIAA2rVrV2S8P/30E7t37+bee+916W8jIizfu5xX/3iV/373X/gUOt7WkXkz5tG6fmvAvclyRVftkubly2HJEnj+eahg/6aVqnQ0aXaeJs1WRUqa0zPTiT4SfSY5diTG2xO3cyrjVM52DWo1yEmKtiRsYVnMMhrUasBjlz7G8IjhBNUIKuIsZ2zfvp1BgwYxZcoUunfvzumM08zdPJc3Vr3BhgMbAPDz9iPQL5BaXrU48e0Jjvx6hDqt6tDtkW6EhofmubTevE7znES1fs36RSZDGzduBKB9+/b8EfcH7/z1DgujFpIlWdzQ6gZGdBlBz/N6nlW/miVZrNi7gtmRs/li6xccOXWE+jXr069dP+688E4ubXJphUuQnSEixKfEczL95FmX9HNfzs9efirjFCEBIbQNtYlyebSYF2Tz5s0sW7aM2267jbCwsBIdIz09/az+FcU5efIkbdq34ejpo6QOSyXdK52bWt9EkF8QczbPqfLJcrZqlzS/9hqMGQNJSVC3bhkFplQ1URGS5sDAwLMGs6+INGm2PJE0n0w/ybbEbWddVo8+Ep1T4wjQrE6znOS4bX1H62Fo27M6ky2PWc7zy59n6d9LCfYPZnS30YzqOorggOD8pz5LVlYWh04eYsaaGbz25mukNEqhXft2jL5kNAM7DCTQLzBnJIWVK1cyevRoJk+e7HKS44z9x/czc+1M3l37LgdSDnBO8Dk8FPEQd3e6m7hjccyKnMWczXPYe3QvNX1rcnObm7njgju47tzr8PV2fzyq7H3zzTeMHj2aP/74I6dG3xljxozhtdde49dff6VtRFum/jWVqauncirjVLVIlrNVu6T588/hrrtg2zZo3bqMAlOqmtCk2XmaNFtlnTQnnkzkm23f5Gk93pO8J2e9t/HmvHrn5bQYZifHreu3JtDPtVEnVset5vnlz/PN9m8I8gtiRJcRPHLpI4UmD+vi1/HmqjeZEzmH9BPp1JhRA07DW2++xbBhw3JabIcMGcLChQv54IMP6NevX4nfC2elZabxVdRXvLP6HVbsXZEzgoK38ea6c6/jzg530qdNH5ffH1XxREVF0blzZ7p3786SJUucmmwkKSmJc889l379+jFjxoyc5aczTpORlUEtv1plGXKF4tJ3tohUqFvnzp3FVT/8IAIiv/3m8q5KqXy2bt3q6RCkVq1aIiKSlZUlY8aMkfbt28sFF1wgc+fOFRGR/fv3S/fu3aVjx47Svn17WbZsmWRkZMiQIUNytp0yZUqZx1nQewWskQrwXVqet5J8b7vi0vcvFZ5F/Cf5S8fpHWXAggEy8deJ8sWWL2Tzwc1yOuO028+58cBG6f9FfzHPGgmYFCCjl4yW2KOxIiKSnpkuC7YskCs+vEJ4Fqn1fC0ZtXiU7EjcIfv375d//OMfAsitt94qu3btEhGRI0eOSFRUlNvjdMaG+A0yZukYeXvV23Iw5aBHYlBla/r06QLI66+/7vQ++/btk+Tk5DKMqnJw5Tu7Skxukl0CdOCAZ+NQqqoZPRo2bHDvMS+6CN54w7ltFy5cyIYNG9i4cSOJiYl06dKFHj16MHv2bK6//nr+85//kJmZycmTJ9mwYQNxcXE5E2IkJ5e8Q5CqONbFr2Nl7EpeuvYlxlw2Bm+v8pny+MKwC5l7+1z+76r/48UVL/L2X28zbc00bmt7G3/s+4OYozG0qNuCKddN4Z5O91DHv07OvkuXLuW1117j8ccfZ9OmTWzdupXg4GCCg4sv9SgLHcM70jG8o0fOrcrHAw88wJIlS3jiiSe4+uqr6dix8L/3xo0bufDCC2nSpEk5Rlg1uG/CcA/KTpoPHvRsHEop91qxYgUDBw7E29ubsLAwrrzySlavXk2XLl346KOPePbZZ4mMjCQoKIhzzjmHXbt2MWrUKL777jtq167t6fCVG0xfPZ2avjV5IOKBckuYc2tdvzUf3/wxO0ft5J6L7uGrbV/Rom4Lvur/FdGjonnk0kfyJMwAXl5ejB07lnXr1jFp0qQyn61QKWMM77//PiEhISxZsqTQ7aKioujatSsvvPBCOUZXdVSJf8khIeDlpUmzUu7mbItweevRowfLli3j22+/ZejQoTz66KMMHjyYjRs3snTpUmbMmMH8+fP58MMPPR2qKoXk1GRmRc7ijg53UNffs728Wwa3ZPq/pjP9X9Od3qdTp0506tSpDKNS6ozQ0FAiIyMLnOkRbIfV++67j8DAQIYNG1bO0VUNVaKl2dsbGjTQ8gylqpru3bszb948MjMzSUhIYNmyZXTt2pWYmBjCwsIYNmwY9913H+vWrSMxMZGsrCxuu+02Jk2axLp16zwdviqlTzd+yqmMUwyPGO7pUJSqFLIT5jVr1vDTTz/lWTdt2jT++OMP3njjDRo0qPqjYpSFKtHSDLZEQ1ualapabrnlFlauXEnHjh0xxjB58mTCw8P55JNPeOWVV/D19SUwMJBPP/2UuLg47r77brKysgB48cUXPRy9Kg0RYcaaGXRp1IXOjTp7OhylKg0RYfjw4cTExBAZGUlYWBgxMTGMGzeOnj17MmjQIE+HWGlp0qyUqnCyh5szxvDKK6/wyiuv5Fk/ZMgQhgwZctZ+2rpcdfwW8xtRiVF82FtLbJRyhTGGTz75hM6dO3P33Xfz7bffEh8fT/PmzZkxY0alnLimoqgS5RkA4eFanqGUUlXF9DXTCfYPpv8F/T0dilKVTrt27XjttddYsmQJ77zzDt26dSMyMpLmzZt7OrRKrcokzdktzRVsrhallFIuOpBygIVRCxl60VBq+tb0dDhKVUrDhw/nxhtv5OGHH+b48eNOTXqiilZl3sGwMEhLg6NHPR2JUkqp0vhg3QdkZGXwYMSDng5FqUrLGMNHH33Efffdx6FDhzwdTpVQZWqaw8Pt/cGDUNezIxMppZQqocysTGaum8m1La/l/JDzPR2OUpVaaGgo7733nqfDqDKqVEszaF2zUkpVZot3Lmbv0b06zJxSqsKpckmzjqChlFKV1/Q102kY2JDerXt7OhSllMrDqaTZGNPTGLPdGBNtjBlXwPoexph1xpgMY8ztBayvbYyJNca8446gC5K7PEMppVTlsztpN99Ff8ewi4fh6+3r6XCUUiqPYpNmY4w3MBW4AWgHDDTGtMu32V5gKDC7kMM8BywreZjFCwmxMwNqeYZS1UtgYGCh6/bs2cMFF1xQjtGo0nh37bt4GS+GddYpfpVSFY8zLc1dgWgR2SUiacBcoE/uDURkj4hsArLy72yM6QyEAd+7Id5CeXlBaKi2NCulVGV0OuM0H6z/gJta30ST2k08HY5SSp3FmdEzGgP7cj2PBS5x5uDGGC/gNWAQ8I8itrsfuB+gWbNmzhy6QOHhmjQr5XZXXXX2sn794KGH4ORJ6NXr7PVDh9pbYiLcnq9i69dfizzduHHjaNq0KSNGjADg2WefxcfHh19++YWkpCTS09OZNGkSffr0KfI4+aWmpjJ8+HDWrFmDj48PU6ZM4eqrr2bLli3cfffdpKWlkZWVxZdffkmjRo3o168fsbGxZGZm8vTTT9O/v06yUZYWbF1A4slE7QColKqwynrIuYeAxSISW9S0jSIyE5gJEBERUeLpScLCtDxDqcquf//+jB49Oidpnj9/PkuXLuXhhx+mdu3aJCYm0q1bN3r37u3SdLBTp07FGENkZCTbtm3juuuuY8eOHcyYMYN///vf3HnnnaSlpZGZmcnixYtp1KgR3377LQBHdQD4Mjd9zXTOq3ce/zin0PYVpZTyKGeS5jigaa7nTRzLnHEp0N0Y8xAQCPgZY1JE5KzOhO4QFgZbt5bFkZWqxopqGa5Zs+j19esX27KcX6dOnTh06BD79+8nISGB4OBgwsPDeeSRR1i2bBleXl7ExcVx8OBBwrN7ADthxYoVjBo1CoA2bdrQvHlzduzYwaWXXsrzzz9PbGwst956K61ataJDhw489thjPPHEE/zrX/+ie/fuLr0G5ZrIg5H8vu93Xv3nq3iZKjOok1KqinHm22k10MoY09IY4wcMABY5c3ARuVNEmolIC2AM8GlZJcygU2krVVX07duXBQsWMG/ePPr378+sWbNISEhg7dq1bNiwgbCwMFJTU91yrjvuuINFixYREBBAr169+Pnnnzn//PNZt24dHTp04KmnnmLixIluOZcq2PQ106nhXYOhFw31dChKKVWoYpNmEckARgJLgShgvohsMcZMNMb0BjDGdDHGxAJ9gXeNMVvKMujChIfbqbSTkz1xdqWUu/Tv35+5c+eyYMEC+vbty9GjR2nQoAG+vr788ssvxMTEuHzM7t27M2vWLAB27NjB3r17ad26Nbt27eKcc87h4Ycfpk+fPmzatIn9+/dTs2ZNBg0axNixY1m3bp27X6JyOH76OJ9t+oz+F/QnpGaIp8NRSqlCOVXTLCKLgcX5lj2T6/FqbNlGUcf4GPjY5QhdkHuCk+DgsjyTUqostW/fnuPHj9O4cWMaNmzInXfeyU033USHDh2IiIigTZs2Lh/zoYceYvjw4XTo0AEfHx8+/vhjatSowfz58/nss8/w9fUlPDycJ598ktWrVzN27Fi8vLzw9fVl+vTpZfAqy44xpifwJuANvC8iL+Vb3xz4EAgFjgCDRCTWsS4TiHRsuldEynSWkVmRs0hJS9EOgEqpCs9IBatliIiIkDVr1pRo3x9/hH/+05ZQXnmle+NSqrqIioqibdu2ng6jUijovTLGrBWRCA+FlD22/g7gn9jRjlYDA0Vka65tvgD+JyKfGGOuAe4Wkbsc61JEpPDBrwtQ0u9tEeGidy/Cy3ix7v51LnXsVEopd3DlO7tK9bjI7hOkI2gopaqxYsfWx05U9bPj8S8FrC8XK2NXsungJoZHDNeEWSlV4ZX1kHPlKnd5hlKq+oiMjOSuu+7Ks6xGjRqsWrXKQxF5lDNj628EbsWWcNwCBBljQkTkMOBvjFkDZAAvicjXZRXo9DXTCfIL4o4Od5TVKZRSym2qVNKcPZW2Js1KlY6IVKqWvw4dOrBhw4ZyPWdFK21z0RjgHWPMUGAZdhjRTMe65iISZ4w5B/jZGBMpIn/nP0BpJ6VKPJnI/C3zGXbxMAL9XKoGUUopj6hS5RleXtCggSbNSpWGv78/hw8fruxJYZkSEQ4fPoy/v7+nQylIsWPri8h+EblVRDoB/3EsS3bcxznudwG/Ap0KOomIzBSRCBGJCA0NdTnIj9Z/RFpmmnYAVEpVGlWqpRl0VkClSqtJkybExsaSkJDg6VAqNH9/f5o0KXLQIE/JGVsfmywPAPLUPxhj6gNHRCQLGI8dSQNjTDBwUkROO7a5HJjs7gCzJIsZa2fQo3kP2jdo7+7DK6VUmaiSSbO2NCtVcr6+vrRs2dLTYagSEpEMY0z22PrewIfZY+sDa0RkEXAV8KIxRrDlGSMcu7fFjrWfhb0S+VLuUTfc5cddP7IraRfPX/O8uw+tlFJlpsolzeHhOpW2Uqp6c2Js/QXAggL2+wPoUNbxXdXiKr7o+wW9W5fpENBKKeVWVS5pzj2VdiXqx6SUUtWGn7cft7e73dNhKKWUS6pUR0CwSbNOpa2UUkoppdypSibNoHXNSimllFLKfapc0qyzAiqllFJKKXerckmztjQrpZRSSil306RZKaWUUkqpYlS5pDl7Km0tz1BKKaWUUu5S5ZJmnUpbKaWUUkq5W5VLmkFnBVRKKaWUUu5VJZPm8HBNmpVSSimllPtUyaQ5LExrmpVSSimllPs4lTQbY3oaY7YbY6KNMeMKWN/DGLPOGJNhjLk91/KLjDErjTFbjDGbjDH93Rl8YcLC4NAhO5W2UkoppZRSpVVs0myM8QamAjcA7YCBxph2+TbbCwwFZudbfhIYLCLtgZ7AG8aYuqUNujjh4TqVtlJKKaWUch9nWpq7AtEisktE0oC5QJ/cG4jIHhHZBGTlW75DRHY6Hu8HDgGhbom8CNljNWuJhlJKKaWUcgdnkubGwL5cz2Mdy1xijOkK+AF/u7qvq3SCE6WUUkop5U7l0hHQGNMQ+Ay4W0SyClh/vzFmjTFmTUJCQqnPFx5u7zVpVkoppZRS7uBM0hwHNM31vIljmVOMMbWBb4H/iMifBW0jIjNFJEJEIkJDS1+9oeUZSimllFLKnZxJmlcDrYwxLY0xfsAAYJEzB3ds/xXwqYgsKHmYrqlXz06lrS3NSimllFLKHYpNmkUkAxgJLAWigPkissUYM9EY0wj/ftkAACAASURBVBvAGNPFGBML9AXeNcZscezeD+gBDDXGbHDcLiqTV5KLTqWtlFJKKaXcyceZjURkMbA437Jncj1ejS3byL/f58DnpYyxRMLDtTxDKaWUUkq5R5WcERBsXbO2NCullFJKKXfQpFkppZRSSqliVNmkOTzcJs06lbZSSimllCqtKps0h4VBejokJXk6EqWUUkopVdlV6aQZtERDKaWUUkqVXpVNmnVWQKWUUkop5S5VNmnWWQGVUkoppZS7VPmkWVualVJKKaVUaVXZpLlePfDx0aRZKVX9GGN6GmO2G2OijTHjCljf3BjzkzFmkzHmV2NMk1zrhhhjdjpuQ8o3cqWUqriqbNKcPZW2lmcopaoTY4w3MBW4AWgHDDTGtMu32avApyJyITAReNGxbz1gAnAJ0BWYYIwJLq/YlVKqIquySTPoBCdKqWqpKxAtIrtEJA2YC/TJt0074GfH419yrb8e+EFEjohIEvAD0LMcYlZKqQpPk2allKpaGgP7cj2PdSzLbSNwq+PxLUCQMSbEyX0BMMbcb4xZY4xZk5CQ4JbAlVKqIqvSSXN4uJZnKKVUAcYAVxpj1gNXAnFApisHEJGZIhIhIhGhoaFlEaNSSlUoPp4OoCyFhcGhQ3YqbWM8HY1SSpWLOKBprudNHMtyiMh+HC3NxphA4DYRSTbGxAFX5dv317IMVimlKosq3dKsU2krpaqh1UArY0xLY4wfMABYlHsDY0x9Y0z29/944EPH46XAdcaYYEcHwOscy5RSqtqr0kmzzgqolKpuRCQDGIlNdqOA+SKyxRgz0RjT27HZVcB2Y8wOIAx43rHvEeA5bOK9GpjoWKaUUtVelS/PAFvX3LatZ2NRSqnyIiKLgcX5lj2T6/ECYEEh+37ImZZnpZRSDlW6pVlnBVRKKaWUUu5QpZNmLc9QSimllFLuUKWT5uBgO5W2DjunlFJKKaVKw6mk2RjT0xiz3RgTbYwZV8D6HsaYdcaYDGPM7fnWDTHG7HTchrgrcGdkT6WtLc1KKaWUUqo0ik2ajTHewFTgBuzUqwONMe3ybbYXGArMzrdvPWACcAl2atcJjmGMyk14uCbNSimllFKqdJxpae4KRIvILhFJA+YCfXJvICJ7RGQTkJVv3+uBH0TkiIgkAT8APd0Qt9PCwrQ8QymllFJKlY4zSXNjYF+u57GOZc5wal9jzP3GmDXGmDUJCQlOHto5YWHa0qyUUkoppUqnQnQEFJGZIhIhIhGhoaFuPXZ4uJ1KOyt/G7hSSimllFJOciZpjgOa5nrexLHMGaXZ1y10Km2llFJKKVVaziTNq4FWxpiWxhg/YACwyMnjLwWuM8YEOzoAXudYVm50ghOllFJKKVVaxSbNIpIBjMQmu1HAfBHZYoyZaIzpDWCM6WKMiQX6Au8aY7Y49j0CPIdNvFcDEx3Lyo0mzUoppZRSqrR8nNlIRBYDi/MteybX49XY0ouC9v0Q+LAUMZaKzgqolFJKKaVKq0J0BCxL2S3NOuycUkoppZQqqSqfNGdPpa0tzUoppZRSqqSqfNLs5aVjNSullFJKqdKp8kkz6KyASimllFKqdKpN0qwtzUoppZRSqqSqRdIcHq5Js1JKKaWUKrlqkTRntzTrVNpKKaWUUqokqk3SnJGhU2krpZRSSqmSqRZJs05wopRSSimlSqNaJM06wYlSSimllCqNapU0a0uzUkoppZQqCU2alVJKKaWUKka1SJqDg8HXV5NmpZRSSilVMtUiafbyggYNtKZZKaWUUkqVTLVImkFnBVRKKaWUUiVXbZJmnRVQKTf47jto2RJOnvR0JKoIxpiexpjtxphoY8y4AtY3M8b8YoxZb4zZZIzp5VjewhhzyhizwXGbUf7RK6VUxVRtkuawMC3PUKrUHnoI9uyBnTs9HYkqhDHGG5gK3AC0AwYaY9rl2+wpYL6IdAIGANNyrftbRC5y3B4sl6CVUqoSqFZJ86FDOpW2UqUSGmrvGzXybByqKF2BaBHZJSJpwFygT75tBKjteFwH2F+O8SmlVKVUbZLm8HCdSlupUktPhxtuOJM8q4qoMbAv1/NYx7LcngUGGWNigcXAqFzrWjrKNn4zxnQv7CTGmPuNMWuMMWsSEhLcFLpSSlVcTiXNTtTH1TDGzHOsX2WMaeFY7muM+cQYE2mMiTLGjHdv+M7TWQGVcoM2baB2bYiK8nQkqnQGAh+LSBOgF/CZMcYLiAeaOco2HgVmG2NqF3QAEZkpIhEiEhGqP6KUUtVAsUmzk/Vx9wJJInIe8DrwsmN5X6CGiHQAOgMPZCfU5U0nOFHKDWbPhlWr4IUXPB2JKlwc0DTX8yaOZbndC8wHEJGVgD9QX0ROi8hhx/K1wN/A+WUesVJKVQLOtDQ7Ux/XB/jE8XgBcK0xxmDr5moZY3yAACANOOaWyF0UHm7vNWlWqpSaNYO9ez0dhSrcaqCVMaalMcYP29FvUb5t9gLXAhhj2mKT5gRjTKijoQRjzDlAK2BXuUWulFIVmDNJszP1cTnbiEgGcBQIwSbQJ7CX/PYCr4rIkfwnKI/aOC3PUKqUPv8cmjcHb29Nmiswx3fwSGApEIUdJWOLMWaiMaa3Y7PHgGHGmI3AHGCoiAjQA9hkjNmA/f5+sKDvbKWUqo58yvj4XYFMoBEQDCw3xvwoInlaLkRkJjATICIiQsoiEJ1KW6lS2rED4uKgXz9YvhwyM20CrSocEVmM7eCXe9kzuR5vBS4vYL8vgS/LPECllKqEnGlpdqY+LmcbRylGHeAwcAfwnYiki8gh4HcgorRBl4QxOiugUqUSHW1bms87zw5FEx/v6YiUUkqpcuNM0uxMfdwiYIjj8e3Az45LfXuBawCMMbWAbsA2dwReEpo0K1UK0dE2Yb7hBjszYL16no5IKaWUKjfFJs1O1sd9AIQYY6KxwxRlD0s3FQg0xmzBJt8ficgmd78IZ+msgEqVQnbS3KwZXH891Kzp6YiUUkqpcuNUTbMT9XGp2OHl8u+XUtByTwkLgw0bPB2FUpVQejoMGADXXgsi8N//QpMmcPHFno5MKaWUKhdl3RGwQgkPPzOVtle1mQtRKTfw9YVp0848HzoU7rhDk2allFLVRrVKHcPCbP+lIzqAklKuOXnS/uPJpmM1K6WUqmaqXdIM2hlQKZe98goEBkJamn2uSbNSSqlqplolzToroFIlFB1tf3X6+dnnTZtCTIxnY1JKKaXKUbVKmnVWQKVKKHvkjGzNmkFyMhw75rmYlFJKqXJULZNmbWlWykX5k+bBg2HLFqhVy3MxKaWUUuWoWo2eoVNpK1UCycmQmJg3aW7Y0N6UUkqpaqJatTRnT6Wt5RlKueiFF+Caa848P30apk6FP//0XExKKaVUOapWSTPoVNpKuaxuXRg/Hjp3PrPMxwf+/W87yYlSSilVDVS7pDk8XJNmpVyybx/s3593mbe3nRFQh51TSilVTVS7pFlbmpVy0TPPQNeuZy/XsZqVUkpVI9U2ac7K8nQkSlUS+UfOyKZJs1JKqWqkWibNmZk6lbZSTisqaY6Ntf+glFJKqSqu2iXNOiugUi5ISbHDzRSUND/+OBw+bOublVJKqSqu2iXNOiugUi74+297X1DSXLcu1K5dvvEopZRSHlJtk2ZtaVbKCU2awGefwWWXnb0uKQmeeAL++KP841JKKaXKWbWaERC0PEMpl4SEwKBBBa/z9obJk+02BSXVSimlVBVS7Vqa69YFPz/Ys8fTkShVCfz5J6xfX/C62rXtPygdQUMppVQ1UO2SZmOgVy/46CNtbVaqWOPGwahRha/XYeeUUkpVE04lzcaYnsaY7caYaGPMuALW1zDGzHOsX2WMaZFr3YXGmJXGmC3GmEhjjL/7wi+Zl16CU6dgwgRPR6JUBVfYcHPZmjfXpFkppVS1UGzSbIzxBqYCNwDtgIHGmHb5NrsXSBKR84DXgZcd+/oAnwMPikh74Cog3W3Rl1Dr1vDQQ/Dee7B5s+fiOHrU9rHKyPBcDEoV6uRJiIsrOmlu1sx+kJVSSqkqzpmW5q5AtIjsEpE0YC7QJ982fYBPHI8XANcaYwxwHbBJRDYCiMhhEakQMyE884wtyRwzxnMxjBgBgwfD1Kmei0GpQu3aZe+LSprfeAN27y6feJRSSikPciZpbgzsy/U81rGswG1EJAM4CoQA5wNijFlqjFlnjHm8oBMYY+43xqwxxqxJSEhw9TWUSEiITZyXLoXvviuXU+bx888wa5ZN3J9+GuLjyz8GpYoUHW3vW7UqfBufajcAj1JKqWqqrDsC+gBXAHc67m8xxlybfyMRmSkiESISERoaWsYhnTFihG1Ee+yx8i2ROH0ahg+Hc8+FFSvs88ceK7/zK+WUq66CX36BdvmrsXLZuxfuvNOOsqEqDCf6oTQzxvxijFlvjNlkjOmVa914x37bjTHXl2/kSilVcTmTNMcBTXM9b+JYVuA2jjrmOsBhbKv0MhFJFJGTwGLg4tIG7S5+fnaY2a1b4f33y++8r7wCO3bYsowOHewABXPm2NZnpSqMunVt4hwQUPg2xsDs2bBxY7mFpYrmZD+Up4D5ItIJGABMc+zbzvG8PdATmOY4nlJKVXvOJM2rgVbGmJbGGD/sF+qifNssAoY4Ht8O/CwiAiwFOhhjajqS6SuBre4J3T1uvhl69LClGuXRn+nvv2HSJOjXD653tOGMGwctW9qW77S0so9BKafMnm1bmovSsKGd5ERH0KhInOmHIkD2HOh1gP2Ox32AuSJyWkR2A9GO4ymlVLVXbNLsqFEeiU2Ao7CtE1uMMRONMb0dm30AhBhjooFHgXGOfZOAKdjEewOwTkS+df/LKDljYMoUSEiAF18s23OJwMiRtoX79dfPLA8IgHfegW3bbCxKVQjjx8OHHxa9jY+PnWpbk+aKxJl+KM8Cg4wxsdgrgNmDcTuzL+CZvihKKeVJTtU0i8hiETlfRM4Vkecdy54RkUWOx6ki0ldEzhORriKyK9e+n4tIexG5QEQK7AjoaZ0721EsXn+9bAcCWLDAdjp87jlo1Cjvul69bKv3xIkQE1N2MSjllNRU2Lev6JEzsukEJ5XRQOBjEWkC9AI+M8a41MfFU31RlFLKU6rdjICFef55e5V5/PiyOf6xYzB6NHTqZMswCvLGG7ble/TosolBKaft3m0vjTiTNLdtC/4en7NIneFMP5R7gfkAIrIS8AfqO7mvUkpVS5o0OzRpAmPHwrx5sHKl+4//zDN2WLkZMwofpat5czv83Ndfw7cVqohFVTvZw805kzS/+64du1FVFM70Q9kLXAtgjGmLTZoTHNsNcMzy2hJoBfxVbpErpVQFpklzLmPH2n5NjzxiG9ncZf16ePttePBB6FpMl5pHH4U2bWDUKDvVt1Ie4UrSrCoUJ/uhPAYMM8ZsBOYAQ8Xagm2B3gp8B4yoKBNSKaWUp2nSnEtgoC3TWLXKtji7Q2amTZbr14cXXih+ez8/mDbNXh1/6SX3xFAWdOrvKm7kSJs416tX/LYbN9ohaNatK/u4lFOc6IeyVUQuF5GOInKRiHyfa9/nHfu1FpElnnoNSilV0WjSnM/gwXDRRfDEE+5p6X3vPfjrL3jtNTvsrTOuvhruuMMmzTt35lqRmgrp6aUPqpR+/BFCQ+29qqJ8fe3sO8YUv623Nyxfnu/DqpRSSlUtmjTn4+1tE9y9e+HNN0t3rIMHbcfCq6+2k6a54tVXbd+qUaNylYo0bAg33li6oErp1Cl44AFITralJJl64bZqevppWOJkI2OzZvZeR9BQSilVhWnSXIBrroGbbrLlFAcPlvw4Y8bAiRO23MKZBrvcGja0Q9MtXQpffomdQjA5GX74wb0F1y6aNAl27bIjgERGwmefeSwUVVbS0uyH39kesbVr28somjQrpZSqwjRpLsQrr9hW1QkTSrb/L7/A55/bMo82bUp2jIcesqUio0fDyZhckwd46DL45s122vEhQ2zHxi5d4Kmn4ORJj4SjykpMDGRludYJsICxmjMzoWNHe0VCKaWUquw0aS5E69YwfLitSd682bV9T5+2+55zDjz5ZMlj8PGxrdRxcTDh+8th61Y7K0psbMkPWkJZWbYso04dWzpijP1hERdX+jIWVcGUZOSM7t2hadM8i/73P9i0yX6GS3PFRimllKoINGkuwoQJ9srzyJGwYgUcOOBcZcSrr8L27XZq7ICA0sVw6aUwfPAJZrx+is0ZbWzCfM01pTtoCbz/Pvzxh31t9evbZVdeactYXnzRTkOuqoiSJM3vvGNvubzxhu0wmpZ21iqllFKq0qmeSfPvv0NiYrGbhYTYIeh++802pDVsaJPoTp2gb1/bye+DD+z6/fttQr1rl637vf12uOEG94Q7uc2HHMisz9PDDiC4WBztBgcO2DKTq66ypRm5vfyyrdueNKncw1Jl5dAhe0mhFFMjb9gAv/4Kjz8OffrY1uYTJ9wXolJKKVXeql/S/P33NgMeNsypzR96yCbCS5bYOt577rEVEps22VbX++6zyWTjxlCrlp28xMfHtrK5S+D3C0lr2IKvVzVk8cjF0KKFnV6wnDz6qK1bnjHj7A6Nbdva92DatDMNlKqSe+45mzi70nv1xx+hZUuIigJsyU6tWnDvvXbSoCNH4KOPyihepZRSqhwUMqFzFbV/PwwaZJOB//3PFlqGhRW7W8uW9pZfRgbs22eTxZ077f3ff8OAATaJdouEBFi2jLrjn+Sq3+H/ptXnRmJI/t8K6g7r66aTFG7pUpgzB5591tZ5F+TZZ22nxyefhPnzyzwkVR78/FzbPiAA9uyBmBgO1mvL7Nn2d2lwMFx2mb1NmWIn+ilsGnmllFKqIqteLc0ff2yvES9caMeDc3UcuHx8fGwy/c9/2hbpKVPgm29g4ED3hAvAf/8LWVmY225l6VK4+dlOnKAm80Yt58MPy3b0uZMnbYfG1q1h3LjCt2vY0L6dX3xhZ1NUlVhGBtxyCyxe7Np+ucZqnjHD1jE//PCZ1WPG2FkuFy50X6hKKaVUeapeSfP48bbYsk8f23utQQNPR1S8hQttOcZFF+HnB09O8IVu3bjaZwX33gv/+EfZlUU895xNdN59F2rUKHrbMWNso/3YsR4dRtpjVq2yVT/vv+/pSEpp7174+mtbyO6Khg3B25uMXXuZNg169YLzzz+zundvaNXKjrhSHT8fSimlKr/qkTT/9pudHMQY+z832EFkFy+GLVs8G1txJk6EqVPztIrXur47rU5t5IPXj7FmDXToYDvkuXOG7chIW7N99912lIziBAXZMo3ly2HRIvfFUdFlZNgfF5dfbqdLHzbMPq+0iWFJRs4Ae9mlcWNilu/l0CE7tnhu3t7w2GOwZo3956iUUkpVNlU/ad63D267zfbgy53JnDoF/fvbObMrsosvts12ufXsibn/fu4ZcJKoKDtKx7hxthPi2rWlP2X2mMx169qWQWfde68t5XjiCZtMVnW7d9tOoM88Yz9KcXEweLB9PmpUJZ1ivKRJMyC39+WbPR1p185eAclv8GA7IIcrnymllFKqoqjaSXN6uu2Vd/o0fPhh3hrmwEC7bv58OH7cczEW5d13C26W69YNpk+H8HAaNbIVHF9+afs1du16ZvruknrvPTuD8muv2WH3nOXrCy+9ZMeo/uCDkp+/ohOxHR87drQt8p9/DrNm2fGrP/rIvv9Tp8Idd9iPXmklJdkxw3/9tfTHKlZ0tO3U17Chy7su6/0qj+1/jNGjC+4uEBBgf0xUhgs8Siml1FlEpELdOnfuLG4zdqwIiMyZU/D6lSvt+vfec9853eXkSZGaNUUefLDg9RkZItHReRYlJYk88IB9SS1biixZIpKV5dpp4+NF6tQRueYa1/cVsftccYVIWJjI8eOu71/RJSWJDBhg3+MrrhDZvbvg7V55xW5z7bUix46V7FxZWSKzZ4s0aGCPZYzIuHEiaWklDr94Y8eKXH11iXa9+WaR+vUy5eSJwj84iYn2Y3333SUNsOID1kgF+C4tz5tbv7eVUqocufKd7dxG0BPYDkQD4wpYXwOY51i/CmiRb30zIAUYU9y53Pbl++OP9uUVlnSK2KykXTuRbt3cc053+vprG//33xe8/vHHRWrUEElNPWvVb7+JtG5td2/eXGTkSHuY06eLP23//vaw27eXPPTs3yITJpT8GBXRb7+JNGsm4u0tMmmS/d1SlE8+sdtefLHIwYOunWvXLpHrr7fvY0SEyIoVIvffb5936SKyc2fJX0dZ+PtvkUF8JuleviKxsUVuO3KkiK+vSFxcOQVXzjRpVkqpysOV7+xiyzOMMd7AVOAGoB0w0BjTLt9m9wJJInIe8Drwcr71U4AlLjaCl87ll9vp/F5/vfBtjLGFuHFx9hp4RbJwoS0qvuqqgtd362av/RdQxNyjhx0k5P33bQnBBx/AddfZ8oF+/eCzz+Dw4bMPuWQJzJsH//lP3pEPXNWtm50R8dVXy3UOljKTnm7fk6uussMX//GHfe7tXfR+gwfbTpFRUfbjuHu3c+d6+WVo395OXPnWW/Dnn3b/d9+FBQtsBUWnTvDJJxWnw+Hbb0OyVz18stLtCBxFeOQRW+/91lvlFJxSSinlDsVl1cClwNJcz8cD4/NtsxS41PHYB0gEjOP5zcArwLOUR0vz6dMiR486v/2pU8U3GZa3tDSR4GCRwYML3+bgQdvs+NJLxR7uxAmRRYtEhg0TCQ+3u3l5ifToYcsItm+327RoIdKmTYGN1y7bsUPEx8eWi1Rm27fbll4QuffekpWc/PGH/XOGh4ts2FD4ditXinToYM91yy0i+/YVvN3evSJXXmm3GzhQJDnZ9ZgKPXCnTiI//ODSbkePigQFiTzeK9IGNXdusfv07WvLgEpaulKRoS3NSilVabjyne1MR8DGwL5cz2MdywrcRkQygKNAiDEmEHgC+L+iTmCMud8Ys8YYsyYhIcGJkIowbhx07gzHjjm3vb+/bTJMT684Qz7s2mUHRr711sK3adDADlWxfHmxh6tZE266CWbOtI3qf/1lZ+87etSOq9y6tZ2bYs8e58ZkdkarVnZilPffz5lZuVJJT7ctoZ062T/Hl1/a1xIY6PqxLr0UVqywo7L16HF2386jR+3kOJddZi94fP21vdDQpEnBx2vaFH76yV5ImT8fLrrItn6X2s6dsH598U3o+Xz8se1L2/exMxOcFGfsWPu633uvBHEqpZRSHlDWo2c8C7wuIilFbSQiM0UkQkQiQkNDS362r7+25Rg9e0Lt2s7vt2OHzUS++abk53an1q1tdvuvfxW9Xffu9hp+VpbTh/bygi5d7FjCGzbYRPmdd+yyp5+2SZ27PP20TdjHj3ffMcvDjz/aRPTf/7Zv8aZNRf9+cUa7djaxbdwYrr8evvrKllYsWABt29ofKw8/DFu32rl3iuPtbX/4rFhhq4x69LBDepfqd18JhpvLLrO47DKIuKY21KnjVNLcpYsd//uNN9w7vrhSSilVVpxJmuOAprmeN3EsK3AbY4wPUAc4DFwCTDbG7AFGA08aY0aWMuaC7d4NQ4dCRIQtpnXFuefaZsCKME6aiE2CvbyKb/EbPhxmz3Ypac6veXMYMcLWM0+cWOLDFCg01Db8f/ONUw3iHvf333DzzXZa9NRU+xtsyRKb6LpD06b2fejUydZ8X3EF9O1rR3dbtcomkEFBrh2zWzf742fgQDss3dVXO5WzFiw62l5mcOEFf/utfd9yJjPJ/qXhhLFj7TDq8+eXIFallFKqvBVXv4GtUd4FtAT8gI1A+3zbjABmOB4PAOYXcJxnKaua5tRUW3hap44ddqAk/vMfW+hbWCFpefn9d5HGjUVWr/ZsHG5y4oR9OUFBIv/6l8iUKSLr14tkZno6sjOOHRMZP17Ez0+kVi2RF190T113YVJSRG680Z5ryhSR9HT3HPezz+z7XKeOyLx5JTjALbfY0WRccPXVIk2bluw1ZGba03XsWLLhDctSQkLJRyhBa5qVUqrScOU7u9iWZrE1yiOxnf2iHAnxFmPMRGNMb8dmH2BrmKOBR4FxbsnonXX8uK1N/vhjaNmyZMe45x7bYvvxx+6MzHULF8KhQ2em+y7On3/afSqomjXhf/+zLaHbt8Ojj9qW1tBQW/Lw9tt2ogvxwCgQWVnw6ae2GubFF+2sfjt22NZxd9R1F6ZWLfjvf+2f+ZFH7EUOdxg0yLY6t2ljX8uDD9qJL53WqpUtbXLSxo3wyy92wpKc15CVBQcOOLW/l5edWnvjRlsS4ynJyfDzz3bUkr597VdIaKi9AqOUUkplyx7hosKIiIiQNWvWuL5jdklDaVx7rS3ziI4u/bFKQsSWirRpY6dNc8aAAbawdd++gqdhq2BiY22ilX3bs8cub9DADul29dVwzTWlG/LOGX/9ZWuIV62y9bVvvWVLHaqC9HRbT/7yy3bIwfnzy+b9vOceO0RhbCwEBzsWvvyy/dVx/LhTvSZPn7ZJ6gUXwPffuz/G/FJSYN06WLPmzG3nzjPrzznHVnhFRNg67csvd/0cxpi1IhLhvqgrvhJ/byullIe58p3tpjauCsAdSe7EiZCW5rnkc+NGm7Q/+aTz+3TvbjOXmBho0aLMQnOXJk3grrvsDezLzZ1EZ9e3Xned7azYtat7zx8fbzsmfvIJhIXZaa8HD/bMb6Sykj2deY8e9rV17mxHThk4sIidRFz63B86ZKcOv+++XAkz2GFYwP6Ia9u22OPUqGF/vIwfbz/+HTs6HYLTUlLsKB0ffpj3qkbTpjY5zu4K0bmza9PGK6WUql6qUKrgBpdfbps6PZU0L1xos7fevYvfNtsVV9j7ytDTrgAtW9oWy88+s3nWjh22sXLdOrjkEvtWbNhQ+vNERtpyhfPOs30nH3/cnmvo0KqVMOfWq5d97zp2hDvugAceKKJcVwCQ7AAAIABJREFUY9kyW5OwapVTx54xw/6+fPjhfCuaOT/sXLYHH7SN0q723y1OQgI884wN6dFH7cAeEybYcqH4eBviwoX2N+p112nCrJRSqmhVNF0ohZgYW2h65Ej5n/sf/7CD7zZo4Pw+F1xgs4EVK8ournJijC2rffxxOzby88/nHW1iyxbXjpeWZhvhe/SACy+0rcv9+tnjvPyya6MSVlZNmsCvv9qW3JkzbQnK9u0FbBgdDYmJTn32Tp+GadNsUt66db6VJUia69aFYcNg7lz7w6m09uyxddbNm9urFVdeCStX2n8iEybAjTdCeHjpz6OUUqp60aQ5v8OH7dhfs2eX/7l79LD1oK7w9rYt5KtXl01MHhIUZFsAd++2rYXffw8dOsCdd+atQS1IXJzdp3lzW/IdFwevvGJrbz/6yPk+llWFjw+88IIdPm//fluGMGtWvo127rR1HU2bFniM3ObNg4MHcw0zl1vDhvYzGRPjUoyjR9uyiTfecGm3PDZtsp0hzzvPjns9YIAd9/qrr6pOvbqzjDE9jTHbjTHRxpizvlSMMa8bYzY4bjuMMcm51mXmWreofCNXSqmKq+p0BHSnTp1ss+e6deV3zuXLbaZ40UWu73vgANSrB35+7o+rgjh82Ca+b79tWzoHD7aJcXYZt4htUZ061Y6vnJUFN9xgR0Do2bPqlmC4Ki7O1jYvXw733ms7QNasiW3Kj4wspBn6DBGbdJ8+DZs3F1LJNGWK7V3p5HjN2QYNsglur162wbp5c3uf/bhevbPPJ2JbkF96yfadrVXLlqE88kjhMyqWNU93BDTGeAM7gH9iZ3BdDQwUka2FbD8K6CQi9ziep4iIS3NfFvS9nZ6eTmxsLKmpqSV4Fcrd/P39adKkCb6+vp4ORakKpXp2BHSne++113fXr7cJdHl47DGbEThZU5pHNbjWHBJiE6NHHrH306fbOuj77rOz7c2YYVsV69Wz2wwfbkdCUHk1bmyHV5swwbY+r1oFX3wBbaKjc2YCTEuz9cCHDp19i4mx/yxmziyi9P/RR0sU26RJcOyYTca//fbs+utatfIm0Y0bw3ff2dKL0FBbivHQQ/YzUM11BaJFZBeAMWYu0AcoMGkGBgIT3B1EbGwsQUFBtGjRAlMJRvapykSEw4cPExsbS8uSDsuqlNKkuUB33gljxtgZAt95p+zPt3evLa948cWSH+PJJ6FRIxhZNhMuVhRhYXam9Mces0nf++/bIdYiImzpRf/+EBDg6SgrNh8fWy/eo4dt3e3cGaaG9Cb6QDOm1YOkpIL3q1HDljzffLP9J1KoI0fsZ9rFqyYtWsAiRzGAiL26EBNjDxUTk/fxunU2sf//9u49zuZybfz453II0cNUEoMQlc0Yp6h0ULI7PKLDHrRV6KB0eKhnF509JU9npafTKKfdgXKotp+XSthqUzskcuiwSyExDLYpZMz1++Naa2YZc561rNP1fr3Wa9b6rvX9rvvrO3O71r2u+7qbNbM/0cGDAyPmDiAVCM0O34itznoIETkBW7hqfsjmmiKyFMgFHlXVdyrSiL1793rAHCNEhGOOOYasrKxoN8W5uOZBc1FSUmDgQMvxPBzeCfyfdPnlFT/Gxx/bEGGCB81BjRvbZLS777Ygr127aLco/lxwgVXXGD4cJmU9RIMGMOA4C4yDtwYNCu4fdVQZC8s88QQ89ZQNFZe2FHwxRODYY+3WqVPRr9mzxwJ5T72plP7AdFU9ELLtBFXdJCItgPkiskpV/1V4RxEZAgwBaBqcAHroayLQZFcRfi2cqzwPmovz8ssV3/f99y2to6xVMGbOhDZtKrcCxVlnWbDy66/2PXaSaNKkTHPXksv+/TaDslWrUqPc1FR4e0ogDyJcQ/RNm1obtmyxbz8iIS+PWlX2w8TXbOjb68WF2gSE/lU0DmwrSn/goLUPVXVT4Of3IrIQ6AAcEjSraiaQCZbTXOlWO+dcjPMxmpKoWjHfkqxZY8uvDRxoj/fssUlVqan28/334cCB4vfPyYFlyyo3ygxWrzk3t2I50S6xDBtmteDeftselzbZd9o0y234/vvwvH9w1LGcFTTK5ZprrKb69dfb7E8X6nOglYg0F5EjsMD4kCoYInIKkAIsCdmWIiI1AvePBbpRfC60c84lFQ+aS/LSSxZ8FA4mNm6Exx+3nM02bSy59pdfbHStVq2CNZoXLrTSDS1aWL2votSpY/vefnvl2nrGGTaqGKeLnLgwWbrUfm8vvth+9wCefdZqrj33nM3mK+y77yyNIlxD9hWo1VwuP/wAb75ppRZ79bLz+u23yLxXHFLVXOBW4H1gLfCWqq4WkYdEJHTlpP7AVD24hFJrYKmIfAkswHKaPWguQW5ubrSb4Jw7TDw9oyS9elmO8MSJFgQfeaSlPsycCSNGWCAybhxkZBxcwaJ1a8vpHDMG3n3XZqsFv6ZeuRL+9S87djBnunbtyqdU1KsHPXpU7hguvuXl2e/rccdZnfHg6i3169s3IP/1X/bhrGdPW8f8z3+257/7zmbUhSuHP9JB89NPW5A/bJgF0GefDZMmWekMB4CqzgHmFNr2QKHHo4rYbzGQFu72DJ87nBW/hGFpzxDtj2/PMxeWXNj70ksvZcOGDezdu5dhw4YxZMgQ5s6dyz333MOBAwc49thj+eijj8jJyeG2225j6dKliAgPPvggV1xxBXXq1CEnJweA6dOnM3v2bCZNmsSgQYOoWbMmX3zxBd26daN///4MGzaMvXv3UqtWLSZOnMjJJ5/MgQMHGDFiBHPnzqVKlSrccMMNtGnThnHjxvFOYC7Lhx9+yAsvvMCsWbPC+u/jnAs/D5pL0qSJzZZ66imrbJGZaWs+X321Bb2l1TSrUcOWoOvbt2BbZqZ9nXzccfYV88cfW62t88+vfHs//LBi+2Vl2YwrEfjyS1t32cWfiRMtPWfKFFslMmjAALt99ZWtavLGGzB+fEHQPG2a/Z6HS926FsR2LbJgQ+Vs22ZVbQYMsNmgqalw+um2BveQIVYaxLmACRMmcPTRR7Nnzx5OPfVU+vTpww033MCiRYto3rw52YGVXx9++GHq1q3LqlWrANhRXAmZEBs3bmTx4sVUrVqVf//733z88cdUq1aNefPmcc899zBjxgwyMzNZv349K1asoFq1amRnZ5OSksLNN99MVlYW9evXZ+LEiVx77bUR/XdwzoWH/w9TmhEjbBm1iy6yvGGw6hopKRU73jPP2LHGj7faaQcOhH/iXl5e2UsKbN1qC1FcdZWN2F14Idx7Lzz0kJcliDdnngl33mnXsiht29qHv0cesXpuUJCu0bp1eNsSzPEPtxdesFHzv/zFHovYuusPPQSbN/us0BhV2ohwpIwbNy5/BHfDhg1kZmZy9tln59cqPjpQ1HvevHlMnTo1f7+UMvTvGRkZVA1Uh9m1axcDBw7k22+/RUTYv39//nFvuukmqgU+zAXf7+qrr+a1115j8ODBLFmyhClTpoTpjJ1zkeRBc2nOOcfqcoVLtWrwn/9pt82bYfVqGykLh927rWrHLbeULUd63z6bgJiVZT/btbOJVY88YssqT5rkRY/jycknW659aapUsZQNsA9/H30U/m8XvvnG0jPC8Q1KqBtusPSPNm0KtvXpYzcvqeVCLFy4kHnz5rFkyRKOPPJIunfvTvv27Vm3bl2ZjxFapq3wyoa1QwY77r//fs4991xmzZrF+vXr6d69e4nHHTx4MJdccgk1a9YkIyMjP6h2zsU2H0qMpoYNwxtUHHWUVUooy2RAVVs27x//sOC4UyfLac3MtMDr7betOsGWLeFrn4uMZcusUktFrlX16nDeeeEv2fbMM9C/f3iPCfY3M2jQwdtE7LZjh80XcA4b/U1JSeHII49k3bp1fPrpp+zdu5dFixbxww8/AOSnZ/Ts2ZPnQ6qwBNMzGjRowNq1a8nLyysx53jXrl2kpqYCMGnSpPztPXv25OWXX86fLBh8v0aNGtGoUSNGjx7N4MGDw3fSzrmI8qA50Zx1FnzySellxsaOtRzYBx44OOdaxL7inzEDVq2yUchE8vPPlr6SKPLy7JuFTz6BmjWj3ZoCTZtaCsivv4bneLm5loP9ySdFP69qOdRDh4bn/Vzcu/DCC8nNzaV169aMHDmS0047jfr165OZmcnll19Oeno6/fr1A+C+++5jx44dtG3blvT0dBYsWADAo48+Sq9evTjjjDNo2LBhse911113cffdd9OhQ4eDqmlcf/31NG3alHbt2pGens4bb7yR/9yAAQNo0qQJrcOdGuWcixxVjalbp06d1FXC+PGqoLpuXcmve/dd1YEDVQ8cKP41mzYV3N+2LSzNi6q33lIVUe3RQ3Xfvmi3JjxeecWu95Qp0W7JwV5/3dq1Zk14jjdtmh1v5sziX/Poo/aa5cvD854VBCzVGOhLD+etqH57TbiufYK65ZZb9JVXXjms7+nXxLlDlafP9pHmRHPWWfazuBSNffvsZ+/elpZR0mS/YJm85cuhefPKrZIYbYsXW9WT1q2hY0c44ohot6jysrNtouqZZxY/+S9awll2TtVShk46yX5vi3PjjZaiVJa8bueiqFOnTqxcuZKrYu3v1jlXojIFzSJyoYh8LSLficjIIp6vISLTAs9/JiLNAtt7isgyEVkV+HleeJvvDnHSSVar9+STD31u+3ab8DVhQvmO2aqVBWY33QT//d8lr3AYi7791oKtpk3h738vCKo+/xwefjj+zido9GjYudNKGMbaJLgTTrCf4QiaFy60vO2//MXqMxenXj0LnN96y+o3Oxejli1bxqJFi6hRo0a0m+KcK4dSg2YRqQo8D1wE/AG4UkT+UOhl1wE7VLUlMBZ4LLB9G3CJqqYBA4G/hqvhrhgitkJacMQ5aP9+W4Tlhx/KX17sqKPgvfcsGH/6abjiivDlqh4On35qVUvmzLF61EEzZ1pO9wUXxOeEx3vvtZrL7dpFuyWHatTI6ob36VP5Yz3+ODRoYN8UlGb48IJr7ZxzzoVRWercdAG+U9XvAURkKtAHCF1atQ8wKnB/OvB/IiKq+kXIa1YDtUSkhqruq3TLXfFUYd06C1yCi1wMGwYLFsDkyRUrcVetmgXjJ51kgcmLL9rI39y5FlAHKxgEb2PG2BLhc+bYZMIGDWyp786dD/+EtauvtuAtuEJe0Jgxdj633GJLor/+ulWSiHV5eXaNjznm4EmcsaRq1fBUhlG12uGXXVa235vUVPtgGEwtcs4558KkLOkZqcCGkMcbA9uKfI2q5gK7gMI1rK4AlhcVMIvIEBFZKiJLs7Kyytp2V5xly+APf7CAFmxBiBdftEUgrrmmcse+7TYrUxesA71unZWnmzYN3nzTAs+//hV+/92e/+c/LRd6xAgb/f6P/4Bu3Qqe3xehz095eXDddQUjjoUDZrDgfvBga2O9ehbkBWbNx7SJE61SRKz/rSxaBNOnV+4YIvaBb8iQsu8TDJh/+61y7+2cc86FOCwTAUWkDZaycWNRz6tqpqp2VtXO9YOLLriKa9/eVhkMTgbMybGc3jFjwnP8004ryC0dPtyCt23bLGc6O9vq5QZWvmLUKHv/rVvh3Xct2G7RomAi3uWXQ8uWtoLcyy/bUs/hKAl3992Wu71mTemvbdvW8pvHjLFVEaH0kn3Rkp0NI0faqGtoqkksevll+6BWUT/9ZNewIh+snnnGfs/iKY3IOedcTCtL0LwJCF2btnFgW5GvEZFqQF1ge+BxY2AWcI2q+soDh0O1apaCEQya77oLZs0qeRJVpNWvb4H7Y4/ZSHRQ796Wkzt3rk00TEuzNI7KBK0vvWR5sEOH2sTFsqhTx4LRqlUtv7ljx9isUX3//RY4x+Lkv8KaNoWNGys+0fLpp21iX0XyzU891fabOLFi7+2cc84VUpag+XOglYg0F5EjgP7Ae4Ve8x420Q/gT8B8VVURqQf8P2Ckqv4jXI12ZXD66bByJbzzjj0uqbRcNN14o03I++UXq3IxeTI8+qgFhL/+asHv7t1lP96cOZajfPHFMG5cxQLLXbtsdLNnTwu8J02CJUuivyjK8uWWZnPrreFf9joSmja1CagVCXqzs+GVV+DKKwvK15VHt2724eupp2xhFOdKUadOnWg3wTkX40qdCKiquSJyK/A+UBWYoKqrReQhrCD0e8CrwF9F5DsgGwusAW4FWgIPiMgDgW1/VNWt4T4RV8hll9mS2EXl8sYiEUvTaNmyYNucOZYL/cQTlm4xdCjUqlXycT74wALKadNsxL0iTjrJ8pyHDbPA7aWX7H1zcuz5xx+Hb76xsn7BW4sWtiR1JD39tI3Y/8//RPZ9wiW0VnN5J+a9+KJ9aLrzzoq//113waWXWs79lVdW/DguLLp3737Itr59+3LzzTfz22+/cfHFFx/y/KBBgxg0aBDbtm3jT3/600HPLVy4MEItja7c3FyqVbTvcs5FVJmGH1V1jqqepKonquojgW0PBAJmVHWvqmaoaktV7RKstKGqo1W1tqq2D7l5wHw4dOhgo7fxUA2iOBkZVi6ufXtLs2jZ0gLYkkZ8x461ur6VHTWqUwdefdUmk339tQXwwdH6DRtg9mwLyvr0gVNOsbSSoLfftnSTrWH+VX/1VZg3zyYtxoOKLnCyZ499S3DRRQf/u5bXJZfYtRk7tuLHcHFr5MiRPP/88/mPR40axejRo+nRowcdO3YkLS2Nd999t0zHysnJKXa/KVOm5C+TfXWgLOKWLVu47LLLSE9PJz09ncWLF7N+/Xratm2bv9+TTz7JqFGjAPtAMXz4cDp37syzzz7L3/72N7p27UqHDh04//zz2RL4tiYnJ4fBgweTlpZGu3btmDFjBhMmTGD48OH5xx0/fjy3BydqO+fCq6xLBx6umy+j7Yq0YIHqGWeonnOOal6ebQv+3LlTtXdv1bVrD2+bduxQ/ewzW8J68uSC7U2a2HLOoNqokWqvXqqvvlq2Y27fbsd7+GHV666zJb9PPFF19uzInEMk7dtn12TPnvLt9+23qu3b2zWvrE8/Vf3pp/Lts39/pd4SX0ZbVaO/ZPPy5cv17LPPzn/cunVr/emnn3TXrl2qqpqVlaUnnnii5gX6kdq1axd7rP379xe531dffaWtWrXSrKwsVVXdvn27qqr27dtXx44dq6qqubm5unPnTv3hhx+0TZs2+cd84okn9MEHH1RV1XPOOUeHDh2a/1x2dnZ+u8aPH6933HGHqqreddddOmzYsINet3v3bm3RooX+/vvvqqp6+umn68qVK4s8j2hfE+diUXn6bP8OyMWH7t3hk08s31gEfv7ZRhJHjLAUigULrBzeKaccvjbVqwddutgt1MqVsGIFfPGF5SF/8YVtA8uvbdbMFphJTbVR6/XrLQ3hppss/zdYFvD44+21nTsX1NuOJ0ccYdfjgw/gyy+hRw/71qC0/PqWLe3fLRy6di3b677+2qq7vPOO/bvPnBme93dR06FDB7Zu3crPP/9MVlYWKSkpHH/88dx+++0sWrSIKlWqsGnTJrZs2cLxxx9f4rFUlXvuueeQ/ebPn09GRgbHBirZHB2oGjR//nymTJkCQNWqValbty47duwo8T369euXf3/jxo3069ePzZs38/vvv9O8eXMA5s2bx9SpU/Nfl5KSAsB5553H7Nmzad26Nfv37yetMt/QOOeK5UGzix8iBakJmzfb1/jB/2hefTU8i2mEQ716FuSH5nAGq4Hk5FjawfLlsHatpTB07VqQytCypdW+btq09PztePHBBzYhD6wU4bnn2rW68cZDJ2quXWtBayAYCIvvv7c6z489Bp06HfzcCy/Yoj3r1tnjjh0rtviPi0kZGRlMnz6dX375hX79+vH666+TlZXFsmXLqF69Os2aNWPv3r2lHqei+4WqVq0aeSGpZYX3r127dv792267jTvuuIPevXuzcOHC/DSO4lx//fWMGTOGU045hcGDB5erXc65sovRkgrOlaJTJ1i1yhZTmTwZrr022i0qWTA4rFcPxo+3BWg2boTFi20p7OAkqOrVbWJhogTMAE8+CZs2WanB3r1tkuVzzxX8m4wbB6+9Zh+EBg4Mfx7+McdYHe7//V94/32rPrJnjz2XnW0j/s89Bz/+aNelMpMPXUzp168fU6dOZfr06WRkZLBr1y6OO+44qlevzoIFC/jxxx/LdJzi9jvvvPN4++232b59OwDZ2dkA9OjRgxdffBGAAwcOsGvXLho0aMDWrVvZvn07+/btY/bs2SW+X2qqrSE2efLk/O09e/Y8KE87OHrdtWtXNmzYwBtvvMGVPunVuYjxoNnFr6pV4c9/rvwqhy7yGjWCq66yusk//mirBYKNwD/7rC113qiRBbflWf2vLOrWtdSXGTNsSe5Jk2D1anvuvvtscuWtt1astJ2LaW3atGH37t2kpqbSsGFDBgwYwNKlS0lLS2PKlCmcUsZ0ruL2a9OmDffeey/nnHMO6enp3HHHHQA8++yzLFiwgLS0NDp16sSaNWuoXr06DzzwAF26dKFnz54lvveoUaPIyMigU6dO+akfAPfddx87duygbdu2pKensyBkBdO+ffvSrVu3/JQN51z4icbYymedO3fWpUuXRrsZzrnDJS/PcsA/+shyvB97LPwj7dnZVrLv9NMtt7pmzfAeP4SILFPVzhF7gxhUVL+9du1aWrduHaUWJZ9evXpx++2306NHj2Jf49fEuUOVp8/2nGbnXHRVqWK5xB07Ru49jj4aRo+O3PGdi5KdO3fSpUsX0tPTSwyYnXOV50Gzc845B6xatSq/1nJQjRo1+Oyzz6LUotLVq1ePb775JtrNcC4peNDsnHMuIlQVqchS9lGSlpbGihUrot2MiIi1VEzn4pFPBHTOORd2NWvWZPv27R6sxQBVZfv27dSMYC6/c8nAR5qdc86FXePGjdm4cSNZWVnRborDPsQ0btw42s1wLq550Oyccy7sqlevnr+SnXPOJQJPz3DOuQQjIheKyNci8p2IjCzi+bEisiJw+0ZEdoY8N1BEvg3cBh7eljvnXOzykWbnnEsgIlIVeB7oCWwEPheR91R1TfA1qnp7yOtvAzoE7h8NPAh0BhRYFth3x2E8Beeci0k+0uycc4mlC/Cdqn6vqr8DU4E+Jbz+SuDNwP0LgA9VNTsQKH8IXBjR1jrnXJyIuZHmZcuWbRORHyuw67HAtnC3Jwb5eSaOZDhHSL7zPCHK7UgFNoQ83gh0LeqFInIC0ByYX8K+qcXsOwQIrnmeIyJfV6CtyfC7kQznCMlxnslwjpB851nmPjvmgmZVrV+R/URkaTIsXevnmTiS4RzBzzPG9Qemq+qB8u6oqplAZmXePE7/zcolGc4RkuM8k+Ecwc+zJJ6e4ZxziWUT0CTkcePAtqL0pyA1o7z7OudcUvGg2TnnEsvnQCsRaS4iR2CB8XuFXyQipwApwJKQze8DfxSRFBFJAf4Y2Oacc0kv5tIzKqFSXxPGET/PxJEM5wh+noeVquaKyK1YsFsVmKCqq0XkIWCpqgYD6P7AVA1Zsk9Vs0XkYSzwBnhIVbMj2NyY+DeLsGQ4R0iO80yGcwQ/z2KJL3HqnHPOOedcyTw9wznnnHPOuVJ40Oycc84551wpEiJoLm3J2EQhIutFZFVg6dul0W5POIjIBBHZKiJfhWw7WkQ+DCzj+2FgQlJcK+Y8R4nIppDljC+OZhsrS0SaiMgCEVkjIqtFZFhge0JdzxLOM6GuZyR5nx3fkqHfToY+G5Kj3w5nnx33Oc2BJWO/IWTJWODK0CVjE4WIrAc6q2rCFB0XkbOBHGCKqrYNbHscyFbVRwP/oaao6ohotrOyijnPUUCOqj4ZzbaFi4g0BBqq6nIROQpYBlwKDCKBrmcJ59mXBLqekeJ9dvxLhn47GfpsSI5+O5x9diKMNJd3yVgXQ1R1EVB4dn4fYHLg/mTslzuuFXOeCUVVN6vq8sD93cBabDW5hLqeJZynKxvvs+NcMvTbydBnQ3L02+HssxMhaC7zsq8JQIEPRGSZ2BK2iaqBqm4O3P8FaBDNxkTYrSKyMvBVYNx+/VWYiDQDOgCfkcDXs9B5QoJezzDzPjsxJezfeSEJ+zeeDP12ZfvsRAiak8mZqtoRuAi4JfD1UUIL1JCN7xyi4r0InAi0BzYDT0W3OeEhInWAGcBwVf136HOJdD2LOM+EvJ6uUpKuz4bE+jsvJGH/xpOh3w5Hn50IQXPSLPuqqpsCP7cCs7CvORPRlkAOUjAXaWuU2xMRqrpFVQ+oah4wngS4niJSHeuUXlfVmYHNCXc9izrPRLyeEeJ9dmJKuL/zwhL1bzwZ+u1w9dmJEDSXacnYeCcitQMJ7IhIbWx5269K3ituvQcMDNwfCLwbxbZETLBDCriMOL+eIiLAq8BaVX065KmEup7FnWeiXc8I8j47MSXU33lREvFvPBn67XD22XFfPQMgUCbkGQqWjH0kyk0KOxFpgY1UgC1//kYinKeIvAl0B44FtgAPAu8AbwFNgR+BvhFeyjfiijnP7tjXQgqsB24MySGLOyJyJvAxsArIC2y+B8sdS5jrWcJ5XkkCXc9I8j47viVDv50MfTYkR78dzj47IYJm55xzzjnnIikR0jOcc84555yLKA+anXPOOeecK4UHzc4555xzzpXCg2bnnHPOOedK4UGzc84555xzpfCg2cUlETkgIitCbiPDeOxmIhL39Tedcy6WeL/t4l21aDfAuQrao6rto90I55xzZeb9totrPtLsEoqIrBeRx0VklYj8U0RaBrY3E5H5IrJSRD4SkaaB7Q1EZJaIfBm4nRE4VFURGS8iq0XkAxGpFbWTcs65BOb9tosXHjS7eFWr0Nd8/UKe26WqacD/YauOATwHTFbVdsDrwLjA9nHA31U1HegIrA5sbwU8r6ptgJ3AFRE+H+ecS3Teb7uoS9tSAAABLUlEQVS45isCurgkIjmqWqeI7euB81T1exGpDvyiqseIyDagoaruD2zfrKrHikgW0FhV94Ucoxnwoaq2CjweAVRX1dGRPzPnnEtM3m+7eOcjzS4RaTH3y2NfyP0DeP6/c85FkvfbLuZ50OwSUb+Qn0sC9xcD/QP3BwAfB+5/BAwFEJGqIlL3cDXSOedcPu+3XczzT2EuXtUSkRUhj+eqarB8UYqIrMRGHa4MbLsNmCgidwJZwODA9mFApohch41MDAU2R7z1zjmXfLzfdnHNc5pdQgnkxnVW1W3RbotzzrnSeb/t4oWnZzjnnHPOOVcKH2l2zjnnnHOuFD7S7JxzzjnnXCk8aHbOOeecc64UHjQ755xzzjlXCg+anXPOOeecK4UHzc4555xzzpXi/wPQ51/EL/kcvAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFMVAjiUj2U5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e51460c7-cbd2-4448-bde6-1514b2827c52"
      },
      "source": [
        "# 모델 평가\n",
        "model.evaluate(test_X, test_Y) #학습 안한걸로 평가해야 한다."
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 860us/step - loss: 0.0267 - accuracy: 0.9900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.026748722419142723, 0.9900000095367432]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BD6BQLiiExf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "4001ab29-172b-454f-829a-8c61d4c9fc85"
      },
      "source": [
        "###############################################\n",
        "import numpy as np\n",
        "# 훈련된 모델로 예측값 수행\n",
        "results = model.predict(test_X)\n",
        "\n",
        "# 예측값 중에서 가장 큰 값의 인덱스값을 b에 넣음\n",
        "b = np.argmax(results, axis=-1)\n",
        "\n",
        "print(b[:10])  # 예측한 값의 결과\n",
        "print(test_Y[:10])  # 실제 값의 결과"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 0 1 0 1 1]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-UiA2mtjDBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#상:7~9\n",
        "#중:6\n",
        "#하:3~5\n",
        "#품질 예측 모델 만들기"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkszqHEDlpdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}